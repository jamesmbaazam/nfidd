[
  {
    "objectID": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html",
    "href": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html",
    "title": "Using delay distributions to model the data generating process",
    "section": "",
    "text": "We’ve now developed a good idea of how epidemiological time delays affect our understanding of an evolving outbreak. So far, we’ve been working with individual line-list data. However, we usually want to model how an outbreak evolves through a whole population. The aim of this session is to introduce how delay distributions can be used to model population-level data generating process during an epidemic.\nThis means working with aggregated count data. This creates some new issues in correctly accounting for uncertainty. We handle population-level data using convolutions as a way of combining count data with a distribution of individual probabilities. We will have to adjust our continuous probability distributions to work with this using discretisation. We’ll then need to re-introduce additional uncertainty to account for the observation process at a population level.\n\n\n\nDelay distributions at the population level\n\n\n\n\nIn this session, we’ll focus on the delay from infection to symptom onset at a population level. First, we will introduce the techniques of convolution and discretisation. We’ll apply these to an aggregated time series of infections in order to simulate observed symptom onsets. Then, we’ll use those simulated symptom onsets to try and reconstruct a time series of infections.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Using delay distributions to model the data generating process"
    ]
  },
  {
    "objectID": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#slides",
    "href": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#slides",
    "title": "Using delay distributions to model the data generating process",
    "section": "",
    "text": "Delay distributions at the population level",
    "crumbs": [
      "Using delay distributions to model the data generating process"
    ]
  },
  {
    "objectID": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#objectives",
    "href": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#objectives",
    "title": "Using delay distributions to model the data generating process",
    "section": "",
    "text": "In this session, we’ll focus on the delay from infection to symptom onset at a population level. First, we will introduce the techniques of convolution and discretisation. We’ll apply these to an aggregated time series of infections in order to simulate observed symptom onsets. Then, we’ll use those simulated symptom onsets to try and reconstruct a time series of infections.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Using delay distributions to model the data generating process"
    ]
  },
  {
    "objectID": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#source-file",
    "href": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#source-file",
    "title": "Using delay distributions to model the data generating process",
    "section": "",
    "text": "The source file of this session is located at sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.qmd.",
    "crumbs": [
      "Using delay distributions to model the data generating process"
    ]
  },
  {
    "objectID": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#libraries-used",
    "href": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#libraries-used",
    "title": "Using delay distributions to model the data generating process",
    "section": "",
    "text": "In this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "Using delay distributions to model the data generating process"
    ]
  },
  {
    "objectID": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#initialisation",
    "href": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#initialisation",
    "title": "Using delay distributions to model the data generating process",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Using delay distributions to model the data generating process"
    ]
  },
  {
    "objectID": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#delay-distributions-and-convolutions",
    "href": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#delay-distributions-and-convolutions",
    "title": "Using delay distributions to model the data generating process",
    "section": "Delay distributions and convolutions",
    "text": "Delay distributions and convolutions\nIn the last session we simulated individual outcomes from a delay distribution, and then re-estimated the corresponding parameters. However, sometimes we do not have data on these individual-level outcomes, either because they are not recorded or because they cannot be shared, for example due to privacy concerns. At the population level, individual-level delays translate into convolutions.\nIf we have a time series of infections \\(I_t\\) (\\(t=1, 2, 3, \\ldots, t_\\mathrm{max}\\)), where \\(t\\) denotes the day on which the infections occur, and observable outcomes occur with a delay given by a delay distribution \\(p_i\\) (\\(i=0, 1, 2, \\dots, p_\\mathrm{max}\\)), where \\(i\\) is the number of days after infection that the observation happens, then the number of observable outcomes \\(C_t\\) on day \\(t\\) is given by\n\\[\nC_t = \\sum_{i=0}^{i=p_\\mathrm{max}} I_{t-i} p_i\n\\]\nIn other words, the number of observable outcomes on day \\(t\\) is given by the sum of infections on all previous days multiplied by the probability that those infections are observed on day \\(t\\). For example, the observable outcomes \\(C_t\\) could be the number of symptom onsets on day \\(t\\) and \\(p_i\\) is the incubation period.\nWe can use the same data as in the session on biases in delay distributions, but this time we first aggregate this into a daily time series of infections. You can do this by sourcing the following code snippet:\n\nsource(\n  here::here(\"snippets\", \"load-ts.r\"),\n  echo = TRUE, max.deparse.length = 1000\n)\n\n\n&gt; data(infection_times)\n\n&gt; df &lt;- transmute(infection_times, infection_day = floor(infection_time))\n\n&gt; inf_ts &lt;- count(df, infection_day, name = \"infections\")\n\n&gt; all_days &lt;- expand(df, infection_day = seq(min(infection_day), \n+     max(infection_day)))\n\n&gt; inf_ts &lt;- replace_na(full_join(all_days, inf_ts, by = join_by(infection_day)), \n+     list(infections = 0))\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe second part of the code snippet above is used to add days without infections with a zero count. This will make our calculations easier later (as otherwise we would have to try and detect these in any models that used this data which could be complicated).\n\n\nAnd look at the first few rows of the daily aggregated data:\n\nhead(inf_ts)\n\n# A tibble: 6 × 2\n  infection_day infections\n          &lt;dbl&gt;      &lt;int&gt;\n1             0          1\n2             1          0\n3             2          1\n4             3          0\n5             4          2\n6             5          1\n\n\nNow we can convolve the time series with a delay distribution to get a time series of outcomes as suggested above.\n\nDiscretising a delay distribution\nIn our first session, we decided to assume the delay from infection to symptom onset had a gamma distribution. However, if we want to use the gamma distribution with shape 5 and rate 1 as before, we face a familiar issue. The gamma distribution is a continuous distribution, but now our delay data are in days which are discrete entities. We will assume that both events that make up the delay (here infection and symptom onset) are observed as daily counts (e.g. as number of infections/symptom onsets by calendar date). Therefore, both observations are censored (as events are rounded to the nearest date). This means that our distribution is double interval censored which we encountered in the the biases in delay distribution session, so we need to use the same ideas introduced in that session.\n::: .callout-note collapse=true #### Mathematical Definition (optional): Discretising a delay distribution subject to double interval censoring\nThe cumulative distribution function (CDF) (\\(F(t)\\)) of a distribution that has a daily censored primary event can be expressed as,\n\\[\nF^*(t) = \\int_0^1 F(t - u) du\n\\]\nIn effect, this is saying that the daily censored CDF is the average of the continuous distributions CDF over all possible event times (here between 0 and 1).\nThe probability mass function (PMF) of this distribution when observed as a daily process (i.e. the secondary event is also daily censored) is then\n\\[\nf_t \\propto \\frac{F^*(t + 1) - F^*(t - 1)}{}\n\\]\nThe important point is that the ultimately observed PMF is a combination of a primary event daily censoring process and a secondary event daily censoring process. :::\nWe can think about this via simulation. We do so by generating many replicates of the corresponding random delay, taking into account that we have already rounded down our infection times to infection days. This means that discretising a delay in this context is double censoring as we discussed in the the biases in delay distribution session. In the absence of any other information or model, we assume for our simulation that infection occurred at some random time during the day, with each time equally likely. We can then apply the incubation period using a continuous probability distribution, before once again rounding down to get the day of symptom onset (mimicking daily reporting). We repeat this many times to get the probability mass function that allows us to go from infection days to symptom onset days:\n\n## function that takes two inputs to discretise a continuous delay distribution\n##\n## function arguments:\n## rgen: a function that generates random delays, e.g. rgamma, rlognormal\n## n: the number of replicates to simulate\n## max: the maximum delay\n## ...: parameters of the delay distribution\n## the function returns a vector of probabilities, corresponding to discrete\n## indices 0, 1, 2 of the discretised delay distribution\n##\n## example: censored_delay_pmf(rgen = rgamma, max = 14, shape = 5, rate = 1)\ncensored_delay_pmf &lt;- function(rgen, max, n = 1e+6, ...) {\n  ## first, simulate exact time of first event (given by day), uniformly\n  ## between 0 and 1\n  first &lt;- runif(n, min = 0, max = 1)\n  ## now,  simulate the exact time of the second event\n  second &lt;- first + rgen(n, ...)\n  ## round down to get the delay in days\n  delay &lt;- floor(second)\n  ## get vector of counts\n  counts &lt;- table(factor(delay, levels = seq(0, max)))\n  ## normalise to get pmf\n  pmf &lt;- counts / sum(counts)\n  ## return\n  return(pmf)\n}\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nTry to understand the censored_delay_pmf() function above. Try it with a few different probability distributions and parameters, e.g. for the parameters given above and a maximum delay of 2 weeks (14 days) it would be:\n\ngamma_pmf &lt;- censored_delay_pmf(rgamma, max = 14, shape = 5, rate = 1)\ngamma_pmf\n\n\n           0            1            2            3            4            5 \n0.0006738544 0.0213000084 0.0904146458 0.1637886841 0.1914657786 0.1741648410 \n           6            7            8            9           10           11 \n0.1339778840 0.0919285654 0.0582628773 0.0344727114 0.0194606761 0.0103971836 \n          12           13           14 \n0.0055410260 0.0027965460 0.0013547178 \n\nplot(gamma_pmf)\n\n\n\n\n\n\n\n\n\n\n\n\nApplying a convolution\nNext we apply a convolution with the discretised incubation period distribution to the time series of infections, to generate a time series of symptom onsets.\n\n## function that takes two inputs to convolve a time series with a delay\n##\n## function arguments:\n## ts: vector of the time series to convolve\n## delay: the probability mass function of the delay, given as a vector of\n## probabilities, corresponding to discrete indices 0, 1, 2 of the discretised\n## delay distribution\n##\n## example: convolve_with_delay(ts = c(10, 14, 10, 10), delay_pmf = c(0.1, 0.6, 0.3))\nconvolve_with_delay &lt;- function(ts, delay_pmf) {\n  max_delay &lt;- length(delay_pmf) - 1 ## subtract one because zero-indexed\n  convolved &lt;- vapply(seq_along(ts), \\(i) {\n    ## get vector of infections over the possible window of the delay period\n    first_index &lt;- max(1, i - max_delay)\n    ts_segment &lt;- ts[seq(first_index, i)]\n    ## take reverse of pmf and cut if needed\n    pmf &lt;- rev(delay_pmf)[seq_len(i - first_index + 1)]\n    ## convolve with delay distribution\n    ret &lt;- sum(ts_segment * pmf)\n    return(ret)\n  }, numeric(1))\n  return(convolved)\n}\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nTry to understand the convolve_with_delay() function above. Try it with a few different time series and delay distributions. How would you create the time series of symptom onsets from infections, using the discretised gamma distribution created above (saved in gamma_pmf)?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nonsets &lt;- convolve_with_delay(inf_ts$infections, gamma_pmf)\n\n\n\n\nWe can plot these symptom onsets:\n\ncombined &lt;- inf_ts |&gt;\n  rename(time = infection_day) |&gt;\n  mutate(onsets = onsets)\nggplot(combined, aes(x = time, y = onsets)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nDo they look similar to the plot of symptom onsets in the session on delay distributions?",
    "crumbs": [
      "Using delay distributions to model the data generating process"
    ]
  },
  {
    "objectID": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#observation-uncertainty",
    "href": "sessions/using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic.html#observation-uncertainty",
    "title": "Using delay distributions to model the data generating process",
    "section": "Observation uncertainty",
    "text": "Observation uncertainty\nUsually not all data are perfectly observed. Also, the convolution we applied is a deterministic operation that brushes over the fact that individual delays are random. We should therefore find another way to model the variation these processes introduce.\nGiven that we are now dealing with count data a natural choice is the Poisson distribution. We can use this to generate uncertainty around our convolved data.\n\ncombined &lt;- combined |&gt;\n  mutate(observed = rpois(n(), onsets))\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nDoes a plot of these observations look more like the plots from the session on delay distributions than the convolution plotted above?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nggplot(combined, aes(x = time, y = observed)) +\n  geom_bar(stat = \"identity\")",
    "crumbs": [
      "Using delay distributions to model the data generating process"
    ]
  },
  {
    "objectID": "sessions/slides/introduction-to-statistical-concepts.html#bayesian-inference-in-15-minutes",
    "href": "sessions/slides/introduction-to-statistical-concepts.html#bayesian-inference-in-15-minutes",
    "title": "Introduction to statistical concepts used in the course",
    "section": "Bayesian inference in 15 minutes",
    "text": "Bayesian inference in 15 minutes"
  },
  {
    "objectID": "sessions/slides/introduction-to-statistical-concepts.html#bayesian-inference-in-15-minutes-1",
    "href": "sessions/slides/introduction-to-statistical-concepts.html#bayesian-inference-in-15-minutes-1",
    "title": "Introduction to statistical concepts used in the course",
    "section": "Bayesian inference in 15 minutes",
    "text": "Bayesian inference in 15 minutes\n\nIdea of Bayesian inference: treat \\(\\theta\\) as random variables (with a probability distribution) and condition on data: posterior probability \\(p(\\theta | \\mathrm{data})\\) as target of inference."
  },
  {
    "objectID": "sessions/slides/introduction-to-reproduction-number.html#convolution-session",
    "href": "sessions/slides/introduction-to-reproduction-number.html#convolution-session",
    "title": "Introduction to the time-varying reproduction number",
    "section": "Convolution session",
    "text": "Convolution session\n\nfunctions {\n  #include \"functions/convolve_with_delay.stan\"\n}\n\ndata {\n  int n;            // number of time days\n  array[n] int obs; // observed onsets\n  int&lt;lower = 1&gt; ip_max; // max incubation period\n  // probability mass function of incubation period distribution (first index zero)\n  array[ip_max + 1] real ip_pmf;\n}\n\nparameters {\n  array[n] real&lt;lower = 0&gt; infections;\n}\n\ntransformed parameters {\n  array[n] real onsets = convolve_with_delay(infections, ip_pmf);\n}\n\nmodel {\n  // priors\n  infections ~ normal(0, 10) T[0, ];\n  obs ~ poisson(onsets);\n}\n\n\nPrior for infections at time \\(t\\) is independent from infections at all other time points. Is this reasonable?"
  },
  {
    "objectID": "sessions/slides/introduction-to-reproduction-number.html#infections-depend-on-previous-infections",
    "href": "sessions/slides/introduction-to-reproduction-number.html#infections-depend-on-previous-infections",
    "title": "Introduction to the time-varying reproduction number",
    "section": "Infections depend on previous infections",
    "text": "Infections depend on previous infections\nRemember the definition of the generation time distribution \\(g(t)\\):\ninfection (person A) to infection (person B, infected by A)\nThrough this, infections depend on previous infections:\n\\[\nI_t = \\mathrm{scaling} \\times \\sum_{t' &lt; t} I_t' g(t - t')\n\\]\nWhat is this scaling?"
  },
  {
    "objectID": "sessions/slides/introduction-to-reproduction-number.html#scaling-of-infections-with-previous-infections",
    "href": "sessions/slides/introduction-to-reproduction-number.html#scaling-of-infections-with-previous-infections",
    "title": "Introduction to the time-varying reproduction number",
    "section": "Scaling of infections with previous infections",
    "text": "Scaling of infections with previous infections\nLet’s assume we have \\(I_0\\) infections at time 0, and the scaling doesn’t change in time.\nHow many people will they go on to infect?\n\n\\[\nI = \\mathrm{scaling} \\times \\sum_{t=0}^\\infty I_0 g(t) = \\mathrm{scaling} * I_0\n\\]\nThe scaling can be interpreted as the (time-varying) reproduction number \\(R_t\\)."
  },
  {
    "objectID": "sessions/slides/introduction-to-reproduction-number.html#the-renewal-equation",
    "href": "sessions/slides/introduction-to-reproduction-number.html#the-renewal-equation",
    "title": "Introduction to the time-varying reproduction number",
    "section": "The renewal equation",
    "text": "The renewal equation\nIf \\(R_t\\) can change over time, it can still be interpreted as the (“instantaneous”) reproduction number:\n\\[\nI_t = R_t \\times \\sum_{t' &lt; t} I_t' g(t - t')\n\\]"
  },
  {
    "objectID": "sessions/slides/introduction-to-reproduction-number.html#the-renewal-equation-as-convolution",
    "href": "sessions/slides/introduction-to-reproduction-number.html#the-renewal-equation-as-convolution",
    "title": "Introduction to the time-varying reproduction number",
    "section": "The renewal equation as convolution",
    "text": "The renewal equation as convolution"
  },
  {
    "objectID": "sessions/slides/introduction-to-reproduction-number.html#the-time-varying-reproduction-number",
    "href": "sessions/slides/introduction-to-reproduction-number.html#the-time-varying-reproduction-number",
    "title": "Introduction to the time-varying reproduction number",
    "section": "The time-varying reproduction number",
    "text": "The time-varying reproduction number\nWe can estimate \\(R_t\\) from a time series of infections using the renewal equation.\nWhat are some other ways of estimating it?"
  },
  {
    "objectID": "sessions/slides/introduction-to-reproduction-number.html#your-turn",
    "href": "sessions/slides/introduction-to-reproduction-number.html#your-turn",
    "title": "Introduction to the time-varying reproduction number",
    "section": " Your Turn",
    "text": "Your Turn\n\nSimulate infections using the renewal equation\nEstimate reproduction numbers using a time series of infections\nCombine with delay distributions to jointly infer infections and R from a time series of outcomes"
  },
  {
    "objectID": "sessions/slides/introduction-to-joint-estimation-of-nowcasting-and-reporting-delays.html#r-fontawesomefalaptop-code-white-your-turn",
    "href": "sessions/slides/introduction-to-joint-estimation-of-nowcasting-and-reporting-delays.html#r-fontawesomefalaptop-code-white-your-turn",
    "title": "Introduction to joint estimation of nowcasting and reporting delays",
    "section": "r fontawesome::fa(\"laptop-code\", \"white\") Your Turn",
    "text": "r fontawesome::fa(\"laptop-code\", \"white\") Your Turn\n\nSimulate the reporting triangle\nPerform a joint estimation of the delay and nowcast\nUnderstand the limitations of the data generating process\nPerform a joint estimation of the delay, nowcast, and reproduction number"
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#biases-in-epidemiological-delays",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#biases-in-epidemiological-delays",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Biases in epidemiological delays",
    "text": "Biases in epidemiological delays\nWhy might our estimates of epidemiological delays be biased?\n\n\n\ndata reliability and representativeness\n\n\n\nintrinsic issues with data collection and recording"
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#issue-1-double-censoring",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#issue-1-double-censoring",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Issue #1: Double censoring",
    "text": "Issue #1: Double censoring\n\nreporting of events usually as a date (not date + precise time)\nfor short delays this can make quite a difference\naccounting for it incorrectly can introduce more bias than doing nothing"
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#double-censoring-example",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#double-censoring-example",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Double censoring: example",
    "text": "Double censoring: example\nWe are trying to estimate an incubation period. For person A we know exposure happened on day 1 and symptom onset on day 3."
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#double-censoring-example-1",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#double-censoring-example-1",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Double censoring: example",
    "text": "Double censoring: example\nWe are trying to estimate an incubation period. For person A we know exposure happened on day 1 and symptom onset on day 3."
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#double-censoring-example-2",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#double-censoring-example-2",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Double censoring: example",
    "text": "Double censoring: example\nWe are trying to estimate an incubation period. For person A we know exposure happened on day 1 and symptom onset on day 3."
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#double-censoring-example-3",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#double-censoring-example-3",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Double censoring: example",
    "text": "Double censoring: example\nWe are trying to estimate an incubation period. For person A we know exposure happened on day 1 and symptom onset on day 3.\n\nThe true incubation period of A could be anywhere between 1 and 3 days (but not all equally likely)."
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#issue-2-right-truncation",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#issue-2-right-truncation",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Issue #2: right truncation",
    "text": "Issue #2: right truncation\n\nreporting of events can be triggered by the secondary event\nin that case, longer delays might be missing because whilst the primary events have occurred the secondary events have not occurred yet"
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#example-right-truncation",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#example-right-truncation",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Example: right truncation",
    "text": "Example: right truncation\nWe are trying to estimate an incubation period. Each arrow represents one person with an associated pair of events (infection and symptom onset)."
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#example-right-truncation-1",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#example-right-truncation-1",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Example: right truncation",
    "text": "Example: right truncation\nWe are trying to estimate an incubation period. Each arrow represents one person with an associated pair of events (infection and symptom onset)."
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#example-right-truncation-2",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#example-right-truncation-2",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Example: right truncation",
    "text": "Example: right truncation\nWe are trying to estimate an incubation period. Each arrow represents one person with an associated pair of events (infection and symptom onset)."
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#example-right-truncation-3",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#example-right-truncation-3",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Example: right truncation",
    "text": "Example: right truncation\nWe are trying to estimate an incubation period. Each arrow represents one person with an associated pair of events (infection and symptom onset)\n\nOn the day of analysis we have not observed some delays yet, and these tended to be longer. This is made worse during periods of exponential growth."
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#censoring-and-right-truncation",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#censoring-and-right-truncation",
    "title": "Introduction to biases in epidemiological delays",
    "section": "Censoring and right truncation",
    "text": "Censoring and right truncation\n\nWhen analysing data from an outbreak in real time, we are likely to have double censoring and right truncation, making things worse\nIn the practical we will only look at the two separately to keep things simple"
  },
  {
    "objectID": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#your-turn",
    "href": "sessions/slides/introduction-to-biases-in-epidemiological-delays.html#your-turn",
    "title": "Introduction to biases in epidemiological delays",
    "section": " Your Turn",
    "text": "Your Turn\n\nSimulate epidemiological delays with biases\nEstimate parameters of a delay distribution, correcting for biases"
  },
  {
    "objectID": "sessions/slides/forecasting-models.html#r-fontawesomefalaptop-code-white-your-turn",
    "href": "sessions/slides/forecasting-models.html#r-fontawesomefalaptop-code-white-your-turn",
    "title": "Forecasting models",
    "section": "r fontawesome::fa(\"laptop-code\", \"white\") Your Turn",
    "text": "r fontawesome::fa(\"laptop-code\", \"white\") Your Turn\n\nReview the performance of the random walk model from the last session\nMotivate a mechanism to include in order to address some of the issues we identified\nMotivate a statistical approach aiming to address the same issues without introducing epidemiological mechanism\nCompare the performance of these models for a single forecast\nEvaluate many forecast from these models and compare their performance to the random walk model"
  },
  {
    "objectID": "sessions/slides/convolutions.html#individual-delays",
    "href": "sessions/slides/convolutions.html#individual-delays",
    "title": "Delay distributions at the population level",
    "section": "Individual delays",
    "text": "Individual delays\nIf \\(f(t)\\) is our delay distribution then\n\\[\np(y_i) = f(y_i - x_i)\n\\]\nis the probability that secondary event of individual \\(i\\) happens at time \\(y_i\\) given its primary event happened at \\(x_i\\)."
  },
  {
    "objectID": "sessions/slides/convolutions.html#population-level-counts",
    "href": "sessions/slides/convolutions.html#population-level-counts",
    "title": "Delay distributions at the population level",
    "section": "Population level counts",
    "text": "Population level counts\nThe expected number of individuals \\(S_t\\) that have their secondary event at time \\(t\\) can then be calculated as the sum of these probabilities\n\\[\nS_t = \\sum_i f_{t - x_i}\n\\]\n\nNote: If \\(S_t\\) is in discrete time steps then \\(f_t\\) needs to be a discrete probability distribution."
  },
  {
    "objectID": "sessions/slides/convolutions.html#population-level-counts-1",
    "href": "sessions/slides/convolutions.html#population-level-counts-1",
    "title": "Delay distributions at the population level",
    "section": "Population level counts",
    "text": "Population level counts\nIf the number of individuals \\(P_{t'}\\) that have their primary event at time \\(t'\\) then we can rewrite this as\n\\[\nS_t = \\sum_{t'} P_{t'} f_{t - t'}\n\\]\nThis operation is called a (discrete) convolution of \\(P\\) with \\(f\\).\nWe can use convolutions with the delay distribution that applies at the individual level to determine population-level counts."
  },
  {
    "objectID": "sessions/slides/convolutions.html#example-infections-to-symptom-onsets",
    "href": "sessions/slides/convolutions.html#example-infections-to-symptom-onsets",
    "title": "Delay distributions at the population level",
    "section": "Example: infections to symptom onsets",
    "text": "Example: infections to symptom onsets"
  },
  {
    "objectID": "sessions/slides/convolutions.html#why-use-a-convolution-not-individual-delays",
    "href": "sessions/slides/convolutions.html#why-use-a-convolution-not-individual-delays",
    "title": "Delay distributions at the population level",
    "section": "Why use a convolution, not individual delays?",
    "text": "Why use a convolution, not individual delays?\n\nwe don’t always have individual data available\nwe often model other processes at the population level (such as transmission) and so being able to model delays on the same scale is useful\ndoing the computation at the population level requires fewer calculations (i.e. is faster)\n\n\n\nhowever, a downside is that we won’t have realistic uncertainty, especially if the number of individuals is small"
  },
  {
    "objectID": "sessions/slides/convolutions.html#what-if-f-is-continuous",
    "href": "sessions/slides/convolutions.html#what-if-f-is-continuous",
    "title": "Delay distributions at the population level",
    "section": "What if \\(f\\) is continuous?",
    "text": "What if \\(f\\) is continuous?\nHaving moved to the population level, we can’t estimate individual-level event times any more.\nInstead, we discretise the distribution (remembering that it is double censored - as both events are censored).\nThis can be solved mathematically but in the session we will use simulation."
  },
  {
    "objectID": "sessions/slides/convolutions.html#your-turn",
    "href": "sessions/slides/convolutions.html#your-turn",
    "title": "Delay distributions at the population level",
    "section": " Your Turn",
    "text": "Your Turn\n\nSimulate convolutions with infection counts\nDiscretise continuous distributions\nEstimate parameters numbers of infections from number of symptom onsets, using a convolution model"
  },
  {
    "objectID": "sessions/overview-of-available-tools.html",
    "href": "sessions/overview-of-available-tools.html",
    "title": "Overview of available tools",
    "section": "",
    "text": "In the course so far we introduced key concepts and methods in nowcasting and forecasting of infectious disease dynamics, using a combination of R and (mostly) stan. Being able to understand these concepts and implement them in stan comes with the ability to create and adapt models that are tailor made to any given situation and specific characteristics of any given data set. At the same time, there is value in using and contributing to open-source tools that implement some or all of the methods we have encountered in the course. These tools have varying levels of flexibility to deal with different kinds of epidemiological problems and data. Whilst they will never have the flexibility of completely custom approaches, using and contributing to them avoids duplication, improves the chances of finding errors, and helps discussing and ultimately enforcing best practice.\n\n\nThe aim of this session is to try out some of the tools that are available that use some of the ideas we have discussed in this course.",
    "crumbs": [
      "Overview of available tools"
    ]
  },
  {
    "objectID": "sessions/overview-of-available-tools.html#objective",
    "href": "sessions/overview-of-available-tools.html#objective",
    "title": "Overview of available tools",
    "section": "",
    "text": "The aim of this session is to try out some of the tools that are available that use some of the ideas we have discussed in this course.",
    "crumbs": [
      "Overview of available tools"
    ]
  },
  {
    "objectID": "sessions/overview-of-available-tools.html#epiestim",
    "href": "sessions/overview-of-available-tools.html#epiestim",
    "title": "Overview of available tools",
    "section": "EpiEstim",
    "text": "EpiEstim\nEpiEstim implements the renewal equation on a time series of infections in a Bayesian framework, i.e. the model in estimate-r.stan in the session on R estimation. In combination with the projections package in can be used for forecasting.\nThe EpiEstim vignette is a good starting point for a walkthrough of \\(R_t\\) estimation and forecasting.",
    "crumbs": [
      "Overview of available tools"
    ]
  },
  {
    "objectID": "sessions/overview-of-available-tools.html#epinow2",
    "href": "sessions/overview-of-available-tools.html#epinow2",
    "title": "Overview of available tools",
    "section": "EpiNow2",
    "text": "EpiNow2\nEpiNow2 implements the renewal equation on a time series of delayed outcomes including nowcasts with a known reporting delay distribution, as well as forecasts using a Gaussian Process or random walk model, i.e. the models introduced here except the joint inference of nowcasts and delays and/or reproduction numbers.\nThe example of nowcasting, Rt estimation and forecasting with EpiNow2 is a good place to find out more about how to use EpiNow2 with linelist data.",
    "crumbs": [
      "Overview of available tools"
    ]
  },
  {
    "objectID": "sessions/overview-of-available-tools.html#epinowcast",
    "href": "sessions/overview-of-available-tools.html#epinowcast",
    "title": "Overview of available tools",
    "section": "Epinowcast",
    "text": "Epinowcast\nEpinowcast was created to replace EpiNow2. It implements all the models discussed in the course with a frontend to work with line lists, data by reference and report date or cumulative data snapshots. Whilst this model can also be used for forecasts (as we have seen) this does not currently have a user-facing interface in the package.\nThe vignette on estimating the effective reproduction number in real-time for a single timeseries with reporting delays is a good example of joint nowcasting and reproduction number estimation from an aggregated time series of reference (outcome) and reporting counts. This example does not start from a line list but does contain information about using the package for transforming between line list and appropriately aggregated data.",
    "crumbs": [
      "Overview of available tools"
    ]
  },
  {
    "objectID": "sessions/overview-of-available-tools.html#going-further",
    "href": "sessions/overview-of-available-tools.html#going-further",
    "title": "Overview of available tools",
    "section": "Going further",
    "text": "Going further\nThere are many other R packages that can be used for R estimation, nowcasting and forecasting. We invite readers to suggest further additions on our discussion board.",
    "crumbs": [
      "Overview of available tools"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html",
    "href": "sessions/joint-nowcasting.html",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "",
    "text": "In the last session we introduced the idea of nowcasting using a simple model. However, this approach had problems: we didn’t fully account for uncertainty, or for example observation error in the primary events, and it’s not a fully generative model of the data reporting process. And as we saw, if we get the delay distribution wrong, we can get the nowcast very wrong.\nA better approach is to jointly estimate the delay distribution together with the nowcast. We can do this by using information from multiple snapshots of the data as it changes over time (using a data structure called the “reporting triangle”). In this session, we’ll introduce this approach to joint estimation in nowcasting. At the end we’ll then demonstrate a way to combine this with our previous work estimating the reproduction number, steadily improving our real time outbreak model.\n\n\n\nIntroduction to joint estimation of delays and nowcasts\n\n\n\n\nThis session aims to introduce how to do nowcasting if the reporting delay distribution is unknown.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/joint-nowcasting.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#slides",
    "href": "sessions/joint-nowcasting.html#slides",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "",
    "text": "Introduction to joint estimation of delays and nowcasts",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#objectives",
    "href": "sessions/joint-nowcasting.html#objectives",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "",
    "text": "This session aims to introduce how to do nowcasting if the reporting delay distribution is unknown.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/joint-nowcasting.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#source-file",
    "href": "sessions/joint-nowcasting.html#source-file",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "",
    "text": "The source file of this session is located at sessions/joint-nowcasting.qmd.",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#libraries-used",
    "href": "sessions/joint-nowcasting.html#libraries-used",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "",
    "text": "In this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#initialisation",
    "href": "sessions/joint-nowcasting.html#initialisation",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#motivation",
    "href": "sessions/joint-nowcasting.html#motivation",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "Motivation",
    "text": "Motivation\nSo far we have assumed that the delay distribution is known. In practice, this is often not the case and we need to estimate it from the data. As we discussed in the session on biases in delay distributions, this can be done using individual data and then passing this estimate to a simple nowcasting model like those above. However, this has the disadvantage that the nowcasting model does not take into account the uncertainty in the delay distribution or observation error of the primary events. We can instead estimate the delay distribution and nowcast the data jointly.",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#the-reporting-triangle",
    "href": "sessions/joint-nowcasting.html#the-reporting-triangle",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "The reporting triangle",
    "text": "The reporting triangle\nTo jointly estimate we need to decompose observations into what is known as the reporting triangle. This is a matrix where the rows are the days of onset and the columns are the days of report. The entries are the number of onsets on day \\(i\\) that are reported on day \\(j\\). We can then use this matrix to estimate the delay distribution and nowcast the data. It is referred to as a triangle because the data for the more recent data entries are incomplete which gives the matrix a triangular shape.\nWe can construct the reporting triangle from onsets (\\(N_{t}\\)) as follows: \\[\nN_{t} = \\sum_{d=0}^{D} n_{t,d}\n\\]\nWhere \\(n_{t,d}\\) is the number of onsets on day \\(t\\) that are reported on day \\(t-d\\) and \\(D\\) represents the maximum delay between date of reference and time of report which in theory could be infinite but in practice we set to a finite value to make the model identifiable and computationally feasible. We can now construct a model to estimate \\(n_{t,d}\\),\n\\[\n  n_{t,d} \\mid \\lambda_{t},p_{t,d} \\sim \\text{Poisson} \\left(\\lambda_{t} \\times p_{t,d} \\right),\\ t=1,...,T.\n\\]\nwhere \\(\\lambda_{t}\\) is the expected number of onsets on day \\(t\\) and \\(p_{t,d}\\) is the probability that an onset on day \\(t\\) is reported on day \\(t-d\\). Here \\(\\lambda_{t}\\) is the same as the expected number of onsets on day \\(t\\) in the simple nowcasting model above so we again modelled it using a geometric random walk for now. We model \\(p_{t,d}\\) as a Dirichlet distribution as it is a distribution over probabilities. \\(p_{t,d}\\) is equivalent to the reporting delays we have been using as fixed quantities so far but now estimated within the model. In most real-world settings we would want to use our domain expertise to inform the prior distribution of \\(p_{t,d}\\).",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#simulating-the-reporting-triangle",
    "href": "sessions/joint-nowcasting.html#simulating-the-reporting-triangle",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "Simulating the reporting triangle",
    "text": "Simulating the reporting triangle\nNow that we are aiming to jointly estimate the delay distribution we need additional data. We can simulate this data by using the same generative process as above but now also simulating the reporting delays.\nOnce again we generate our simulated onset dataset:\n\nsource(here(\"snippets\", \"simulate-onsets.r\")) ## generates `onset_df`\nhead(onset_df)\n\n# A tibble: 6 × 3\n    day onsets infections\n  &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;\n1     1      0          0\n2     2      0          1\n3     3      0          0\n4     4      0          2\n5     5      0          1\n6     6      0          1\n\ncutoff &lt;- 71\n\nWe also need to simulate the reporting delays:\n\nsource(here(\"functions\", \"censored-delay-pmf.r\"))\nreporting_delay_pmf &lt;- censored_delay_pmf(rlnorm, max = 15, meanlog = 1, sdlog = 0.5)\nplot(reporting_delay_pmf)\n\n\n\n\n\n\n\n\nWe can then simulate the reporting triangle:\n\nreporting_triangle &lt;- onset_df |&gt;\n  filter(day &lt; cutoff) |&gt;\n  mutate(\n    reporting_delay = list(tibble(d = 0:15, reporting_delay = reporting_delay_pmf)\n  )) |&gt;\n  unnest(reporting_delay) |&gt;\n  mutate(\n    reported_onsets = rpois(n(), onsets * reporting_delay)\n  ) |&gt;\n  mutate(reported_day = day + d)\n\nWe also need to update our simulated truth data to include the Poisson observation error we are assuming is part of the observation process.\n\nnoisy_onsets_df &lt;- reporting_triangle |&gt;\n  summarise(noisy_onsets = sum(reported_onsets), .by = day)\n\nAs we only partially observe the reporting triangle we need to filter it to only include the data we have observed:\n\nfiltered_reporting_triangle &lt;- reporting_triangle |&gt;\n  filter(reported_day &lt;= max(day))\n\nFinally, we sum the filtered reporting triangle to get the counts we actually observe.\n\navailable_onsets &lt;- filtered_reporting_triangle |&gt;\n  summarise(available_onsets = sum(reported_onsets), .by = day)",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/joint-nowcasting.html#fitting-the-joint-model",
    "href": "sessions/joint-nowcasting.html#fitting-the-joint-model",
    "title": "Nowcasting with an unknown reporting delay",
    "section": "Fitting the joint model",
    "text": "Fitting the joint model\nAs usual we start by loading the model:\n\njoint_mod &lt;- cmdstan_model(here(\"stan\", \"joint-nowcast.stan\"))\njoint_mod\n\n 1: functions {\n 2:   #include \"functions/geometric_random_walk.stan\"\n 3:   #include \"functions/observe_onsets_with_delay.stan\"\n 4:   #include \"functions/combine_obs_with_predicted_obs_rng.stan\"\n 5: }\n 6: \n 7: data {\n 8:   int n;                // number of days\n 9:   int m;                // number of reports\n10:   array[n] int p;       // number of observations per day\n11:   array[m] int obs;     // observed symptom onsets\n12:   int d;                // number of reporting delays\n13: }\n14: \n15: transformed data{\n16:   array[n] int P = to_int(cumulative_sum(p));\n17:   array[n] int D = to_int(cumulative_sum(rep_array(d, n)));\n18: }\n19: \n20: parameters {\n21:   real&lt;lower=0&gt; init_onsets;\n22:   array[n-1] real rw_noise;\n23:   real&lt;lower=0&gt; rw_sd;\n24:   simplex[d] reporting_delay; // reporting delay distribution\n25: }\n26: \n27: transformed parameters {\n28:   array[n] real onsets = geometric_random_walk(init_onsets, rw_noise, rw_sd);\n29:   array[m] real onsets_by_report = observe_onsets_with_delay(onsets, reporting_delay, P, p);\n30: }\n31: \n32: model {\n33:   // Prior\n34:   init_onsets ~ normal(1, 1) T[0,];\n35:   rw_noise ~ std_normal();\n36:   rw_sd ~ normal(0, 0.1) T[0,];\n37:   reporting_delay ~ dirichlet(rep_vector(1, d));\n38:   // Likelihood\n39:   obs ~ poisson(onsets_by_report);\n40: }\n41: \n42: generated quantities {\n43:   array[d*n] real complete_onsets_by_report = observe_onsets_with_delay(onsets, reporting_delay, D, rep_array(d, n));\n44:   array[n] int nowcast = combine_obs_with_predicted_obs_rng(obs, complete_onsets_by_report, P, p, d, D);\n45: }\n46: \n\n\n\n\n\n\n\n\nModel details\n\n\n\n\n\nThis time we won’t go into details of the model. For now, it is important that you understand the concept but as the models get more complex we hope that you trust us that the model does what we describe above.\nOnce thing to note is that we are now fitting the initial number of symptom onsets (init_onsets). This is different from earlier when we had to pass the initial number of infections (I0) as data. In most situations this number would be unknown so what we do here is closer to what one would do in the real world.\n\n\n\nWe then fit it do data:\n\njoint_data &lt;- list(\n  n = length(unique(filtered_reporting_triangle$day)),                # number of days\n  m = nrow(filtered_reporting_triangle),               # number of reports\n  p = filtered_reporting_triangle |&gt;\n   group_by(day) |&gt;\n   filter(d == max(d)) |&gt;\n   mutate(d = d + 1) |&gt;\n   pull(d),       # number of observations per day\n  obs = filtered_reporting_triangle$reported_onsets,     # observed symptom onsets\n  d = 16               # number of reporting delays\n)\njoint_nowcast_fit &lt;- joint_mod$sample(data = joint_data, parallel_chains = 4)\n\n\njoint_nowcast_fit\n\n    variable   mean median   sd  mad     q5    q95 rhat ess_bulk ess_tail\n lp__        373.36 373.76 7.88 7.87 359.77 385.62 1.00     1018     1558\n init_onsets   0.20   0.15 0.18 0.15   0.01   0.55 1.00     4534     2743\n rw_noise[1]  -0.97  -0.97 0.88 0.91  -2.42   0.47 1.00     8763     3287\n rw_noise[2]  -0.71  -0.69 0.93 0.90  -2.26   0.81 1.00     8783     3074\n rw_noise[3]  -0.50  -0.49 0.95 0.92  -2.10   1.02 1.00     9306     3079\n rw_noise[4]  -0.32  -0.33 0.92 0.92  -1.84   1.21 1.00     9366     2713\n rw_noise[5]  -0.14  -0.14 0.95 0.96  -1.74   1.39 1.00     9499     2703\n rw_noise[6]   0.04   0.03 0.94 0.96  -1.51   1.60 1.00     9234     2884\n rw_noise[7]  -0.06  -0.05 0.93 0.93  -1.60   1.44 1.00     9244     2500\n rw_noise[8]  -0.14  -0.16 0.96 0.93  -1.72   1.41 1.00    11198     2476\n\n # showing 10 of 2348 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\nOne benefit of this model is that because we have decomposed the data into the reporting triangle we can make a nowcast that uses the data we have available augmented with predictions from the model. This should give us far more accurate uncertainty estimates than the simple nowcasting models above (see stan/functions/combine_obs_with_predicted_obs_rng.stan but note the code is fairly involved). We now extract this nowcast:\n\njoint_nowcast_onsets &lt;- joint_nowcast_fit |&gt;\n  gather_draws(nowcast[day]) |&gt;\n  ungroup() |&gt;\n  filter(.draw %in% sample(.draw, 100))\n\nFinally, we can plot the nowcast alongside the observed data:\n\nggplot(joint_nowcast_onsets, aes(x = day)) +\n  geom_col(data = noisy_onsets_df, mapping = aes(y = noisy_onsets), alpha = 0.6) +\n  geom_line(mapping = aes(y = .value, group = .draw), alpha = 0.1) +\n  geom_point(data = available_onsets, mapping = aes(y = available_onsets))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nReminder: The points in this plot represent the data available when the nowcast was made (and so are truncated) whilst the bars represent the finally reported data (a perfect nowcast would exactly reproduce these).\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nLook back at the last three nowcasts. How do they compare? What are the advantages and disadvantages of each? Could we improve the nowcasts further?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe simple nowcast struggled to capture the generative process of the data and so produced poor nowcasts. The nowcast with the geometric random walk was better but still struggled to capture the generative process of the data. The joint nowcast was the best of the three as it properly handled the uncertainty and allowed us to fit the delay distribution versus relying on known delays.\nHowever, the joint nowcast is still quite simple (in the sense that no detailed mechanism or reporting process is being modelled) and so may struggle to capture more complex patterns in the data. In particular the prior model for the geometric random walk assumes that onsets are the same as the previous day with some statistical noise. This may not be a good assumption in a rapidly changing epidemic (where the reproduction number is not near 1).\nIn addition, whilst we say it is “quite simple” as should be clear from the code it is quite complex and computationally intensive. This is because we are fitting a model to the reporting triangle which is a much larger data set and so the model is relatively quite slow to fit.",
    "crumbs": [
      "Nowcasting with an unknown reporting delay"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html",
    "href": "sessions/forecasting-models.html",
    "title": "Forecasting models",
    "section": "",
    "text": "We can classify models along a spectrum by how much they include an understanding of underlying processes, or mechanisms; or whether they emphasise drawing from the data using a statistical approach. In this session, we’ll start with the renewal model that we’ve been using and explore adding both more mechanistic structure and then more statistical structure to the model. We’ll again evaluate these models to see what effect these different approaches might have.\n\n\n\nForecasting models\n\n\n\n\nThe aim of this session is to introduce some common forecasting models and to evaluate them.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/forecasting-models.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\nlibrary(\"scoringutils\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#slides",
    "href": "sessions/forecasting-models.html#slides",
    "title": "Forecasting models",
    "section": "",
    "text": "Forecasting models",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#objectives",
    "href": "sessions/forecasting-models.html#objectives",
    "title": "Forecasting models",
    "section": "",
    "text": "The aim of this session is to introduce some common forecasting models and to evaluate them.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/forecasting-models.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\nlibrary(\"scoringutils\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#source-file",
    "href": "sessions/forecasting-models.html#source-file",
    "title": "Forecasting models",
    "section": "",
    "text": "The source file of this session is located at sessions/forecasting-models.qmd.",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#libraries-used",
    "href": "sessions/forecasting-models.html#libraries-used",
    "title": "Forecasting models",
    "section": "",
    "text": "In this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\nlibrary(\"scoringutils\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#initialisation",
    "href": "sessions/forecasting-models.html#initialisation",
    "title": "Forecasting models",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#adding-more-mechanistic-structure-to-the-renewal-model",
    "href": "sessions/forecasting-models.html#adding-more-mechanistic-structure-to-the-renewal-model",
    "title": "Forecasting models",
    "section": "Adding more mechanistic structure to the renewal model",
    "text": "Adding more mechanistic structure to the renewal model\nOne way to potentially improve the renewal model is to add more mechanistic structure. In the forecasting concepts session, we saw that the renewal model was making unbiased forecasts when the reproduction number was constant but that it overestimated the number of cases when the reproduction number was reducing due to susceptible depletion.\nThis suggests that we should add a term to the renewal model which captures the depletion of susceptibles. One way to do this is to add a term which is proportional to the number of susceptibles in the population. This is the idea behind the SIR model which is a simple compartmental model of infectious disease transmission. If we assume that susceptible depletion is the only mechanism which is causing the reproduction number to change, we can write the reproduction model as:\n\\[\nR_t = \\frac{S_{t-1}}{N} R_0\n\\]\nThis approximates susceptible depletion as a linear function of the number of susceptibles in the population. This is a simplification but it is a good starting point.\n\n\n\n\n\n\nWhat behaviour would we expect from this model?\n\n\n\n\n\n\nn &lt;- 100\nN &lt;- 1000\nR0 &lt;- 1.5\nS &lt;- rep(NA, n)\nS[1] &lt;- N\nRt &lt;- rep(NA, n) ## reproduction number\nRt[1] &lt;- R0\nI &lt;- rep(NA, n)\nI[1] &lt;- 1\nfor (i in 2:n) {\n  Rt[i] &lt;- (S[i-1]) / N * R0\n  I[i] &lt;- I[i-1] * Rt[i]\n  S[i] &lt;- S[i-1] - I[i]\n}\n\ndata &lt;- tibble(t = 1:n, Rt = Rt)\n\nggplot(data, aes(x = t, y = Rt)) +\n  geom_line() +\n  labs(title = \"Simulated data from an SIR model\",\n       x = \"Time\",\n       y = \"Rt\")\n\n\n\n\n\n\n\n\nThe key assumptions we are making here are:\n\nThe population is constant and we roughly know the size of the population.\nThe reproduction number only changes due to susceptible depletion\nThe number of new cases at each time is proportional to the number of susceptibles in the population.\n\nWe’ve coded this up as a stan model in stan/mechanistic-r.stan. See stan/functions/pop_bounded_renewal.stan for the function which calculates the reproduction number. Let’s load the model:\n\nmech_mod &lt;- cmdstan_model(here(\"stan\", \"mechanistic-r.stan\"))\nmech_mod\n\n 1: functions {\n 2:   #include \"functions/convolve_with_delay.stan\"\n 3:   #include \"functions/pop_bounded_renewal.stan\"\n 4: }\n 5: \n 6: data {\n 7:   int n;                // number of days\n 8:   int I0;              // number initially infected\n 9:   array[n] int obs;     // observed symptom onsets\n10:   int gen_time_max;     // maximum generation time\n11:   array[gen_time_max] real gen_time_pmf;  // pmf of generation time distribution\n12:   int&lt;lower = 1&gt; ip_max; // max incubation period\n13:   array[ip_max + 1] real ip_pmf;\n14:   int h;                // number of days to forecast\n15:   array[2] real N_prior;      // prior for total population\n16: }\n17: \n18: transformed data {\n19:    int m = n + h;\n20: }\n21: \n22: parameters {\n23:   real&lt;lower = 0&gt; R;    // initial reproduction number\n24:   real&lt;lower = 0&gt; N;   // total population\n25: }\n26: \n27: transformed parameters {\n28:   array[m] real infections = pop_bounded_renewal(I0, R, gen_time_pmf, N, m);\n29:   array[m] real onsets = convolve_with_delay(infections, ip_pmf);\n30: }\n31: \n32: model {\n33:   // priors\n34:   R ~ normal(1, 0.5) T[0,];\n35:   N ~ normal(N_prior[1], N_prior[2]) T[0,];\n36:   obs ~ poisson(onsets[1:n]);\n37: }\n38: \n39: generated quantities {\n40:   array[h] real forecast;\n41:   if (h &gt; 0) {\n42:     for (i in 1:h) {\n43:       forecast[i] = poisson_rng(onsets[n + i]);\n44:     }\n45:   }\n46: }\n\n\n\nAdding more statistical structure to the renewal model\nAdding more mechanistic structure is not always possible and, if we don’t specify mechanisms correctly, might make forecasts worse. Rather than adding more mechanistic structure to the renewal model, we could add more statistical structure with the aim of improving performance. Before we do this, we need to think about what we want from a forecasting model. As we identified above, we want a model which is unbiased and which has good short-term forecasting properties. We know that we want it to be able to adapt to trends in the reproduction number and that we want it to be able to capture the noise in the data. A statistical term that can be used to describe capturing a trend is saying that the time series is non-stationary. More specifically, a stationary time series is defined as one that does not have a trend over time. In infectious disease epidemiology, this would only be expected for endemic diseases without external seasonal influence.\nThe random walk model we used in the forecasting concept session is a special case of a more general class of models called autoregressive (AR) models. AR models are a class of models which predict the next value in a time series as a linear combination of the previous values in the time series. The random walk model is specifically a special case of an AR(1) model where the next value in the time series is predicted as the previous value, multiplied by a value between 1 and -1 , plus some noise. For the log-transformed reproduction number (\\(log(R_t)\\)), the model is:\n\\[\nlog(R_t) = \\phi log(R_{t-1}) + \\epsilon_t\n\\]\nwhere \\(\\epsilon_t\\) is a normally distributed error term with mean 0 and standard deviation \\(\\sigma\\) and \\(\\phi\\) is a parameter between -1 and 1. If we restrict \\(\\phi\\) to be between 0 and 1, we get a model which is biased towards a reproduction number of 1 but which can still capture trends in the data that decay over time.\n\n\n\n\n\n\nWhat behaviour would we expect from this model?\n\n\n\n\n\n\nn &lt;- 100\nphi &lt;- 0.4\nsigma &lt;- 0.1\nlog_R &lt;- rep(NA, n)\nlog_R[1] &lt;- rnorm(1, 0, sigma)\nfor (i in 2:n) {\n  log_R[i] &lt;- phi * log_R[i-1] + rnorm(1, 0, sigma)\n}\ndata &lt;- tibble(t = 1:n, R = exp(log_R))\n\nggplot(data, aes(x = t, y = R)) +\n  geom_line() +\n  labs(title = \"Simulated data from an exponentiated AR(1) model\",\n       x = \"Time\",\n       y = \"R\")\n\n\n\n\n\n\n\n\n\n\n\nHowever, we probably don’t want a model which is biased towards a reproduction number of 1 (unless we have good reason to believe that is the expected behaviour). So what should we do?\nReturning to the idea that the reproduction number is a non-stationary time series, as we have a trend in the reproduction number we want to capture, we can use a method from the field of time series analysis called differencing to make the time series stationary. This involves taking the difference between consecutive values in the time series. For the log-transformed reproduction number, this would be:\n\\[\nlog(R_t) - log(R_{t-1}) = \\phi (log(R_{t-1}) - log(R_{t-2})) + \\epsilon_t\n\\]\n\n\n\n\n\n\nWhat behaviour would we expect from this model?\n\n\n\n\n\nAgain we look at an R function that implements this model:\n\nsource(here(\"functions\", \"geometric-diff-ar.r\"))\ngeometric_diff_ar\n\nfunction (init, noise, std, damp) \n{\n    n &lt;- length(noise) + 1\n    x &lt;- numeric(n)\n    x[1] &lt;- init\n    x[2] &lt;- x[1] + noise[1] * std\n    for (i in 3:n) {\n        x[i] &lt;- x[i - 1] + damp * (x[i - 1] - x[i - 2]) + noise[i - \n            1] * std\n    }\n    return(exp(x))\n}\n\n\nWe can use this function to simulate a differenced random walk:\n\nlog_R &lt;- geometric_diff_ar(init = 1, noise = rnorm(100), std = 0.1, damp = 0.1)\n\ndata &lt;- tibble(t = seq_along(log_R), R = exp(log_R))\n\nggplot(data, aes(x = t, y = R)) +\n  geom_line() +\n  labs(title = \"Simulated data from an exponentiated AR(1) model with differencing\",\n       x = \"Time\",\n       y = \"R\")\n\n\n\n\n\n\n\n\n\n\n\nWe’ve coded up a model that uses this random walk as a stan model in stan/statistical-r.stan. See stan/functions/geometic_diff_ar.stan for the function which calculates the reproduction number. Lets load the model:\n\nstat_mod &lt;- cmdstan_model(here(\"stan/statistical-r.stan\"))\nstat_mod\n\n 1: functions {\n 2:   #include \"functions/convolve_with_delay.stan\"\n 3:   #include \"functions/renewal.stan\"\n 4:   #include \"functions/geometric_diff_ar.stan\"\n 5: }\n 6: \n 7: data {\n 8:   int n;                // number of days\n 9:   int I0;              // number initially infected\n10:   array[n] int obs;     // observed symptom onsets\n11:   int gen_time_max;     // maximum generation time\n12:   array[gen_time_max] real gen_time_pmf;  // pmf of generation time distribution\n13:   int&lt;lower = 1&gt; ip_max; // max incubation period\n14:   array[ip_max + 1] real ip_pmf;\n15:   int h;                // number of days to forecast\n16: }\n17: \n18: transformed data {\n19:    int m = n + h;\n20: }\n21: \n22: parameters {\n23:   real init_R;         // initial reproduction number\n24:   array[m-1] real rw_noise; // random walk noise\n25:   real&lt;lower = 0&gt; rw_sd; // random walk standard deviation\n26:   real&lt;lower = 0, upper = 1&gt; damp; // damping\n27: }\n28: \n29: transformed parameters {\n30:   array[m] real R = geometric_diff_ar(init_R, rw_noise, rw_sd, damp);\n31:   array[m] real &lt;upper = 1e5&gt; infections = renewal(I0, R, gen_time_pmf);\n32:   array[m] real onsets = convolve_with_delay(infections, ip_pmf);\n33: }\n34: \n35: model {\n36:   // priors\n37:   init_R ~ normal(-.1, 0.5); // Approximately Normal(1, 0.5)\n38:   rw_noise ~ std_normal();\n39:   rw_sd ~ normal(0, 0.01) T[0,];\n40:   damp ~ normal(0.9, 0.2) T[0, 1];\n41:   obs ~ poisson(onsets[1:n]);\n42: }\n43: \n44: generated quantities {\n45:   array[h] real forecast;\n46:   if (h &gt; 0) {\n47:     for (i in 1:h) {\n48:       forecast[i] = poisson_rng(onsets[n + i]);\n49:     }\n50:   }\n51: }\n\n\n\n\nForecasting with the mechanistic and statistical models\nWe will now use the mechanistic and statistical models to forecast the number of cases in the future using data simulated in the same way as we did in the forecasting concepts session. We will first load in the data and filter for a target forecast date.\n\nsource(here(\"snippets\", \"simulate-onsets.r\"))\nonset_df\n\n# A tibble: 142 × 3\n     day onsets infections\n   &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;\n 1     1      0          0\n 2     2      0          1\n 3     3      0          0\n 4     4      0          2\n 5     5      0          1\n 6     6      0          1\n 7     7      0          1\n 8     8      0          3\n 9     9      0          0\n10    10      1          0\n# ℹ 132 more rows\n\n# we'll make a forecast on day non day 41, pretending we haven't seen the later data\ncutoff &lt;- 41\n\nfiltered_onset_df &lt;- onset_df |&gt;\n  filter(day &lt;= cutoff)\n\nWe will now fit the more mechanistic model to the data.\n\nhorizon &lt;- 28\n\ndata &lt;- list(\n  n =nrow(filtered_onset_df),\n  I0 = 1,\n  obs = filtered_onset_df$onsets,\n  gen_time_max = length(gen_time_pmf),\n  gen_time_pmf = gen_time_pmf,\n  ip_max = length(ip_pmf) - 1,\n  ip_pmf = ip_pmf,\n  h = horizon, # Here we set the number of days to forecast into the future\n  N_prior = c(10000, 2000) # the prior for the population size\n)\nmech_forecast_fit &lt;- mech_mod$sample(\n  data = data, parallel_chains = 4\n)\n\n\nmech_forecast_fit\n\n      variable    mean  median      sd     mad      q5      q95 rhat ess_bulk\n lp__            31.87   32.19    1.04    0.74   29.73    32.84 1.00     1488\n R                1.44    1.44    0.02    0.02    1.41     1.47 1.00     2524\n N             9928.07 9938.50 1992.12 1887.27 6624.34 13260.36 1.00     2713\n infections[1]    0.10    0.10    0.00    0.00    0.09     0.10 1.00     2526\n infections[2]    0.26    0.26    0.00    0.00    0.25     0.27 1.00     2526\n infections[3]    0.36    0.36    0.01    0.01    0.35     0.37 1.00     2525\n infections[4]    0.41    0.41    0.01    0.01    0.40     0.42 1.00     2526\n infections[5]    0.44    0.44    0.01    0.01    0.43     0.46 1.00     2525\n infections[6]    0.48    0.48    0.01    0.01    0.46     0.50 1.00     2525\n infections[7]    0.53    0.53    0.01    0.01    0.51     0.56 1.00     2525\n ess_tail\n     2092\n     2251\n     1586\n     2251\n     2251\n     2251\n     2251\n     2251\n     2251\n     2251\n\n # showing 10 of 169 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\nWe will now fit the more statistical model to the data.\n\ndata &lt;- list(\n  n =nrow(filtered_onset_df),\n  I0 = 1,\n  obs = filtered_onset_df$onsets,\n  gen_time_max = length(gen_time_pmf),\n  gen_time_pmf = gen_time_pmf,\n  ip_max = length(ip_pmf) - 1,\n  ip_pmf = ip_pmf,\n  h = horizon # Here we set the number of days to forecast into the future\n)\nstat_forecast_fit &lt;- stat_mod$sample(\n  data = data, parallel_chains = 4,\n  init = \\() list(init_R = 0, rw_sd = 0.01) # again set the initial values to make fitting more numerically stable\n)\n\nFinally we can extract the forecasts from the models and plot them.\n\nmech_forecast &lt;- mech_forecast_fit |&gt;\n  gather_draws(forecast[day]) |&gt;\n  ungroup() |&gt; \n  mutate(day = day + cutoff)\n\nstat_forecast &lt;- stat_forecast_fit |&gt;\n  gather_draws(forecast[day]) |&gt;\n  ungroup() |&gt; \n  mutate(day = day + cutoff)\n\nforecast &lt;- bind_rows(\n  mutate(mech_forecast, model = \"more mechanistic\"),\n  mutate(stat_forecast, model = \"more statistical\")\n) |&gt;\n  ungroup()\n\ntarget_onsets &lt;- onset_df |&gt;\n  filter(day &gt; cutoff) |&gt;\n  filter(day &lt;= cutoff + horizon)\n\n\nforecast |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_line(alpha = 0.1, aes(y = .value, group = interaction(.draw, model), colour = model)) +\n  geom_point(data = target_onsets, aes(x = day, y = onsets), color = \"black\") +\n  scale_y_log10() +\n  guides(colour = guide_legend(override.aes = list(alpha = 1)))\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nWhat do you notice about the forecasts from the more mechanistic and more statistical models?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe more mechanistic model captures the downturn in the data very well.\nThe more statistical model is not as good at capturing the downturn in the data but is substantially better than the random walk model was in the forecasting concepts session.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nAs these models are still renewal processes we can still plot the time-varying reproduction number which can be a helpful way of reasoning about how the models are performing.\n\nstat_forecast_fit |&gt;\n  gather_draws(R[day]) |&gt;\n  ungroup() |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(y = .value, x = day)) +\n  geom_hline(yintercept = 1, linetype = \"dashed\") +\n  geom_line(aes(group = .draw), alpha = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happens when you are very wrong about the population size? (optional)\n\n\n\nIn the above we assumed that we knew the population size roughly. In practice, we may not. Refit the more mechanistic model with different priors for the population size and see how the forecasts change.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndata &lt;- list(\n  n = nrow(filtered_onset_df),\n  I0 = 1,\n  obs = filtered_onset_df$onsets,\n  gen_time_max = length(gen_time_pmf),\n  gen_time_pmf = gen_time_pmf,\n  ip_max = length(ip_pmf) - 1,\n  ip_pmf = ip_pmf,\n  h = horizon, # Here we set the number of days to forecast into the future\n  N_prior = c(100, 20) # the prior for the population size\n)\n\nmech_forecast_fit_diff &lt;- mech_mod$sample(\n  data = data, parallel_chains = 4\n)\n\nmech_forecast_diff &lt;- mech_forecast_fit_diff |&gt;\n  gather_draws(forecast[day]) |&gt;\n  ungroup() |&gt; \n  mutate(day = day + cutoff)\n\n\nmech_forecast_diff |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(y = .value, x = day)) +\n  geom_line(alpha = 0.1, aes(group = .draw)) +\n  geom_point(\n    data = target_onsets, aes(x = day, y = onsets),\n    color = \"black\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating forecasts from our models\nAs in the forecasting concepts session, we have fit these models to a range of forecast dates so you don’t have to wait for the models to fit. We will now evaluate the forecasts from the mechanistic and statistical models.\n\ndata(rw_forecasts, stat_forecasts, mech_forecasts)\nforecasts &lt;- bind_rows(\n  rw_forecasts,\n  stat_forecasts,\n  mech_forecasts\n) |&gt; \n  ungroup()\n\n\n\n\n\n\n\nTip\n\n\n\nWe generated these forecasts using the code in data-raw/generate-example-forecasts.r which uses the same approach we just took for a single forecast date but generalises it to many forecast dates.\nSome important things to note about these forecasts:\n\nWe used a 14 day forecast horizon.\nEach forecast used all the data up to the forecast date.\nWe generated 1000 posterior samples for each forecast.\nWe started forecasting 3 weeks into the outbreak and then forecast every 7 days until the end of the data (excluding the last 14 days to allow a full forecast).\nWe use the same simulated outbreak data:\n\n\nhead(onset_df)\n\n# A tibble: 6 × 3\n    day onsets infections\n  &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;\n1     1      0          0\n2     2      0          1\n3     3      0          0\n4     4      0          2\n5     5      0          1\n6     6      0          1\n\n\n\n\n\nVisualising your forecast\n\nforecasts |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_line(aes(y = .value, group = interaction(.draw, target_day), col = target_day), alpha = 0.1) +\n  geom_point(data = onset_df |&gt;\n    filter(day &gt;= 21),\n    aes(x = day, y = onsets), color = \"black\") +\n  scale_color_binned(type = \"viridis\") +\n  facet_wrap(~model) +\n  lims(y = c(0, 500))\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nAs for the single forecast it is helpful to also plot the forecast on the log scale.\n\nforecasts |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_line(aes(y = .value, group = interaction(.draw, target_day), col = target_day), alpha = 0.1) +\n  geom_point(data = onset_df, aes(x = day, y = onsets), color = \"black\") +\n  scale_y_log10(limits = c(NA, 500)) +\n  scale_color_binned(type = \"viridis\") +\n  facet_wrap(~model)\n\nWarning in scale_y_log10(limits = c(NA, 500)): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\nWarning: Removed 13 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nHow do these forecasts compare? Which do you prefer?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHow do these forecasts compare?\n\nThe more mechanistic model captures the downturn in the data very well.\nPast the peak all models were comparable.\nThe more statistical model does a very poor job of capturing the downturn in the data extending the current trend.\nThe more statistical model is more uncertain than the mechanistic model but less uncertain than the random walk.\n\nWhich do you prefer?\n\nThe more mechanistic model seems to be the best at capturing the downturn in the data and the uncertainty in the forecasts seems reasonable.\n\n\n\n\n\n\nScoring your forecast\n\nsc_forecasts &lt;- forecasts |&gt;\n  left_join(onset_df, by = \"day\") |&gt;\n  filter(!is.na(.value)) |&gt;\n  as_forecast(\n    forecast_unit = c(\"target_day\", \"horizon\", \"model\"),\n    forecast_type = \"sample\",\n    observed = \"onsets\",\n    predicted = \".value\",\n    model = \"model\",\n    sample_id = \".draw\"\n  )\nsc_forecasts\n\nForecast type: sample\n\n\nForecast unit:\n\n\ntarget_day, horizon, and model\n\n\n\n        sample_id predicted observed target_day horizon       model\n            &lt;int&gt;     &lt;num&gt;    &lt;int&gt;      &lt;num&gt;   &lt;int&gt;      &lt;char&gt;\n     1:         1         4        3         22       1 Random walk\n     2:         2         2        3         22       1 Random walk\n     3:         3         2        3         22       1 Random walk\n     4:         4         6        3         22       1 Random walk\n     5:         5         2        3         22       1 Random walk\n    ---                                                            \n671996:       996         1        7        127      14 Mechanistic\n671997:       997         7        7        127      14 Mechanistic\n671998:       998         2        7        127      14 Mechanistic\n671999:       999         1        7        127      14 Mechanistic\n672000:      1000         5        7        127      14 Mechanistic\n\n\nEverything seems to be in order. We can now use the scoringutils package to calculate some metrics as we did in the forecasting concepts session.\n\nsc_scores &lt;- sc_forecasts |&gt;\n  score()\n\nsc_scores\n\n     target_day horizon       model   bias      dss     crps log_score    mad\n          &lt;num&gt;   &lt;int&gt;      &lt;char&gt;  &lt;num&gt;    &lt;num&gt;    &lt;num&gt;     &lt;num&gt;  &lt;num&gt;\n  1:         22       1 Random walk  0.043 1.540881 0.469424  1.655610 1.4826\n  2:         22       2 Random walk  0.556 2.391756 0.950522  1.851434 2.9652\n  3:         22       3 Random walk  0.328 2.194804 0.738624  1.842254 2.9652\n  4:         22       4 Random walk  0.687 3.231981 1.570469  2.175798 2.9652\n  5:         22       5 Random walk  0.767 3.750147 2.172579  2.489797 2.9652\n ---                                                                         \n668:        127      10 Mechanistic  0.509 2.013433 0.809048  1.802981 1.4826\n669:        127      11 Mechanistic  0.680 2.464343 1.158455  1.845716 1.4826\n670:        127      12 Mechanistic  0.974 4.875547 2.604446  3.415057 1.4826\n671:        127      13 Mechanistic  0.084 1.249373 0.408800  1.462535 1.4826\n672:        127      14 Mechanistic -0.956 6.383069 3.065386  3.692003 1.4826\n     ae_median   se_mean\n         &lt;num&gt;     &lt;num&gt;\n  1:         0  0.155236\n  2:         2  3.655744\n  3:         1  1.898884\n  4:         3  9.284209\n  5:         3 15.327225\n ---                    \n668:         1  2.292196\n669:         2  4.313929\n670:         3 13.704804\n671:         0  0.119716\n672:         4 15.904144\n\n\n\nAt a glance\nLet’s summarise the scores by model first.\n\nsc_scores |&gt;\n  summarise_scores(by = \"model\")\n\n         model      bias      dss      crps log_score       mad ae_median\n        &lt;char&gt;     &lt;num&gt;    &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;\n1: Random walk 0.2602411 6.387998 13.804122  3.980707 18.251203 18.522321\n2: Statistical 0.3075893 6.247106 13.833699  3.983604 16.364859 18.415179\n3: Mechanistic 0.2600536 5.615946  6.490944  3.705884  8.511712  9.035714\n     se_mean\n       &lt;num&gt;\n1: 1578.2811\n2: 1504.3416\n3:  196.7022\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nBefore we look in detail at the scores, what do you think the scores are telling you? Which model do you think is best?\n\n\n\n\nContinuous ranked probability score\nAs in the forecasting concepts session, we will start by looking at the CRPS by horizon and forecast date.\n\n\n\n\n\n\nReminder: Key things to note about the CRPS\n\n\n\n\nSmall values are better\nAs it is an absolute scoring rule it can be difficult to use to compare forecasts across scales.\n\n\n\nFirst by forecast horizon.\n\nsc_scores |&gt;\n  summarise_scores(by = c(\"model\", \"horizon\")) |&gt;\n  ggplot(aes(x = horizon, y = crps, col = model)) +\n  geom_point()\n\n\n\n\n\n\n\n\nand across different forecast dates\n\nsc_scores |&gt;\n  summarise_scores(by = c(\"target_day\", \"model\")) |&gt;\n  ggplot(aes(x = target_day, y = crps, col = model)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nHow do the CRPS scores change based on forecast date? How do the CRPS scores change with forecast horizon?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHow do the CRPS scores change based on forecast horizon?\n\nAll models have increasing CRPS with forecast horizon.\nThe more mechanistic model has the lowest CRPS at all forecast horizon.\nThe more stastical model forms notably worse at all forecast horizons.\n\nHow do the CRPS scores change with forecast date?\n\nThe more statistical model does particularly poorly around the peak of the outbreak.\nThe more mechanistic model does particularly well around the peak of the outbreak versus all other models\n\n\n\n\n\n\nPIT histograms\n\n\n\n\n\n\nReminder: Interpreting the PIT histogram\n\n\n\n\nIdeally PIT histograms should be uniform.\nIf is a U shape then the model is overconfident and if it is an inverted U shape then the model is underconfident.\nIf it is skewed then the model is biased towards the direction of the skew.\n\n\n\nLet’s first look at the overall PIT histogram.\n\n sc_forecasts |&gt;\n  get_pit(by = \"model\") |&gt;\n  plot_pit() +\n  facet_wrap(~model)\n\n\n\n\n\n\n\n\nAs before let’s look at the PIT histogram by forecast horizon (to save space we will group horizons)\n\nsc_forecasts |&gt; \n  mutate(group_horizon = case_when(\n    horizon &lt;= 3 ~ \"1-3\",\n    horizon &lt;= 7 ~ \"4-7\",\n    horizon &lt;= 14 ~ \"8-14\"\n  )) |&gt;\n  get_pit(by = c(\"model\", \"group_horizon\")) |&gt;\n  plot_pit() +\n  facet_grid(vars(model), vars(group_horizon))\n\n\n\n\n\n\n\n\nand then for different forecast dates.\n\n sc_forecasts |&gt;\n  get_pit(by = c(\"model\", \"target_day\")) |&gt;\n  plot_pit() +\n  facet_grid(vars(model), vars(target_day))\n\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nWhat do you think of the PIT histograms?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhat do you think of the PIT histograms?\n\nThe more mechanistic model is reasonably well calibrated but has a tendency to underpredict.\nBoth the random walk and more statistical model are biased towards overpredicting with the more statistical model also being poorly calibrated (liable to both under and overpredict).\nAcross horizons the more mechanistic model is only liable to underpredict at the longest horizons.\nSimilarly, the statistical and random walk models are more biased at longer horizons.\nThe forecast date stratified PIT histograms are hard to interpret but the more mechanistic model seems to be the best calibrated across forecast date.\n\n\n\n\n\n\n\nScoring on the log scale\nAgain as in the forecasting concepts session, we will also score the forecasts on the log scale.\n\nlog_sc_forecasts &lt;- sc_forecasts |&gt;\n  transform_forecasts(\n    fun = log_shift,\n    offset = 1,\n    append = FALSE\n  )\n\nlog_sc_scores &lt;- log_sc_forecasts |&gt;\n  score()\n\n\n\n\n\n\n\nTip\n\n\n\nReminder: For more on scoring on the log scale see Scoring forecasts on transformed scales.\n\n\n\nAt a glance\n\nlog_sc_scores |&gt;\n  summarise_scores(by = \"model\")\n\n         model      bias        dss      crps log_score       mad ae_median\n        &lt;char&gt;     &lt;num&gt;      &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;\n1: Random walk 0.2202500 -0.5437929 0.2430521 0.5758656 0.3761217 0.3308532\n2: Statistical 0.2669464 -0.3897250 0.2464576 0.5991320 0.3302442 0.3410720\n3: Mechanistic 0.2189554 -1.0162121 0.2116730 0.2931774 0.2182572 0.2914358\n     se_mean\n       &lt;num&gt;\n1: 0.2015962\n2: 0.2116263\n3: 0.1764724\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nBefore we look in detail at the scores, what do you think the scores are telling you? Which model do you think is best?\n\n\n\n\nCRPS\n\nlog_sc_scores |&gt;\n  summarise_scores(by = c(\"model\", \"horizon\")) |&gt;\n  ggplot(aes(x = horizon, y = crps, col = model)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nlog_sc_scores |&gt;\n  summarise_scores(by = c(\"target_day\", \"model\")) |&gt;\n  ggplot(aes(x = target_day, y = crps, col = model)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nHow do the CRPS scores on the log scale compare to the scores on the original scale?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe random walk and more mechanistic models have much similar performance.\nEven at the peak this is true as the log scale approach more evenly weights the over and underpredictions.\nThe more statistical model is still notably worse than the other models.\nIn particular, it is much worse at the peak of the outbreak and at longer horizons.\n\n\n\n\n\n\nPIT histograms\n\n log_sc_forecasts |&gt;\n  get_pit(by = \"model\") |&gt;\n  plot_pit() +\n  facet_wrap(~model)\n\n\n\n\n\n\n\n\n\nlog_sc_forecasts |&gt; \n  mutate(group_horizon = case_when(\n    horizon &lt;= 3 ~ \"1-3\",\n    horizon &lt;= 7 ~ \"4-7\",\n    horizon &lt;= 14 ~ \"8-14\"\n  )) |&gt;\n  get_pit(by = c(\"model\", \"group_horizon\")) |&gt;\n  plot_pit() +\n  facet_grid(vars(model), vars(group_horizon))\n\n\n\n\n\n\n\n\n\n log_sc_forecasts |&gt;\n  get_pit(by = c(\"model\", \"target_day\")) |&gt;\n  plot_pit() +\n  facet_grid(vars(model), vars(target_day))\n\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nWhat do you think of the PIT histograms?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhat do you think of the PIT histograms? - The PIT histograms are similar to the original scale PIT histograms.",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#adding-more-statistical-structure-to-the-renewal-model",
    "href": "sessions/forecasting-models.html#adding-more-statistical-structure-to-the-renewal-model",
    "title": "Forecasting models",
    "section": "Adding more statistical structure to the renewal model",
    "text": "Adding more statistical structure to the renewal model\nAdding more mechanistic structure is not always possible and, if we don’t specify mechanisms correctly, might make forecasts worse. Rather than adding more mechanistic structure to the renewal model, we could add more statistical structure with the aim of improving performance. Before we do this, we need to think about what we want from a forecasting model. As we identified above, we want a model which is unbiased and which has good short-term forecasting properties. We know that we want it to be able to adapt to trends in the reproduction number and that we want it to be able to capture the noise in the data. A statistical term that can be used to describe capturing a trend is saying that the time series is non-stationary. More specifically, a stationary time series is defined as one that does not have a trend over time. In infectious disease epidemiology, this would only be expected for endemic diseases without external seasonal influence.\nThe random walk model we used in the forecasting concept session is a special case of a more general class of models called autoregressive (AR) models. AR models are a class of models which predict the next value in a time series as a linear combination of the previous values in the time series. The random walk model is specifically a special case of an AR(1) model where the next value in the time series is predicted as the previous value, multiplied by a value between 1 and -1 , plus some noise. For the log-transformed reproduction number (\\(log(R_t)\\)), the model is:\n\\[\nlog(R_t) = \\phi log(R_{t-1}) + \\epsilon_t\n\\]\nwhere \\(\\epsilon_t\\) is a normally distributed error term with mean 0 and standard deviation \\(\\sigma\\) and \\(\\phi\\) is a parameter between -1 and 1. If we restrict \\(\\phi\\) to be between 0 and 1, we get a model which is biased towards a reproduction number of 1 but which can still capture trends in the data that decay over time.\n\n\n\n\n\n\nWhat behaviour would we expect from this model?\n\n\n\n\n\n\nn &lt;- 100\nphi &lt;- 0.4\nsigma &lt;- 0.1\nlog_R &lt;- rep(NA, n)\nlog_R[1] &lt;- rnorm(1, 0, sigma)\nfor (i in 2:n) {\n  log_R[i] &lt;- phi * log_R[i-1] + rnorm(1, 0, sigma)\n}\ndata &lt;- tibble(t = 1:n, R = exp(log_R))\n\nggplot(data, aes(x = t, y = R)) +\n  geom_line() +\n  labs(title = \"Simulated data from an exponentiated AR(1) model\",\n       x = \"Time\",\n       y = \"R\")\n\n\n\n\n\n\n\n\n\n\n\nHowever, we probably don’t want a model which is biased towards a reproduction number of 1 (unless we have good reason to believe that is the expected behaviour). So what should we do?\nReturning to the idea that the reproduction number is a non-stationary time series, as we have a trend in the reproduction number we want to capture, we can use a method from the field of time series analysis called differencing to make the time series stationary. This involves taking the difference between consecutive values in the time series. For the log-transformed reproduction number, this would be:\n\\[\nlog(R_t) - log(R_{t-1}) = \\phi (log(R_{t-1}) - log(R_{t-2})) + \\epsilon_t\n\\]\n\n\n\n\n\n\nWhat behaviour would we expect from this model?\n\n\n\n\n\nAgain we look at an R function that implements this model:\n\nsource(here(\"functions\", \"geometric-diff-ar.r\"))\ngeometric_diff_ar\n\nfunction (init, noise, std, damp) \n{\n    n &lt;- length(noise) + 1\n    x &lt;- numeric(n)\n    x[1] &lt;- init\n    x[2] &lt;- x[1] + noise[1] * std\n    for (i in 3:n) {\n        x[i] &lt;- x[i - 1] + damp * (x[i - 1] - x[i - 2]) + noise[i - \n            1] * std\n    }\n    return(exp(x))\n}\n\n\nWe can use this function to simulate a differenced random walk:\n\nlog_R &lt;- geometric_diff_ar(init = 1, noise = rnorm(100), std = 0.1, damp = 0.1)\n\ndata &lt;- tibble(t = seq_along(log_R), R = exp(log_R))\n\nggplot(data, aes(x = t, y = R)) +\n  geom_line() +\n  labs(title = \"Simulated data from an exponentiated AR(1) model with differencing\",\n       x = \"Time\",\n       y = \"R\")\n\n\n\n\n\n\n\n\n\n\n\nWe’ve coded up a model that uses this random walk as a stan model in stan/statistical-r.stan. See stan/functions/geometic_diff_ar.stan for the function which calculates the reproduction number. Lets load the model:\n\nstat_mod &lt;- cmdstan_model(here(\"stan/statistical-r.stan\"))\nstat_mod\n\n 1: functions {\n 2:   #include \"functions/convolve_with_delay.stan\"\n 3:   #include \"functions/renewal.stan\"\n 4:   #include \"functions/geometric_diff_ar.stan\"\n 5: }\n 6: \n 7: data {\n 8:   int n;                // number of days\n 9:   int I0;              // number initially infected\n10:   array[n] int obs;     // observed symptom onsets\n11:   int gen_time_max;     // maximum generation time\n12:   array[gen_time_max] real gen_time_pmf;  // pmf of generation time distribution\n13:   int&lt;lower = 1&gt; ip_max; // max incubation period\n14:   array[ip_max + 1] real ip_pmf;\n15:   int h;                // number of days to forecast\n16: }\n17: \n18: transformed data {\n19:    int m = n + h;\n20: }\n21: \n22: parameters {\n23:   real init_R;         // initial reproduction number\n24:   array[m-1] real rw_noise; // random walk noise\n25:   real&lt;lower = 0&gt; rw_sd; // random walk standard deviation\n26:   real&lt;lower = 0, upper = 1&gt; damp; // damping\n27: }\n28: \n29: transformed parameters {\n30:   array[m] real R = geometric_diff_ar(init_R, rw_noise, rw_sd, damp);\n31:   array[m] real &lt;upper = 1e5&gt; infections = renewal(I0, R, gen_time_pmf);\n32:   array[m] real onsets = convolve_with_delay(infections, ip_pmf);\n33: }\n34: \n35: model {\n36:   // priors\n37:   init_R ~ normal(-.1, 0.5); // Approximately Normal(1, 0.5)\n38:   rw_noise ~ std_normal();\n39:   rw_sd ~ normal(0, 0.01) T[0,];\n40:   damp ~ normal(0.9, 0.2) T[0, 1];\n41:   obs ~ poisson(onsets[1:n]);\n42: }\n43: \n44: generated quantities {\n45:   array[h] real forecast;\n46:   if (h &gt; 0) {\n47:     for (i in 1:h) {\n48:       forecast[i] = poisson_rng(onsets[n + i]);\n49:     }\n50:   }\n51: }",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#visualising-your-forecast",
    "href": "sessions/forecasting-models.html#visualising-your-forecast",
    "title": "Forecasting models",
    "section": "Visualising your forecast",
    "text": "Visualising your forecast\n\nforecasts |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_line(aes(y = .value, group = interaction(.draw, target_day), col = target_day), alpha = 0.1) +\n  geom_point(data = onset_df |&gt;\n    filter(day &gt;= 21),\n    aes(x = day, y = onsets), color = \"black\") +\n  scale_color_binned(type = \"viridis\") +\n  facet_wrap(~model) +\n  lims(y = c(0, 500))\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nAs for the single forecast it is helpful to also plot the forecast on the log scale.\n\nforecasts |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_line(aes(y = .value, group = interaction(.draw, target_day), col = target_day), alpha = 0.1) +\n  geom_point(data = onset_df, aes(x = day, y = onsets), color = \"black\") +\n  scale_y_log10(limits = c(NA, 500)) +\n  scale_color_binned(type = \"viridis\") +\n  facet_wrap(~model)\n\nWarning in scale_y_log10(limits = c(NA, 500)): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\nWarning: Removed 13 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nHow do these forecasts compare? Which do you prefer?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHow do these forecasts compare?\n\nThe more mechanistic model captures the downturn in the data very well.\nPast the peak all models were comparable.\nThe more statistical model does a very poor job of capturing the downturn in the data extending the current trend.\nThe more statistical model is more uncertain than the mechanistic model but less uncertain than the random walk.\n\nWhich do you prefer?\n\nThe more mechanistic model seems to be the best at capturing the downturn in the data and the uncertainty in the forecasts seems reasonable.",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#scoring-your-forecast",
    "href": "sessions/forecasting-models.html#scoring-your-forecast",
    "title": "Forecasting models",
    "section": "Scoring your forecast",
    "text": "Scoring your forecast\n\nsc_forecasts &lt;- forecasts |&gt;\n  left_join(onset_df, by = \"day\") |&gt;\n  filter(!is.na(.value)) |&gt;\n  as_forecast(\n    forecast_unit = c(\"target_day\", \"horizon\", \"model\"),\n    forecast_type = \"sample\",\n    observed = \"onsets\",\n    predicted = \".value\",\n    model = \"model\",\n    sample_id = \".draw\"\n  )\nsc_forecasts\n\nForecast type: sample\n\n\nForecast unit:\n\n\ntarget_day, horizon, and model\n\n\n\n        sample_id predicted observed target_day horizon       model\n            &lt;int&gt;     &lt;num&gt;    &lt;int&gt;      &lt;num&gt;   &lt;int&gt;      &lt;char&gt;\n     1:         1         4        3         22       1 Random walk\n     2:         2         2        3         22       1 Random walk\n     3:         3         2        3         22       1 Random walk\n     4:         4         6        3         22       1 Random walk\n     5:         5         2        3         22       1 Random walk\n    ---                                                            \n671996:       996         1        7        127      14 Mechanistic\n671997:       997         7        7        127      14 Mechanistic\n671998:       998         2        7        127      14 Mechanistic\n671999:       999         1        7        127      14 Mechanistic\n672000:      1000         5        7        127      14 Mechanistic\n\n\nEverything seems to be in order. We can now use the scoringutils package to calculate some metrics as we did in the forecasting concepts session.\n\nsc_scores &lt;- sc_forecasts |&gt;\n  score()\n\nsc_scores\n\n     target_day horizon       model   bias      dss     crps log_score    mad\n          &lt;num&gt;   &lt;int&gt;      &lt;char&gt;  &lt;num&gt;    &lt;num&gt;    &lt;num&gt;     &lt;num&gt;  &lt;num&gt;\n  1:         22       1 Random walk  0.043 1.540881 0.469424  1.655610 1.4826\n  2:         22       2 Random walk  0.556 2.391756 0.950522  1.851434 2.9652\n  3:         22       3 Random walk  0.328 2.194804 0.738624  1.842254 2.9652\n  4:         22       4 Random walk  0.687 3.231981 1.570469  2.175798 2.9652\n  5:         22       5 Random walk  0.767 3.750147 2.172579  2.489797 2.9652\n ---                                                                         \n668:        127      10 Mechanistic  0.509 2.013433 0.809048  1.802981 1.4826\n669:        127      11 Mechanistic  0.680 2.464343 1.158455  1.845716 1.4826\n670:        127      12 Mechanistic  0.974 4.875547 2.604446  3.415057 1.4826\n671:        127      13 Mechanistic  0.084 1.249373 0.408800  1.462535 1.4826\n672:        127      14 Mechanistic -0.956 6.383069 3.065386  3.692003 1.4826\n     ae_median   se_mean\n         &lt;num&gt;     &lt;num&gt;\n  1:         0  0.155236\n  2:         2  3.655744\n  3:         1  1.898884\n  4:         3  9.284209\n  5:         3 15.327225\n ---                    \n668:         1  2.292196\n669:         2  4.313929\n670:         3 13.704804\n671:         0  0.119716\n672:         4 15.904144\n\n\n\nAt a glance\nLet’s summarise the scores by model first.\n\nsc_scores |&gt;\n  summarise_scores(by = \"model\")\n\n         model      bias      dss      crps log_score       mad ae_median\n        &lt;char&gt;     &lt;num&gt;    &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;\n1: Random walk 0.2602411 6.387998 13.804122  3.980707 18.251203 18.522321\n2: Statistical 0.3075893 6.247106 13.833699  3.983604 16.364859 18.415179\n3: Mechanistic 0.2600536 5.615946  6.490944  3.705884  8.511712  9.035714\n     se_mean\n       &lt;num&gt;\n1: 1578.2811\n2: 1504.3416\n3:  196.7022\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nBefore we look in detail at the scores, what do you think the scores are telling you? Which model do you think is best?\n\n\n\n\nContinuous ranked probability score\nAs in the forecasting concepts session, we will start by looking at the CRPS by horizon and forecast date.\n\n\n\n\n\n\nReminder: Key things to note about the CRPS\n\n\n\n\nSmall values are better\nAs it is an absolute scoring rule it can be difficult to use to compare forecasts across scales.\n\n\n\nFirst by forecast horizon.\n\nsc_scores |&gt;\n  summarise_scores(by = c(\"model\", \"horizon\")) |&gt;\n  ggplot(aes(x = horizon, y = crps, col = model)) +\n  geom_point()\n\n\n\n\n\n\n\n\nand across different forecast dates\n\nsc_scores |&gt;\n  summarise_scores(by = c(\"target_day\", \"model\")) |&gt;\n  ggplot(aes(x = target_day, y = crps, col = model)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nHow do the CRPS scores change based on forecast date? How do the CRPS scores change with forecast horizon?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHow do the CRPS scores change based on forecast horizon?\n\nAll models have increasing CRPS with forecast horizon.\nThe more mechanistic model has the lowest CRPS at all forecast horizon.\nThe more stastical model forms notably worse at all forecast horizons.\n\nHow do the CRPS scores change with forecast date?\n\nThe more statistical model does particularly poorly around the peak of the outbreak.\nThe more mechanistic model does particularly well around the peak of the outbreak versus all other models\n\n\n\n\n\n\nPIT histograms\n\n\n\n\n\n\nReminder: Interpreting the PIT histogram\n\n\n\n\nIdeally PIT histograms should be uniform.\nIf is a U shape then the model is overconfident and if it is an inverted U shape then the model is underconfident.\nIf it is skewed then the model is biased towards the direction of the skew.\n\n\n\nLet’s first look at the overall PIT histogram.\n\n sc_forecasts |&gt;\n  get_pit(by = \"model\") |&gt;\n  plot_pit() +\n  facet_wrap(~model)\n\n\n\n\n\n\n\n\nAs before let’s look at the PIT histogram by forecast horizon (to save space we will group horizons)\n\nsc_forecasts |&gt; \n  mutate(group_horizon = case_when(\n    horizon &lt;= 3 ~ \"1-3\",\n    horizon &lt;= 7 ~ \"4-7\",\n    horizon &lt;= 14 ~ \"8-14\"\n  )) |&gt;\n  get_pit(by = c(\"model\", \"group_horizon\")) |&gt;\n  plot_pit() +\n  facet_grid(vars(model), vars(group_horizon))\n\n\n\n\n\n\n\n\nand then for different forecast dates.\n\n sc_forecasts |&gt;\n  get_pit(by = c(\"model\", \"target_day\")) |&gt;\n  plot_pit() +\n  facet_grid(vars(model), vars(target_day))\n\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nWhat do you think of the PIT histograms?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhat do you think of the PIT histograms?\n\nThe more mechanistic model is reasonably well calibrated but has a tendency to underpredict.\nBoth the random walk and more statistical model are biased towards overpredicting with the more statistical model also being poorly calibrated (liable to both under and overpredict).\nAcross horizons the more mechanistic model is only liable to underpredict at the longest horizons.\nSimilarly, the statistical and random walk models are more biased at longer horizons.\nThe forecast date stratified PIT histograms are hard to interpret but the more mechanistic model seems to be the best calibrated across forecast date.",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/forecasting-models.html#scoring-on-the-log-scale",
    "href": "sessions/forecasting-models.html#scoring-on-the-log-scale",
    "title": "Forecasting models",
    "section": "Scoring on the log scale",
    "text": "Scoring on the log scale\nAgain as in the forecasting concepts session, we will also score the forecasts on the log scale.\n\nlog_sc_forecasts &lt;- sc_forecasts |&gt;\n  transform_forecasts(\n    fun = log_shift,\n    offset = 1,\n    append = FALSE\n  )\n\nlog_sc_scores &lt;- log_sc_forecasts |&gt;\n  score()\n\n\n\n\n\n\n\nTip\n\n\n\nReminder: For more on scoring on the log scale see Scoring forecasts on transformed scales.\n\n\n\nAt a glance\n\nlog_sc_scores |&gt;\n  summarise_scores(by = \"model\")\n\n         model      bias        dss      crps log_score       mad ae_median\n        &lt;char&gt;     &lt;num&gt;      &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;\n1: Random walk 0.2202500 -0.5437929 0.2430521 0.5758656 0.3761217 0.3308532\n2: Statistical 0.2669464 -0.3897250 0.2464576 0.5991320 0.3302442 0.3410720\n3: Mechanistic 0.2189554 -1.0162121 0.2116730 0.2931774 0.2182572 0.2914358\n     se_mean\n       &lt;num&gt;\n1: 0.2015962\n2: 0.2116263\n3: 0.1764724\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nBefore we look in detail at the scores, what do you think the scores are telling you? Which model do you think is best?\n\n\n\n\nCRPS\n\nlog_sc_scores |&gt;\n  summarise_scores(by = c(\"model\", \"horizon\")) |&gt;\n  ggplot(aes(x = horizon, y = crps, col = model)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nlog_sc_scores |&gt;\n  summarise_scores(by = c(\"target_day\", \"model\")) |&gt;\n  ggplot(aes(x = target_day, y = crps, col = model)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nHow do the CRPS scores on the log scale compare to the scores on the original scale?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe random walk and more mechanistic models have much similar performance.\nEven at the peak this is true as the log scale approach more evenly weights the over and underpredictions.\nThe more statistical model is still notably worse than the other models.\nIn particular, it is much worse at the peak of the outbreak and at longer horizons.\n\n\n\n\n\n\nPIT histograms\n\n log_sc_forecasts |&gt;\n  get_pit(by = \"model\") |&gt;\n  plot_pit() +\n  facet_wrap(~model)\n\n\n\n\n\n\n\n\n\nlog_sc_forecasts |&gt; \n  mutate(group_horizon = case_when(\n    horizon &lt;= 3 ~ \"1-3\",\n    horizon &lt;= 7 ~ \"4-7\",\n    horizon &lt;= 14 ~ \"8-14\"\n  )) |&gt;\n  get_pit(by = c(\"model\", \"group_horizon\")) |&gt;\n  plot_pit() +\n  facet_grid(vars(model), vars(group_horizon))\n\n\n\n\n\n\n\n\n\n log_sc_forecasts |&gt;\n  get_pit(by = c(\"model\", \"target_day\")) |&gt;\n  plot_pit() +\n  facet_grid(vars(model), vars(target_day))\n\nWarning: Removed 18 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nWhat do you think of the PIT histograms?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhat do you think of the PIT histograms? - The PIT histograms are similar to the original scale PIT histograms.",
    "crumbs": [
      "Forecasting models"
    ]
  },
  {
    "objectID": "sessions/end-of-course-summary-and-discussion.html",
    "href": "sessions/end-of-course-summary-and-discussion.html",
    "title": "End of course summary and discussion",
    "section": "",
    "text": "End of course summary\nFor any questions or comments about please feel free to use the course discussion board.",
    "crumbs": [
      "End of course summary and discussion"
    ]
  },
  {
    "objectID": "sessions/end-of-course-summary-and-discussion.html#further-reading",
    "href": "sessions/end-of-course-summary-and-discussion.html#further-reading",
    "title": "End of course summary and discussion",
    "section": "Further reading",
    "text": "Further reading\nThe following is a highly subjective list of papers we would recommend to read for those interested in engaging further with the topics discussed here.\n\nDelay estimation\n\nPark et al., Estimating epidemiological delay distributions for infectious diseases.\nCharniga et al., Best practices for estimating and reporting epidemiological delay distributions of infectious diseases using public health surveillance and healthcare data.\n\n\n\n\\(R_t\\) estimation\n\nGostic et al., Practical considerations for measuring the effective reproductive number, \\(R_t\\).\nBrockhaus et al., Why are different estimates of the effective reproductive number so different? A case study on COVID-19 in Germany.\n\n\n\nNowcasting\n\nWolffram et al., Collaborative nowcasting of COVID-19 hospitalization incidences in Germany.\nLison et al., Generative Bayesian modeling to nowcast the effective reproduction number from line list data with missing symptom onset dates.\nStoner et al., A Powerful Modelling Framework for Nowcasting and Forecasting COVID-19 and Other Diseases.\n\n\n\nForecasting\n\nFunk et al., Assessing the performance of real-time epidemic forecasts: A case study of Ebola in the Western Area region of Sierra Leone, 2014-15.\nHeld et al, Probabilistic forecasting in infectious disease epidemiology: the 13th Armitage lecture.\nLopez et al., Challenges of COVID-19 Case Forecasting in the US, 2020-2021.\nSherratt et al., Predictive performance of multi-model ensemble forecasts of COVID-19 across European nations.\nAsher, Forecasting Ebola with a regression transmission model.\nHyndman and Athanasopoulos, Forecasting: Principles and Practice (free online text book).",
    "crumbs": [
      "End of course summary and discussion"
    ]
  },
  {
    "objectID": "sessions/biases-in-delay-distributions.html",
    "href": "sessions/biases-in-delay-distributions.html",
    "title": "Biases in delay distributions",
    "section": "",
    "text": "So far, we’ve looked at the uncertainty of the time delays between epidemiological events. The next challenge is that our information on these delays is usually biased, especially when we’re analysing data in real time. We’ll consider two types of biases that commonly occur in reported infectious disease data:\n\nCensoring: when we know an event occurred at some time, but not exactly when.\nTruncation: when not enough time has passed for all the relevant epidemiological events to occur or be observed.\n\nWe can again handle these by including them as uncertain parameters in the modelling process.\n\n\nIntroduction to biases in epidemiological delays\n\n\n\nIn this session, we’ll introduce censoring and right truncation as typical properties of infectious disease data sets, using the delay from symptom onset to hospitalisation as an example.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/biases-in-delay-distributions.qmd.\n\n\n\nIn this session we will use the nfidd package to load a data set of infection times, the ggplot2 package for plotting, the dplyr and tidyr packages to wrangle data, the lubridate package to deal with dates, the here package to find the stan models, and the cmdstanr package for using stan.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"lubridate\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Biases in delay distributions"
    ]
  },
  {
    "objectID": "sessions/biases-in-delay-distributions.html#slides",
    "href": "sessions/biases-in-delay-distributions.html#slides",
    "title": "Biases in delay distributions",
    "section": "",
    "text": "Introduction to biases in epidemiological delays",
    "crumbs": [
      "Biases in delay distributions"
    ]
  },
  {
    "objectID": "sessions/biases-in-delay-distributions.html#objectives",
    "href": "sessions/biases-in-delay-distributions.html#objectives",
    "title": "Biases in delay distributions",
    "section": "",
    "text": "In this session, we’ll introduce censoring and right truncation as typical properties of infectious disease data sets, using the delay from symptom onset to hospitalisation as an example.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/biases-in-delay-distributions.qmd.\n\n\n\nIn this session we will use the nfidd package to load a data set of infection times, the ggplot2 package for plotting, the dplyr and tidyr packages to wrangle data, the lubridate package to deal with dates, the here package to find the stan models, and the cmdstanr package for using stan.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"lubridate\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Biases in delay distributions"
    ]
  },
  {
    "objectID": "sessions/biases-in-delay-distributions.html#source-file",
    "href": "sessions/biases-in-delay-distributions.html#source-file",
    "title": "Biases in delay distributions",
    "section": "",
    "text": "The source file of this session is located at sessions/biases-in-delay-distributions.qmd.",
    "crumbs": [
      "Biases in delay distributions"
    ]
  },
  {
    "objectID": "sessions/biases-in-delay-distributions.html#libraries-used",
    "href": "sessions/biases-in-delay-distributions.html#libraries-used",
    "title": "Biases in delay distributions",
    "section": "",
    "text": "In this session we will use the nfidd package to load a data set of infection times, the ggplot2 package for plotting, the dplyr and tidyr packages to wrangle data, the lubridate package to deal with dates, the here package to find the stan models, and the cmdstanr package for using stan.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"lubridate\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "Biases in delay distributions"
    ]
  },
  {
    "objectID": "sessions/biases-in-delay-distributions.html#initialisation",
    "href": "sessions/biases-in-delay-distributions.html#initialisation",
    "title": "Biases in delay distributions",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Biases in delay distributions"
    ]
  },
  {
    "objectID": "sessions/biases-in-delay-distributions.html#estimating-delay-distributions-accounting-for-censoring",
    "href": "sessions/biases-in-delay-distributions.html#estimating-delay-distributions-accounting-for-censoring",
    "title": "Biases in delay distributions",
    "section": "Estimating delay distributions accounting for censoring",
    "text": "Estimating delay distributions accounting for censoring\nLet’s estimate the time from symptom onset to hospitalisation with the censored data.\nA naïve approach to estimating the delay would be to ignore the fact that the data are censored. To estimate the delay from onset to hospitalisation, we could just use the difference between the censored times, which is an integer (the number of days).\n\ndf_dates &lt;- df_dates |&gt;\n  mutate(\n    incubation_period = onset_time - infection_time,\n    onset_to_hosp = hosp_time - onset_time\n  )\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nFit the lognormal model used in the session on delay distributions to the estimates from the rounded data, i.e. using the df_dates data set. Do you still recover the parameters that we put in?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmod &lt;- cmdstan_model(here(\"stan\", \"lognormal.stan\"))\nres &lt;- mod$sample(\n  data = list(\n    n = nrow(na.omit(df_dates)),\n    y = na.omit(df_dates)$onset_to_hosp\n  )\n)\n\n\nres\n\n variable     mean   median   sd  mad       q5      q95 rhat ess_bulk ess_tail\n  lp__    -1320.95 -1320.65 1.04 0.73 -1323.06 -1319.98 1.00     1835     2119\n  meanlog     1.73     1.73 0.01 0.01     1.71     1.75 1.00     3632     2559\n  sdlog       0.50     0.50 0.01 0.01     0.49     0.52 1.00     3125     2196\n\n\nUsually the estimates will be further from the “true” parameters than before when we worked with the unrounded data.\n\n\n\nTo account for double interval censoring, we need to modify the model to include the fact that we don’t know when exactly on any given day the event happened. For example, if we know that symptom onset of an individual occurred on 20 June, 2024, and they were admitted to hospital on 22 June, 2024, this could mean an onset-to-hospitalisation delay from 1 day (onset at 23:59 on the 20th, admitted at 0:01 on the 22nd) to 3 days (onset at 0:01 on the 20th, admitted at 23:59 on the 22nd).\nWe can use this in our delay estimation by making the exact time of the events based on the dates given part of the estimation procedure:\n\ncmod &lt;- cmdstan_model(here(\"stan\", \"censored-delay-model.stan\"))\ncmod\n\n 1: data {\n 2:   int&lt;lower = 0&gt; n;\n 3:   array[n] int&lt;lower = 1&gt; onset_to_hosp;\n 4: }\n 5: \n 6: parameters {\n 7:   real meanlog;\n 8:   real&lt;lower = 0&gt; sdlog;\n 9:   array[n] real&lt;lower = 0, upper = 1&gt; onset_day_time;\n10:   array[n] real&lt;lower = 0, upper = 1&gt; hosp_day_time;\n11: }\n12: \n13: transformed parameters {\n14:   array[n] real&lt;lower = 0&gt; true_onset_to_hosp;\n15:   for (i in 1:n) {\n16:     true_onset_to_hosp[i] =\n17:       onset_to_hosp[i] + hosp_day_time[i] - onset_day_time[i];\n18:   }\n19: }\n20: \n21: model {\n22:   meanlog ~ normal(0, 10);\n23:   sdlog ~ normal(0, 10) T[0, ];\n24:   onset_day_time ~ uniform(0, 1);\n25:   hosp_day_time ~ uniform(0, 1);\n26: \n27:   true_onset_to_hosp ~ lognormal(meanlog, sdlog);\n28: }\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nFamiliarise yourself with the model above. Do you understand all the lines? Which line(s) define the parameter prior distribution(s), which one(s) the likelihood, and which one(s) reflect that we have now provided the delay as the difference in integer days?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLines 21-24 define the parametric prior distributions (for parameters meanlog and sdlog, and the estimates of exact times of events). Line 27 defines the likelihood. Lines 15-17 reflect the integer delays, adjusted by the estimated times of day.\n\n\n\nNow we can use this model to re-estimate the parameters of the delay distribution:\n\ncres &lt;- cmod$sample(\n  data = list(\n    n = nrow(na.omit(df_dates)),\n    onset_to_hosp = na.omit(df_dates)$onset_to_hosp\n  )\n)\n\n\ncres\n\n          variable      mean    median    sd   mad        q5       q95 rhat\n lp__              -11577.05 -11576.00 50.45 50.41 -11660.30 -11495.89 1.00\n meanlog                1.73      1.73  0.01  0.01      1.72      1.75 1.00\n sdlog                  0.49      0.49  0.01  0.01      0.48      0.51 1.00\n onset_day_time[1]      0.46      0.45  0.29  0.37      0.04      0.94 1.00\n onset_day_time[2]      0.52      0.53  0.29  0.36      0.06      0.95 1.00\n onset_day_time[3]      0.52      0.53  0.29  0.37      0.06      0.95 1.00\n onset_day_time[4]      0.51      0.52  0.28  0.37      0.06      0.94 1.00\n onset_day_time[5]      0.45      0.43  0.28  0.35      0.04      0.93 1.00\n onset_day_time[6]      0.52      0.53  0.29  0.38      0.05      0.96 1.00\n onset_day_time[7]      0.46      0.44  0.28  0.34      0.04      0.94 1.00\n ess_bulk ess_tail\n     1209     2097\n     9905     3174\n     9025     2800\n     8925     2490\n     9245     2313\n     9583     2204\n     9576     2646\n     7395     2579\n     9724     2315\n     8396     2241\n\n # showing 10 of 5394 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\n\n\n\n\n\n\nTake 10 minutes\n\n\n\nTry re-simulating the delays using different parameters of the delay distribution. Can you establish under which conditions the bias in estimation gets worse?",
    "crumbs": [
      "Biases in delay distributions"
    ]
  },
  {
    "objectID": "sessions/biases-in-delay-distributions.html#estimating-delay-distributions-accounting-for-truncation",
    "href": "sessions/biases-in-delay-distributions.html#estimating-delay-distributions-accounting-for-truncation",
    "title": "Biases in delay distributions",
    "section": "Estimating delay distributions accounting for truncation",
    "text": "Estimating delay distributions accounting for truncation\nIf we take the naïve mean of delays we get an underestimate as expected:\n\n# truncated mean delay\nmean(df_realtime$onset_to_hosp)\n\n[1] 5.952562\n\n# compare with the mean delay over the full outbreak\nmean(df$hosp_time - df$onset_time, na.rm=TRUE)\n\n[1] 6.382549\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nFit the lognormal model used above to the estimates from the truncated data, i.e. using the df_realtime data set. How far away from the “true” parameters do you end up?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nres &lt;- mod$sample(\n  data = list(\n    n = nrow(na.omit(df_realtime)),\n    y = na.omit(df_realtime)$onset_to_hosp\n  )\n)\n\n\nres\n\n variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n  lp__    -141.74 -141.43 1.02 0.73 -143.85 -140.79 1.00     1774     2561\n  meanlog    1.67    1.67 0.03 0.03    1.62    1.73 1.00     3170     2444\n  sdlog      0.47    0.47 0.02 0.02    0.43    0.51 1.00     3175     2330\n\n\n\n\n\nOnce again, we can write a model that adjusts for truncation, by re-creating the simulated truncation effect in the stan model:\n\ntmod &lt;- cmdstan_model(here(\"stan\", \"truncated-delay-model.stan\"))\ntmod\n\n 1: data {\n 2:   int&lt;lower = 0&gt; n;\n 3:   array[n] real&lt;lower = 0&gt; onset_to_hosp;\n 4:   array[n] real&lt;lower = 0&gt; time_since_onset;\n 5: }\n 6: \n 7: parameters {\n 8:   real meanlog;\n 9:   real&lt;lower = 0&gt; sdlog;\n10: }\n11: \n12: model {\n13:   meanlog ~ normal(0, 10);\n14:   sdlog ~ normal(0, 10) T[0, ];\n15: \n16:   for (i in 1:n) {\n17:     onset_to_hosp[i] ~ lognormal(meanlog, sdlog) T[0, time_since_onset[i]];\n18:   }\n19: }\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nFamiliarise yourself with the model above. Which line introduces the truncation, i.e. the fact that we have not been able to observe hospitalisation times beyond the cutoff of (here) 70 days?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLine 17 defines the upper limit of onset_to_hosp as time_since_onset.\n\n\n\nNow we can use this model to re-estimate the parameters of the delay distribution:\n\ntres &lt;- tmod$sample(\n  data = list(\n    n = nrow(df_realtime),\n    onset_to_hosp = df_realtime$onset_to_hosp, \n    time_since_onset = 70 - df_realtime$onset_time\n  )\n)\n\n\ntres\n\n variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n  lp__    -115.63 -115.31 1.01 0.73 -117.57 -114.66 1.00     1915     1921\n  meanlog    1.77    1.77 0.04 0.04    1.70    1.84 1.00     2074     2009\n  sdlog      0.50    0.50 0.03 0.03    0.46    0.56 1.00     1889     2030\n\n\n\n\n\n\n\n\nTake 10 minutes\n\n\n\nTry re-simulating the delays using different parameters of the delay distribution. Can you establish under which conditions the bias in estimation gets worse?",
    "crumbs": [
      "Biases in delay distributions"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html",
    "href": "sessions/R-Stan-and-statistical-concepts.html",
    "title": "Probability distributions and parameter estimation",
    "section": "",
    "text": "Many important characteristics, or parameters, of epidemiological processes are not fully observed - and are therefore uncertain. For example, in this course this might include time delays, reproduction numbers, or case numbers now and in the future. We can specify the shape of uncertainty around a specific parameter using a probability distribution.\nWe’ll want to correctly specify this uncertainty. We can do this best by combining our own prior understanding with the data that we have available. In this course, we’ll use this Bayesian approach to modelling. A useful tool for creating these models is the stan probabilistic programming language.\n\n\n\nIntroduction to statistical concepts used in the course\nIntroduction to stan concepts used in the course\n\n\n\n\nThe aim of this session is to introduce the concept of probability distributions and how to estimate their parameters using Bayesian inference with stan.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/R-Stan-and-statistical-concepts.qmd.\n\n\n\nIn this session we will use the ggplot2 library for plotting, the here library to reference files, for example, the stan model, and the cmdstanr library for using stan. We will also use the bayesplot and posterior packages to investigate the results of the inference conducted with stan.\n\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"bayesplot\")\nlibrary(\"posterior\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html#slides",
    "href": "sessions/R-Stan-and-statistical-concepts.html#slides",
    "title": "Probability distributions and parameter estimation",
    "section": "",
    "text": "Introduction to statistical concepts used in the course\nIntroduction to stan concepts used in the course",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html#objectives",
    "href": "sessions/R-Stan-and-statistical-concepts.html#objectives",
    "title": "Probability distributions and parameter estimation",
    "section": "",
    "text": "The aim of this session is to introduce the concept of probability distributions and how to estimate their parameters using Bayesian inference with stan.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/R-Stan-and-statistical-concepts.qmd.\n\n\n\nIn this session we will use the ggplot2 library for plotting, the here library to reference files, for example, the stan model, and the cmdstanr library for using stan. We will also use the bayesplot and posterior packages to investigate the results of the inference conducted with stan.\n\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"bayesplot\")\nlibrary(\"posterior\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html#source-file",
    "href": "sessions/R-Stan-and-statistical-concepts.html#source-file",
    "title": "Probability distributions and parameter estimation",
    "section": "",
    "text": "The source file of this session is located at sessions/R-Stan-and-statistical-concepts.qmd.",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html#libraries-used",
    "href": "sessions/R-Stan-and-statistical-concepts.html#libraries-used",
    "title": "Probability distributions and parameter estimation",
    "section": "",
    "text": "In this session we will use the ggplot2 library for plotting, the here library to reference files, for example, the stan model, and the cmdstanr library for using stan. We will also use the bayesplot and posterior packages to investigate the results of the inference conducted with stan.\n\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"bayesplot\")\nlibrary(\"posterior\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html#initialisation",
    "href": "sessions/R-Stan-and-statistical-concepts.html#initialisation",
    "title": "Probability distributions and parameter estimation",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html#estimating-the-parameters-of-probability-distributions",
    "href": "sessions/R-Stan-and-statistical-concepts.html#estimating-the-parameters-of-probability-distributions",
    "title": "Probability distributions and parameter estimation",
    "section": "Estimating the parameters of probability distributions",
    "text": "Estimating the parameters of probability distributions\nWe will now use stan to estimate the parameters of the probability distribution. To do so, we first load in the model.\n\n### load gamma model from the session directory\nmod &lt;- cmdstan_model(here(\"stan\", \"gamma.stan\"))\n### show model code\nmod\n\n 1: // gamma_model.stan\n 2: data {\n 3:   int&lt;lower=0&gt; N;\n 4:   array[N] real y;\n 5: }\n 6: \n 7: parameters {\n 8:   real&lt;lower=0&gt; alpha;\n 9:   real&lt;lower=0&gt; beta;\n10: }\n11: \n12: model {\n13:   alpha ~ normal(0, 10) T[0,];\n14:   beta ~ normal(0, 10) T[0,];\n15:   y ~ gamma(alpha, beta);\n16: }\n\n\n\n\n\n\n\n\nArrays in stan\n\n\n\nOn line 4 there is a data declaration starting with array[n]. This declares an array of size n of the type given afterwards (here: real). Arrays work in a similar way as arrays or vectors in R and its elements be accessed with the bracket operator [. For example, to get the third element of the array y you would write y[3].\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nFamilarise yourself with the model above. Do you understand all the lines? Which line(s) define the parameter prior distribution(s), which one(s) the likelihood, and which one(s) the data that has to be supplied to the model?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLines 13 and 14 define the parametric prior distributions (for parameters alpha and beta). Line 15 defines the likelihood. Lines 3 and 4 define the data that has to be supplied to the model.\n\n\n\nWe use the model we have defined in conjunction with the gamma distributed random numbers generated earlier to see if we can recover the parameters of the gamma distribution used. Once you have familiarised yourself with the model, use the sample() function to fit the model.\n\nstan_data &lt;- list(\n  N = length(gammas),\n  y = gammas\n)\ngamma_fit &lt;- mod$sample(data = stan_data)\n\n\n\n\n\n\n\nPassing data to the stan model\n\n\n\nThe stan_data object is a list with elements that will is passed to the stan model as the data argument to sample. The names and types of the elements need to correspond to the data block in the model (see lines 3 and 4 in the model). Here, we pass the length of gammas as N and the vector gammas itself as y.\n\n\n\n\n\n\n\n\nStan messages\n\n\n\nThemod$sample command will produce a lot of messages which we have suppressed above. This is fine and intended to keep the user informed about any issues as well as general progress with the inference. This will come in handy later in the course when we fit more complicated models that can take a little while to run.\n\n\nIn order to view a summary of the posterior samples generated, use\n\ngamma_fit\n\n variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n    lp__  -151.10 -150.82 0.97 0.72 -152.99 -150.17 1.00     1363     1609\n    alpha   17.92   17.82 2.33 2.33   14.22   21.82 1.00      723      847\n    beta     3.60    3.58 0.48 0.48    2.84    4.41 1.00      720      847\n\n\nYou can see that the estimates are broadly consistent with the parameters we specified. To investigate this further, we will conduct a so-called posterior predictive check by comparing random numbers simulated using the estimated parameters to the ones we simulated earlier.\n\n## Extract posterior draws\ngamma_posterior &lt;- as_draws_df(gamma_fit$draws())\nhead(gamma_posterior)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__ alpha beta\n1 -150    20  4.0\n2 -150    19  3.7\n3 -152    15  3.0\n4 -151    21  4.2\n5 -150    20  3.9\n6 -152    20  3.8\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n## Generate posterior predictive samples\ngamma_ppc &lt;- sapply(seq_along(gammas), function(i) {\n  rgamma(n = length(gammas),\n         shape = gamma_posterior$alpha[i],\n         rate = gamma_posterior$beta[i])\n})\n\n## Plot posterior predictive check\nppc_dens_overlay(y = gammas, yrep = gamma_ppc)\n\n\n\n\n\n\n\n\nWe can see that the random numbers generated from the posterior samples are distributed relatively evenly around the data (in black), i.e., the samples generated earlier that we fitted to.",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html#going-further",
    "href": "sessions/R-Stan-and-statistical-concepts.html#going-further",
    "title": "Probability distributions and parameter estimation",
    "section": "Going further",
    "text": "Going further\n\nFor the model above we chose truncated normal priors with a mode at 0 and standard deviation 10. If you change the parameters of the prior distributions, does it affect the results?\nYou could try the model included in lognormal.stan to estimate parameters of the lognormal distribution.",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "sessions/R-Stan-and-statistical-concepts.html#wrap-up",
    "href": "sessions/R-Stan-and-statistical-concepts.html#wrap-up",
    "title": "Probability distributions and parameter estimation",
    "section": "Wrap up",
    "text": "Wrap up",
    "crumbs": [
      "Probability distributions and parameter estimation"
    ]
  },
  {
    "objectID": "learning_objectives.html",
    "href": "learning_objectives.html",
    "title": "Independent learning outcomes",
    "section": "",
    "text": "familiarity with R concepts used in the course\n\nto be completed once the course has been fully written but likely includes functions, accessing documentation, etc.\n\nunderstanding of statistical concepts used in the course\n\nto be completed once the course has been fully written but likely includes discrete and continuous probability distributions"
  },
  {
    "objectID": "learning_objectives.html#r-and-statistical-concepts-used",
    "href": "learning_objectives.html#r-and-statistical-concepts-used",
    "title": "Independent learning outcomes",
    "section": "",
    "text": "familiarity with R concepts used in the course\n\nto be completed once the course has been fully written but likely includes functions, accessing documentation, etc.\n\nunderstanding of statistical concepts used in the course\n\nto be completed once the course has been fully written but likely includes discrete and continuous probability distributions"
  },
  {
    "objectID": "learning_objectives.html#delay-distributions",
    "href": "learning_objectives.html#delay-distributions",
    "title": "Independent learning outcomes",
    "section": "Delay distributions",
    "text": "Delay distributions\n\nunderstanding of the ubiquity of delays in epidemiological data\nunderstanding of how delays affect population-level epidemiological data via discrete convolutions\nability to apply convolutions of discrete probability distributions to epidemiological data in R"
  },
  {
    "objectID": "learning_objectives.html#biases-in-delay-distributions",
    "href": "learning_objectives.html#biases-in-delay-distributions",
    "title": "Independent learning outcomes",
    "section": "Biases in delay distributions",
    "text": "Biases in delay distributions\n\nunderstanding of how censoring affects the estimation and interpretation of epidemiological delay distributions\nability to estimate parameters of probability distributions from observed delays, taking into account censoring, using R\nunderstanding of right truncation in epidemiolgical data\nability to estimate parameters of probability distributions from observed delays, taking into account truncation, in R"
  },
  {
    "objectID": "learning_objectives.html#r-estimation-and-the-renewal-equation",
    "href": "learning_objectives.html#r-estimation-and-the-renewal-equation",
    "title": "Independent learning outcomes",
    "section": "R estimation and the renewal equation",
    "text": "R estimation and the renewal equation\n\nunderstanding of the reproduction number and challenges in its estimation\nawareness of broad categories of methods for estimating the reproduction number, including estimation from population-level data\nunderstanding of the renewal equation as an epidemiological model\nawareness of connections of the renewal equation with other epidemiological models\nfamiliarity with the generation time as a particular type of delay distributions\nability to estimate static and time-varying reproduction numbers from time-series data in R"
  },
  {
    "objectID": "learning_objectives.html#nowcasting",
    "href": "learning_objectives.html#nowcasting",
    "title": "Independent learning outcomes",
    "section": "Nowcasting",
    "text": "Nowcasting\n\nunderstanding of nowcasting as a particular right truncation problem\nAbility to perform a simple nowcast in R\nawareness of the breadth of methods to perform nowcasting\nR estimation as a nowcasting problem"
  },
  {
    "objectID": "learning_objectives.html#forecasting",
    "href": "learning_objectives.html#forecasting",
    "title": "Independent learning outcomes",
    "section": "Forecasting",
    "text": "Forecasting\n\nunderstanding of forecasting as an epidemiological problem, and its relationship with nowcasting and R estimation\nunderstanding of the difference between forecasts, projections and scenarios\nfamiliarity with common forecasting models and their properties, and applicability in epidemiology\nability to use a common forecasting model on an epidemiological time series in R\nability to use a semi-mechanistic model for forecasting an epidemiological time series in R"
  },
  {
    "objectID": "learning_objectives.html#ensemble-models",
    "href": "learning_objectives.html#ensemble-models",
    "title": "Independent learning outcomes",
    "section": "Ensemble models",
    "text": "Ensemble models\n\nunderstanding of predictive ensembles and their properties\nability to create a predictive ensemble of forecasts in R"
  },
  {
    "objectID": "learning_objectives.html#evaluating-forecasts-and-nowcasts",
    "href": "learning_objectives.html#evaluating-forecasts-and-nowcasts",
    "title": "Independent learning outcomes",
    "section": "Evaluating forecasts (and nowcasts)",
    "text": "Evaluating forecasts (and nowcasts)\n\nfamiliarity with metrics for evaluating probabilistic forecasts and their properties\nability to score probabilistic forecasts in R"
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "Getting help",
    "section": "",
    "text": "For any questions about the course or its content, feel free to use the Discussion board"
  },
  {
    "objectID": "getting-set-up.html",
    "href": "getting-set-up.html",
    "title": "Required software",
    "section": "",
    "text": "Each session in this course uses R code for demonstration. All the content is self-contained within a software package designed for the course. To get the most out of this course, you will need to use R and the following instructions to interact with the course material."
  },
  {
    "objectID": "getting-set-up.html#installation-of-the-nfiidd-package",
    "href": "getting-set-up.html#installation-of-the-nfiidd-package",
    "title": "Required software",
    "section": "Installation of the nfiidd package",
    "text": "Installation of the nfiidd package\nTo install the packages needed in the course, including the nfiidd package that contains data files used, you can use the pak package:\n\ninstall.packages(\"pak\")\npak::pak(\"nfidd/nfidd\", dependencies = \"all\", upgrade = TRUE)\n\nThen you can check that the installation completed successfully by loading the package into your R session:\n\nlibrary(\"nfidd\")"
  },
  {
    "objectID": "getting-set-up.html#installing-cmdstan",
    "href": "getting-set-up.html#installing-cmdstan",
    "title": "Required software",
    "section": "Installing cmdstan",
    "text": "Installing cmdstan\nThe course relies on running stan through the cmdstanr R package, which itself uses the cmdstan software. This requires a separate installation step:\n\ncmdstanr::install_cmdstan()\n\n\n\n\n\n\n\nNote\n\n\n\nThis may take a few minutes. Also you’re likely to see lots of warnings and other messages printed to your screen - don’t worry, this is normal and doesn’t mean there is a problem.\n\n\nIf there are any problems with this, you can try (on Windows) to fix them using\n\ncmdstanr::check_cmdstan_toolchain(fix = TRUE)\n\nYou can test that you have a working cmdstanr setup using\n\ncmdstanr::cmdstan_version()\n\n[1] \"2.35.0\"\n\n\nFor more details, and for links to resources in case something goes wrong, see the Getting Started with CmdStanr vignette of the package."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nowcasting and forecasting infectious disease dynamics",
    "section": "",
    "text": "A course and living resource for learning about nowcasting and forecasting infectious disease dynamics.\nAll the materials here are provided under MIT License. We invite people to use the materials here in their own teaching. We welcome all forms of contributions, additions and suggestions people might have for improving the materials."
  },
  {
    "objectID": "sessions.html",
    "href": "sessions.html",
    "title": "Sessions",
    "section": "",
    "text": "Monday June 24: 9.00-9.30\n\nIntroduction to the course and the instructors (10 mins)\nMotivating the course: From an epidemiological line list to informing decisions in real-time (20 mins)"
  },
  {
    "objectID": "sessions.html#session-0-introduction-and-course-overview",
    "href": "sessions.html#session-0-introduction-and-course-overview",
    "title": "Sessions",
    "section": "",
    "text": "Monday June 24: 9.00-9.30\n\nIntroduction to the course and the instructors (10 mins)\nMotivating the course: From an epidemiological line list to informing decisions in real-time (20 mins)"
  },
  {
    "objectID": "sessions.html#session-1-r-stan-and-statistical-concept-background",
    "href": "sessions.html#session-1-r-stan-and-statistical-concept-background",
    "title": "Sessions",
    "section": "Session 1: R, Stan, and statistical concept background",
    "text": "Session 1: R, Stan, and statistical concept background\nMonday June 24: 9.30-10.30\n\nIntroduction to statistical concepts used in the course (15 mins)\nIntroduction to stan concepts used in the course (15 mins)\nPractice session: introduction to estimation in stan (30 mins)"
  },
  {
    "objectID": "sessions.html#session-2-delay-distributions",
    "href": "sessions.html#session-2-delay-distributions",
    "title": "Sessions",
    "section": "Session 2: Delay distributions",
    "text": "Session 2: Delay distributions\nMonday June 24: 11.00-11.45\n\nIntroduction to epidemiological delays and how to represent them with probability distributions (10 mins)\nPractice session: simulate and estimate epidemiological delays (30 mins)\nWrap up (5 mins)"
  },
  {
    "objectID": "sessions.html#session-3-biases-in-delay-distributions",
    "href": "sessions.html#session-3-biases-in-delay-distributions",
    "title": "Sessions",
    "section": "Session 3: Biases in delay distributions",
    "text": "Session 3: Biases in delay distributions\nMonday June 24: 11.45-12.30 and 14.00-14.45\n\nIntroduction to biases in delay distributions (10 mins)\nPractice session: Simulating biases in delay distributions and estimating delays without adjustment on these data (35 mins)\nPractice session: estimating delay distributions with adjustments for bias (35 mins)\nWrap up (10 mins)"
  },
  {
    "objectID": "sessions.html#session-4-using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic",
    "href": "sessions.html#session-4-using-delay-distributions-to-model-the-data-generating-process-of-an-epidemic",
    "title": "Sessions",
    "section": "Session 4: Using delay distributions to model the data generating process of an epidemic",
    "text": "Session 4: Using delay distributions to model the data generating process of an epidemic\nMonday June 24: 14.45-15.30\n\nUsing delay distributions to model the data generating process of an epidemic (15 mins)\nPractice session: implementing a convolution model and identifying potential problems (30 mins)"
  },
  {
    "objectID": "sessions.html#session-5-r-estimation-and-the-renewal-equation",
    "href": "sessions.html#session-5-r-estimation-and-the-renewal-equation",
    "title": "Sessions",
    "section": "Session 5: R estimation and the renewal equation",
    "text": "Session 5: R estimation and the renewal equation\nMonday June 24: 16.00-17.30\n\nIntroduction to the time-varying reproduction number (10 mins)\nPractice session: using the renewal equation to estimate R (35 mins)\nPractice session: combining R estimation with delay distribution convolutions (35 mins)\nWrap up (10 mins)"
  },
  {
    "objectID": "sessions.html#session-6-nowcasting-concepts",
    "href": "sessions.html#session-6-nowcasting-concepts",
    "title": "Sessions",
    "section": "Session 6: Nowcasting concepts",
    "text": "Session 6: Nowcasting concepts\nTuesday June 25: 9.00-10.30\n\nIntroduction to nowcasting as a right-truncation problem (10 mins)\nPractice session: Simulating the delay distribution (35 mins)\nPractice session: Nowcasting using pre-estimated delay distributions (35 mins)\nWrap up (10 mins)"
  },
  {
    "objectID": "sessions.html#session-7-nowcasting-with-an-unknown-reporting-delay",
    "href": "sessions.html#session-7-nowcasting-with-an-unknown-reporting-delay",
    "title": "Sessions",
    "section": "Session 7: Nowcasting with an unknown reporting delay",
    "text": "Session 7: Nowcasting with an unknown reporting delay\nTuesday June 25: 11.00-12.30\n\nIntroduction to joint estimation of delays and nowcasts (10 mins)\nPractice session: Joint estimation of delays and nowcasts (35 mins)\nPractice session: Joint estimation of delays, nowcasts and reproduction numbers (35 mins)\nWrap up (10 mins)"
  },
  {
    "objectID": "sessions.html#session-8-forecasting-concepts",
    "href": "sessions.html#session-8-forecasting-concepts",
    "title": "Sessions",
    "section": "Session 8: Forecasting concepts",
    "text": "Session 8: Forecasting concepts\nTuesday June 25: 14.00-15.30\n\nIntroduction to forecasting as an epidemiological problem, and its relationship with nowcasting and R estimation (10 mins)\nPractice session: extending a model into the future (35 minutes)\nPractice session: evaluate your forecast (35 mins)\nWrap up (10 mins)"
  },
  {
    "objectID": "sessions.html#session-9-forecasting-models",
    "href": "sessions.html#session-9-forecasting-models",
    "title": "Sessions",
    "section": "Session 9: Forecasting models",
    "text": "Session 9: Forecasting models\nTuesday June 25: 16.00-17.30\n\nAn overview of forecasting models (10 mins)\nPractice session: Evaluating forecasts from a range of models (60 mins)\nWrap up and discussion (20 mins)"
  },
  {
    "objectID": "sessions.html#session-10-methods-in-the-real-world",
    "href": "sessions.html#session-10-methods-in-the-real-world",
    "title": "Sessions",
    "section": "Session 10: Methods in the real world",
    "text": "Session 10: Methods in the real world\nTuesday June 25: 9.00-10.30\n\nPresentations on uses of forecasts in the real world (45 mins)\nQ & A about course contents and their relationship to outbreak response work (45 mins)"
  },
  {
    "objectID": "sessions.html#session-11-overview-of-available-tools",
    "href": "sessions.html#session-11-overview-of-available-tools",
    "title": "Sessions",
    "section": "Session 11: Overview of available tools",
    "text": "Session 11: Overview of available tools\nWednesday June 26: 11.00-12.15\n\nPractice session: Choose from one an open source example, run through it, and relate it to the material in this course. (60 mins)\nWrap up and discussion (15 mins)"
  },
  {
    "objectID": "sessions.html#session-12-end-of-course-summary",
    "href": "sessions.html#session-12-end-of-course-summary",
    "title": "Sessions",
    "section": "Session 12: End of course summary",
    "text": "Session 12: End of course summary\nWednesday June 26: 12.15-12.30\n\nSummary of the course (5 mins)\nDiscussion of future directions and how to continue learning (10 mins)"
  },
  {
    "objectID": "sessions/R-estimation-and-the-renewal-equation.html",
    "href": "sessions/R-estimation-and-the-renewal-equation.html",
    "title": "R estimation and the renewal equation",
    "section": "",
    "text": "In the last session we used the idea of convolutions as a way to interpret individual time delays at a population level. In that session, we linked symptom onsets back to infections. Now we want to link infections themselves together over time, knowing that current infections were infected by past infections. Correctly capturing this transmission process is crucial to modelling infections in the present and future.\n\n\n\nIntroduction to the reproduction number\n\n\n\n\nThe aim of this session is to introduce the renewal equation as an infection generating process, and to show how it can be used to estimate a time-varying reproduction number.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/R-estimation-and-the-renewal-equation.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "R estimation and the renewal equation"
    ]
  },
  {
    "objectID": "sessions/R-estimation-and-the-renewal-equation.html#slides",
    "href": "sessions/R-estimation-and-the-renewal-equation.html#slides",
    "title": "R estimation and the renewal equation",
    "section": "",
    "text": "Introduction to the reproduction number",
    "crumbs": [
      "R estimation and the renewal equation"
    ]
  },
  {
    "objectID": "sessions/R-estimation-and-the-renewal-equation.html#objectives",
    "href": "sessions/R-estimation-and-the-renewal-equation.html#objectives",
    "title": "R estimation and the renewal equation",
    "section": "",
    "text": "The aim of this session is to introduce the renewal equation as an infection generating process, and to show how it can be used to estimate a time-varying reproduction number.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/R-estimation-and-the-renewal-equation.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "R estimation and the renewal equation"
    ]
  },
  {
    "objectID": "sessions/R-estimation-and-the-renewal-equation.html#source-file",
    "href": "sessions/R-estimation-and-the-renewal-equation.html#source-file",
    "title": "R estimation and the renewal equation",
    "section": "",
    "text": "The source file of this session is located at sessions/R-estimation-and-the-renewal-equation.qmd.",
    "crumbs": [
      "R estimation and the renewal equation"
    ]
  },
  {
    "objectID": "sessions/R-estimation-and-the-renewal-equation.html#libraries-used",
    "href": "sessions/R-estimation-and-the-renewal-equation.html#libraries-used",
    "title": "R estimation and the renewal equation",
    "section": "",
    "text": "In this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "R estimation and the renewal equation"
    ]
  },
  {
    "objectID": "sessions/R-estimation-and-the-renewal-equation.html#initialisation",
    "href": "sessions/R-estimation-and-the-renewal-equation.html#initialisation",
    "title": "R estimation and the renewal equation",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "R estimation and the renewal equation"
    ]
  },
  {
    "objectID": "sessions/R-estimation-and-the-renewal-equation.html#simulating-a-geometric-random-walk",
    "href": "sessions/R-estimation-and-the-renewal-equation.html#simulating-a-geometric-random-walk",
    "title": "R estimation and the renewal equation",
    "section": "Simulating a geometric random walk",
    "text": "Simulating a geometric random walk\nYou can have a look at an R function for performing the geometric random walk:\n\nsource(here(\"functions\", \"geometric-random-walk.r\"))\ngeometric_random_walk\n\nfunction (init, noise, std) \n{\n    n &lt;- length(noise) + 1\n    x &lt;- numeric(n)\n    x[1] &lt;- init\n    for (i in 2:n) {\n        x[i] &lt;- x[i - 1] + noise[i - 1] * std\n    }\n    return(exp(x))\n}\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nLook at this function and try to understand what it does. Note that we use the fact that we can generate a random normally distributed variable \\(X\\) with mean 0 and standard deviation \\(\\sigma\\) by mutiplying a standard normally distributed variable (i.e., mean 0 and standard deviation 1) \\(Y\\) with \\(\\sigma\\). Using this non-centred parameterisation for efficiency) will improve our computational efficency later when using an equivalent function in stan\n\n\nWe can use this function to simulate a random walk:\n\nR &lt;- geometric_random_walk(init = 1, noise = rnorm(100), std = 0.1)\ndata &lt;- tibble(t = seq_along(R), R = exp(R))\n\nggplot(data, aes(x = t, y = R)) +\n  geom_line() +\n  labs(title = \"Simulated data from a random walk model\",\n       x = \"Time\",\n       y = \"R\")\n\n\n\n\n\n\n\n\nYou can repeat this multiple times either with the same parameters or changing some to get a feeling for what this does.",
    "crumbs": [
      "R estimation and the renewal equation"
    ]
  },
  {
    "objectID": "sessions/R-estimation-and-the-renewal-equation.html#estimating-r_t-with-a-geometric-random-walk-prior",
    "href": "sessions/R-estimation-and-the-renewal-equation.html#estimating-r_t-with-a-geometric-random-walk-prior",
    "title": "R estimation and the renewal equation",
    "section": "Estimating \\(R_t\\) with a geometric random walk prior",
    "text": "Estimating \\(R_t\\) with a geometric random walk prior\nWe can now include this in a stan model,\n\nrw_mod &lt;- cmdstan_model(here(\"stan\", \"estimate-inf-and-r-rw.stan\"))\nrw_mod\n\n 1: functions {\n 2:   #include \"functions/convolve_with_delay.stan\"\n 3:   #include \"functions/renewal.stan\"\n 4:   #include \"functions/geometric_random_walk.stan\"\n 5: }\n 6: \n 7: data {\n 8:   int n;                // number of days\n 9:   int I0;              // number initially infected\n10:   array[n] int obs;     // observed symptom onsets\n11:   int gen_time_max;     // maximum generation time\n12:   array[gen_time_max] real gen_time_pmf;  // pmf of generation time distribution\n13:   int&lt;lower = 1&gt; ip_max; // max incubation period\n14:   array[ip_max + 1] real ip_pmf;\n15: }\n16: \n17: parameters {\n18:   real init_R;         // initial reproduction number\n19:   array[n-1] real rw_noise; // random walk noise\n20:   real&lt;lower = 0&gt; rw_sd; // random walk standard deviation\n21: }\n22: \n23: transformed parameters {\n24:   array[n] real R = geometric_random_walk(init_R, rw_noise, rw_sd);\n25:   array[n] real infections = renewal(I0, R, gen_time_pmf);\n26:   array[n] real onsets = convolve_with_delay(infections, ip_pmf);\n27: }\n28: \n29: model {\n30:   // priors\n31:   init_R ~ normal(-.1, 0.5); // Approximately Normal(1, 0.5)\n32:   rw_noise ~ std_normal();\n33:   rw_sd ~ normal(0, 0.05) T[0,];\n34:   obs ~ poisson(onsets);\n35: }\n\n\nNote that the model is very similar to the one we used earlier, but with the addition of the random walk model for the reproduction number using a function in stan that does the same as our R function of the same name we defined.\nWe can now generate estimates from this model:\n\ndata &lt;- list(\n  n = length(obs) - 1,\n  obs = obs[-1],\n  I0 = inf_ts$infections[1],\n  gen_time_max = length(gen_time_pmf),\n  gen_time_pmf = gen_time_pmf,\n  ip_max = length(ip_pmf) - 1,\n  ip_pmf = ip_pmf\n)\nr_rw_inf_fit &lt;- rw_mod$sample(\n  data = data, parallel_chains = 4, max_treedepth = 12, \n  init = \\() list(init_R = 0, rw_sd = 0.01)\n)\n\n\nr_rw_inf_fit\n\n    variable     mean   median   sd  mad       q5      q95 rhat ess_bulk\n lp__        21806.35 21806.70 8.82 8.60 21791.70 21820.40 1.00     1277\n init_R          0.59     0.59 0.14 0.14     0.35     0.83 1.00     5267\n rw_noise[1]     0.15     0.13 1.03 1.05    -1.49     1.84 1.00     8370\n rw_noise[2]     0.10     0.11 1.00 0.99    -1.55     1.77 1.00     6852\n rw_noise[3]     0.01     0.01 1.00 0.99    -1.64     1.67 1.00     8089\n rw_noise[4]    -0.06    -0.04 0.98 1.00    -1.66     1.57 1.00     7298\n rw_noise[5]    -0.13    -0.12 1.00 1.04    -1.81     1.50 1.00     8225\n rw_noise[6]    -0.20    -0.19 1.03 1.04    -1.90     1.51 1.00     8854\n rw_noise[7]    -0.30    -0.28 0.98 0.99    -1.91     1.31 1.00     7751\n rw_noise[8]    -0.38    -0.39 0.97 0.98    -1.99     1.21 1.00     7172\n ess_tail\n     2019\n     2831\n     2712\n     2849\n     2758\n     2847\n     2877\n     3101\n     2831\n     3042\n\n # showing 10 of 566 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs this is a more complex model we have increased the max_treedepth parameter to 12 to allow for more complex posterior distributions and we have also provided an initialisation for the init_R and rw_sd parameters to help the sampler find the right region of parameter space. This is a common technique when fitting more complex models and is needed as it is hard a priori to know where the sampler should start.\n\n\nWe can again extract and visualise the posteriors in the same way as earlier.\n\nrw_posteriors &lt;- r_rw_inf_fit |&gt;\n  gather_draws(infections[infection_day], R[infection_day]) |&gt;\n  ungroup() |&gt;\n  mutate(infection_day = infection_day - 1) |&gt;\n  filter(.draw %in% sample(.draw, 100))\n\n\nrw_inf_posterior &lt;- rw_posteriors |&gt;\n  filter(.variable == \"infections\")\nggplot(mapping = aes(x = infection_day)) +\n  geom_line(\n    data = rw_inf_posterior, mapping = aes(y = .value, group = .draw), alpha = 0.1\n  ) +\n  geom_line(data = inf_ts, mapping = aes(y = infections), colour = \"red\") +\n  labs(title = \"Infections, estimated (grey) and observed (red)\", \n       subtitle = \"Model 3: renewal equation with random walk\")\n\n\n\n\n\n\n\n\nand reproduction numbers\n\nrw_r_inf_posterior &lt;- rw_posteriors |&gt;\n  filter(.variable == \"R\") |&gt;\n  filter(.draw %in% sample(.draw, 100))\nggplot(\n  data = rw_r_inf_posterior,\n  mapping = aes(x = infection_day, y = .value, group = .draw)\n) +\n  geom_line(alpha = 0.1) +\n  labs(title = \"Estimated R\", \n       subtitle = \"Model 3: renewal equation with random walk\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 10 minutes\n\n\n\nCompare the results across the models used in this session, and the one used in the session on convolutions. How do the models vary in the number of parameters that need to be estimated? How do the assumptions about the infections time series differ between the models? What do you notice about the level of uncertainty in the estimates of infections and \\(R_t\\) over the course of the time series? If you have time you could try re-running the experiment with different \\(R_t\\) trajectories and delay distributions to see whether results change.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can see that using the renewal model as generative model we recover the time series of infections more accurately compared to previously when we assumed independent numbers of infections each day and that using a more believable model (i.e the geometric random walk) for the reproduction number improves things even more. Of course, this is helped by the fact that the data was generated by a model similar to the renewal model used for inference.\n\nComparing the \\(R_t\\) trajectories\n\n## earlier posteriors\nr_posterior &lt;- r_posterior |&gt;\n  mutate(data = \"infections\")\nr_inf_posterior &lt;- r_inf_posterior |&gt;\n  mutate(data = \"onsets (normal)\")\nrw_r_inf_posterior &lt;- rw_r_inf_posterior |&gt;\n  mutate(data = \"onsets (random walk)\")\n\nall_posteriors &lt;- rbind(\n  r_inf_posterior,\n  rw_r_inf_posterior,\n  r_posterior\n)\n\nggplot(\n  all_posteriors,\n  mapping = aes(x = infection_day, y = .value, group = .draw,\n                colour = data)\n) +\n  geom_line(alpha = 0.1) +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(\n    title = \"Rt estimates from renewal equation models\",\n    subtitle = paste(\n      \"Estimates from infections, from symptom onsets, and from onsets with a\",\n      \"random walk\"\n    )\n  ) +\n  guides(colour = guide_legend(override.aes = list(alpha = 1)))\n\n\n\n\n\n\n\n\nWe can see that the estimates are smoother when using the random walk model for the reproduction number, compared to the normal model. The model that fits directly to infections has the lowest uncertainty, which we would expect as it doesn’t have to infer the number of infections from symptom onsets but even here the reproduction number estimates are unrealistically noisy due to the assumption of independence between infections each day.",
    "crumbs": [
      "R estimation and the renewal equation"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html",
    "href": "sessions/delay-distributions.html",
    "title": "Delay distributions",
    "section": "",
    "text": "Every outbreak starts with an infection, but we rarely observe these directly. Instead, there are many types of epidemiological events that we might observe that occur after the time of infection: symptom onsets, hospitalisations and discharge, etc. The length of time between any of these events might be highly variable and uncertain. However, we often need to have some estimate for these delays in order to understand what’s happening now and predict what might happen in the future. We capture this variability using probability distributions, which is the focus of this session.\n\n\n\nIntroduction to epidemiological delays\n\n\n\n\nThe aim of this session is for you to familiarise yourself with the concept of delay distributions used to describe reporting in infectious disease epidemiology. First we’ll look at this working forwards from infections in an outbreak. We’ll use R to probabilistically simulate delays from infection to reporting symptoms and hospitalisations. Then we’ll work only from this set of outcome data and use a stan model to estimate the parameters of one specific delay (in this example, symptom onset to hospitalisation).\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/delay-distributions.qmd.\n\n\n\nIn this session we will use the nfidd package to load a data set of infection times, the ggplot2 package for plotting, the dplyr and tidyr packages to wrangle data, the lubridate package to deal with dates, the here package to find the stan models, the cmdstanr package for using stan, and the posterior packages for investigating the results of the inference conducted with stan.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"lubridate\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"posterior\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html#slides",
    "href": "sessions/delay-distributions.html#slides",
    "title": "Delay distributions",
    "section": "",
    "text": "Introduction to epidemiological delays",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html#objectives",
    "href": "sessions/delay-distributions.html#objectives",
    "title": "Delay distributions",
    "section": "",
    "text": "The aim of this session is for you to familiarise yourself with the concept of delay distributions used to describe reporting in infectious disease epidemiology. First we’ll look at this working forwards from infections in an outbreak. We’ll use R to probabilistically simulate delays from infection to reporting symptoms and hospitalisations. Then we’ll work only from this set of outcome data and use a stan model to estimate the parameters of one specific delay (in this example, symptom onset to hospitalisation).\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/delay-distributions.qmd.\n\n\n\nIn this session we will use the nfidd package to load a data set of infection times, the ggplot2 package for plotting, the dplyr and tidyr packages to wrangle data, the lubridate package to deal with dates, the here package to find the stan models, the cmdstanr package for using stan, and the posterior packages for investigating the results of the inference conducted with stan.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"lubridate\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"posterior\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html#source-file",
    "href": "sessions/delay-distributions.html#source-file",
    "title": "Delay distributions",
    "section": "",
    "text": "The source file of this session is located at sessions/delay-distributions.qmd.",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html#libraries-used",
    "href": "sessions/delay-distributions.html#libraries-used",
    "title": "Delay distributions",
    "section": "",
    "text": "In this session we will use the nfidd package to load a data set of infection times, the ggplot2 package for plotting, the dplyr and tidyr packages to wrangle data, the lubridate package to deal with dates, the here package to find the stan models, the cmdstanr package for using stan, and the posterior packages for investigating the results of the inference conducted with stan.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"ggplot2\")\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"lubridate\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"posterior\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html#initialisation",
    "href": "sessions/delay-distributions.html#initialisation",
    "title": "Delay distributions",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html#load-the-outbreak-data",
    "href": "sessions/delay-distributions.html#load-the-outbreak-data",
    "title": "Delay distributions",
    "section": "Load the outbreak data",
    "text": "Load the outbreak data\nWe will work with a data set that is included in the nfidd R package that you installed initially. The column infection_time is a linelist of infections from our example outbreak, given as a decimal number of days that have passed since the initial infection of the outbreak. It can be loaded with the data command.\n\ndata(infection_times)\nhead(infection_times)\n\n  infection_time\n1       0.000000\n2       2.236708\n3       4.091861\n4       7.347199\n5       8.990060\n6       4.635069\n\n### visualise the infection curve\nggplot(infection_times, aes(x = infection_time)) +\n  geom_histogram(binwidth = 1) +\n  scale_x_continuous(n.breaks = 10) +\n  labs(x = \"Infection time (in days)\", y = \"Number of infections\",\n       title = \"Infections during an outbreak\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn reality, data from an outbreak will usually be given as dates, not decimals; and those will usually not represent infection, but an observed outcome such as symptom onset or hospital admission. For now we don’t want to spend too much time manipulating dates in R, but we will get back to working with more realistic outbreak data later.",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html#working-forwards-simulating-a-sequence-of-delays-after-infection",
    "href": "sessions/delay-distributions.html#working-forwards-simulating-a-sequence-of-delays-after-infection",
    "title": "Delay distributions",
    "section": "Working forwards: simulating a sequence of delays after infection",
    "text": "Working forwards: simulating a sequence of delays after infection\nWe would now like to simulate hospitalisations arising from this outbreak. We will start with our data on infection times, and work forwards to symptom onsets and then hospitalisations. We’ll make the following assumptions about the process from infection to hospital admission:\n\nInfection to symptoms:\n\nWe’ll assume all infections cause symptoms.\nTime from infection to symptom onset (incubation period): We assume that the incubation period is gamma-distributed with shape 5 and rate 1, i.e. a mean of 5 days.\n\nSymptoms to hospital admission:\n\nWe’ll assume that 30% of symptomatic cases become hospitalised.\nTime from symptom onset to hospital admission: We assume that the onset-to-hospitalisation period is lognormally distributed, with meanlog 1.75 and sdlog 0.5, corresponding to a mean delay of about a week.\n\n\nLet’s put these assumptions into practice by simulating some data, adding onset and hospitalisation times (in decimal number of days after the first infection) to the infection times. We’ll use random values for each infection from the probability distributions we’ve assumed above.\n\n\n\n\n\n\nTip\n\n\n\nThroughout the course, we repeat some small chunks of code. Instead of copying these between sessions, we’ve put them into separate R scripts and source them when needed. You can find these files in the snippets and functions directories.\n\n\n\nsource(here::here(\"snippets\", \"onset-hosp.r\"), \n       echo=TRUE, max.deparse.length=1000)\n\n\n&gt; data(infection_times)\n\n&gt; df &lt;- mutate(infection_times, onset_time = infection_time + \n+     rgamma(n(), shape = 5, rate = 1), hosp_time = onset_time + \n+     rlnorm(n(), meanlog = 1.75, sdlog = 0.5))\n\n&gt; df &lt;- mutate(df, hosp_time = if_else(rbinom(n = n(), \n+     size = 1, prob = 0.3) == 1, hosp_time, NA))\n\n\nNow we can plot infections, hospitalisations and onsets.\n\n# convert our data frame to long format\ndfl &lt;- df |&gt;\n  pivot_longer(\n    cols = c(infection_time, onset_time, hosp_time),\n    names_to = \"type\", values_to = \"time\"\n  )\n# plot\nggplot(dfl, aes(x = time)) +\n  geom_histogram(position = \"dodge\", binwidth = 1) +\n  facet_wrap(~ type, ncol = 1) +\n  xlab(\"Time (in days)\") +\n  ylab(\"Count\")\n\nWarning: Removed 4586 rows containing non-finite outside the scale range\n(`stat_bin()`).",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/delay-distributions.html#estimating-delay-distributions-from-outcome-data",
    "href": "sessions/delay-distributions.html#estimating-delay-distributions-from-outcome-data",
    "title": "Delay distributions",
    "section": "Estimating delay distributions from outcome data",
    "text": "Estimating delay distributions from outcome data\nAs mentioned above, our data set of infection, symptom onset and hospitalisation times is not the typical data set we encounter in outbreaks. In reality, we don’t have infection dates, and we also have to deal with missing data, incomplete observations, data entry errors etc. For now, let us just assume we have a data set only including symptom onset times and some hospitalisation times.\nLet’s look at a specific problem: we would like to estimate how long it takes for people to become hospitalised after becoming symptomatic. This might be an important delay to know about, for example when modelling and forecasting hospitalisations, or more generally for estimating required hospital capacity.\nTo do this we can use our data with stan to model the delay from symptom onset to hospitalisation, with the same assumption that it follows a lognormal distribution.\n\nmod &lt;- cmdstan_model(here(\"stan\", \"lognormal.stan\"))\nmod\n\n 1: // lognormal_model.stan\n 2: data {\n 3:   int&lt;lower=0&gt; n; // number of data points\n 4:   array[n] real y; // data\n 5: }\n 6: \n 7: parameters {\n 8:   real meanlog;\n 9:   real&lt;lower=0&gt; sdlog;\n10: }\n11: \n12: model {\n13:   meanlog ~ normal(0, 10);  // prior distribution\n14:   sdlog ~ normal(0, 10) T[0, ]; // prior distribution\n15: \n16:   y ~ lognormal(meanlog, sdlog);\n17: }\n\n\nLet’s estimate the onset-to-hospitalisation delay using the simulated data set we created above. Do we recover the parameters used for simulation?\nWe can do this by sampling from the model’s posterior distribution by feeding it our simulated data set.\n\n## Specify the time from onset to hospitalisation\ndf_onset_to_hosp &lt;- df |&gt;\n  mutate(onset_to_hosp = hosp_time - onset_time) |&gt; \n  # exclude infections that didn't result in hospitalisation\n  drop_na(onset_to_hosp)\n## Use the data to sample from the model posterior\nres &lt;- mod$sample(\n  data = list(\n    n = nrow(df_onset_to_hosp),\n    y = df_onset_to_hosp$onset_to_hosp\n  )\n)\n\nTo see the estimates, we can use:\n\nres$summary() ## could also simply type `res`\n\n# A tibble: 3 × 10\n  variable      mean    median      sd     mad        q5      q95  rhat ess_bulk\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -1281.    -1281.    1.02    0.734   -1283.    -1.28e+3  1.00    1939.\n2 meanlog      1.73      1.73  0.0117  0.0117      1.71   1.75e+0  1.00    3177.\n3 sdlog        0.494     0.494 0.00835 0.00816     0.480  5.08e-1  1.00    3320.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nThese estimates should look similar to what we used in the simulations. We can plot the resulting probability density functions.\n\n\n\n\n\n\nNote\n\n\n\nEvery time we sample from the model posterior, we create 4000 iterations. That is a lot of data to plot, so instead, when we produce plots we’ll use a random sample of 100 iterations. You’ll see this throughout the course.\n\n\n\n## get shape and rate samples from the posterior\nres_df &lt;- res |&gt;\n  as_draws_df() |&gt;\n  filter(.draw %in% sample(.draw, 100)) # sample 100 draws\n\n## find the value (x) that includes 99% of the cumulative density\nmax_x &lt;- max(qlnorm(0.99, meanlog = res_df$meanlog, sdlog = res_df$sdlog))\n\n## calculate density on grid of x values\nx &lt;- seq(0, max_x, length.out = 100)\nres_df &lt;- res_df |&gt;\n  crossing(x = x) |&gt; ## add grid to data frame\n  mutate(density = dlnorm(x, meanlog, sdlog))\n\n## plot\nggplot(res_df, aes(x = x, y = density, group = .draw)) +\n  geom_line(alpha = 0.3)",
    "crumbs": [
      "Delay distributions"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html",
    "href": "sessions/forecasting-concepts.html",
    "title": "Forecasting concepts",
    "section": "",
    "text": "So far we’ve looked at epidemiological processes and events up until the present. Now we’ll start to forecast into the future, while considering what we might want from a “good” forecast. After enough time has passed to observe events, we can then retrospectively evaluate how well forecasts performed. We’ll introduce evaluating forecasts qualitatively by visual inspection, and quantitatively using scoring metrics.\n\n\n\nForecasting as an epidemiological problem\n\n\n\n\nThe aim of this session is to introduce the concept of forecasting, using a simple model, and forecasting evaluation.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/forecasting-concepts.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. A new addition is the scoringutils package for calculating forecast evaluation metrics. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\nlibrary(\"scoringutils\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#slides",
    "href": "sessions/forecasting-concepts.html#slides",
    "title": "Forecasting concepts",
    "section": "",
    "text": "Forecasting as an epidemiological problem",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#objectives",
    "href": "sessions/forecasting-concepts.html#objectives",
    "title": "Forecasting concepts",
    "section": "",
    "text": "The aim of this session is to introduce the concept of forecasting, using a simple model, and forecasting evaluation.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/forecasting-concepts.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. A new addition is the scoringutils package for calculating forecast evaluation metrics. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\nlibrary(\"scoringutils\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#source-file",
    "href": "sessions/forecasting-concepts.html#source-file",
    "title": "Forecasting concepts",
    "section": "",
    "text": "The source file of this session is located at sessions/forecasting-concepts.qmd.",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#libraries-used",
    "href": "sessions/forecasting-concepts.html#libraries-used",
    "title": "Forecasting concepts",
    "section": "",
    "text": "In this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. A new addition is the scoringutils package for calculating forecast evaluation metrics. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\nlibrary(\"scoringutils\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#initialisation",
    "href": "sessions/forecasting-concepts.html#initialisation",
    "title": "Forecasting concepts",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#take-5-minutes",
    "href": "sessions/forecasting-concepts.html#take-5-minutes",
    "title": "Forecasting concepts",
    "section": "Take 5 minutes",
    "text": "Take 5 minutes\nWhat have we changed in the model to make it a forecasting model? Do you see any limitations of this approach?",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#fitting-the-model-and-forecast-for-28-days-into-the-future",
    "href": "sessions/forecasting-concepts.html#fitting-the-model-and-forecast-for-28-days-into-the-future",
    "title": "Forecasting concepts",
    "section": "Fitting the model and forecast for 28 days into the future",
    "text": "Fitting the model and forecast for 28 days into the future\nWe can now fit the model to the data and then make a forecast. This should look very similar to the code we used in the renewal session but with the addition of a non-zero h in the data list.\n\nhorizon &lt;- 28\n\ndata &lt;- list(\n  n = nrow(filtered_onset_df),\n  I0 = 1,\n  obs = filtered_onset_df$onsets,\n  gen_time_max = length(gen_time_pmf),\n  gen_time_pmf = gen_time_pmf,\n  ip_max = length(ip_pmf) - 1,\n  ip_pmf = ip_pmf,\n  h = horizon # Here we set the number of days to forecast into the future\n)\nrw_forecast &lt;- mod$sample(\n  data = data, parallel_chains = 4, adapt_delta = 0.95,\n  init = \\() list(init_R = 0, rw_sd = 0.01)\n)\n\n\nrw_forecast\n\n    variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n lp__        3268.25 3268.61 7.19 7.30 3256.06 3279.53 1.00     1440     2298\n init_R         0.43    0.43 0.08 0.07    0.31    0.58 1.00     2499     1556\n rw_noise[1]    0.05    0.05 1.02 0.99   -1.64    1.74 1.00     6193     2793\n rw_noise[2]    0.01    0.02 0.98 0.97   -1.61    1.59 1.00     6805     3059\n rw_noise[3]    0.01    0.01 1.02 1.05   -1.64    1.68 1.00     7778     2579\n rw_noise[4]   -0.02   -0.02 1.00 1.01   -1.67    1.65 1.00     6318     2665\n rw_noise[5]   -0.04   -0.03 1.01 1.00   -1.69    1.64 1.00     6481     2689\n rw_noise[6]   -0.08   -0.08 1.01 0.99   -1.76    1.57 1.00     8255     2644\n rw_noise[7]   -0.09   -0.12 1.00 1.02   -1.72    1.58 1.00     7208     2897\n rw_noise[8]   -0.14   -0.14 0.99 1.02   -1.79    1.47 1.00     7438     2926\n\n # showing 10 of 426 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause this model can struggle to fit to the data, we have increased the value of adapt_delta from its default value of 0.8. This is, a tuning parameter that affects the step size of the sampler in exploring the posterior (higher adapt_delta leading to smaller step sizes meaning posterior exploration is slower but more careful).",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#visualising-the-forecast",
    "href": "sessions/forecasting-concepts.html#visualising-the-forecast",
    "title": "Forecasting concepts",
    "section": "Visualising the forecast",
    "text": "Visualising the forecast\nWe can now visualise the forecast. We will first extract the forecast and then plot the forecasted number of symptom onsets alongside the observed number of symptom onsets.\n\nforecast &lt;- rw_forecast |&gt;\n  gather_draws(forecast[day]) |&gt;\n  ungroup() |&gt; \n  mutate(day = day + cutoff)\n\ntarget_onsets &lt;- onset_df |&gt;\n  filter(day &gt; cutoff) |&gt;\n  filter(day &lt;= cutoff + horizon)\n\n\nforecast |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_line(alpha = 0.1, aes(y = .value, group = .draw)) +\n  geom_point(data = target_onsets, aes(x = day, y = onsets), color = \"black\") +\n  labs(title = \"Symptom onsets\", subtitle = \"Forecast (trajectories) and observed (points)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nWhat do you think of this forecast? Did the model do a good job? Is there another way you could visualise the forecast that might be more informative?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nOn the face of it the forecast looks very poor with some very high predictions compared to the data.\nBased on this visualisation it is hard to tell if the model is doing a good job but it seems like it is not.\nAs outbreaks are generally considered to be exponential processes it might be more informative to plot the forecast on the log scale.\n\n\nforecast |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_line(alpha = 0.1, aes(y = .value, group = .draw)) +\n  geom_point(data = target_onsets, aes(x = day, y = onsets), color = \"black\") +\n  scale_y_continuous(trans = \"log\") +\n  labs(title = \"Symptom onsets, log scale\", subtitle = \"Forecast and observed\")\n\n\n\n\n\n\n\n\nThis should be a lot more informative. We see that for longer forecast horizons the model is not doing a great job of capturing the reduction in symptom onsets. However, we can now see that the model seems to be producing very reasonable forecasts for the first week or so of the forecast. This is a common pattern in forecasting where a model is good at capturing the short term dynamics but struggles with the longer term dynamics.\n\n\n\nAs our forecasting model is based on the reproduction number, we can also visualise the forecast of the reproduction number. This can be helpful for understanding why our forecasts of symptom onsets look the way they do and for understanding the uncertainty in the forecasts. We can also compare this to the “true” reproduction number, estimated once all relevant data is available. To do this, we will fit the model again but with a later cutoff. Then we can compare the reproduction numbers produced as forecasts at the earlier time, with estimates at the later time that used more of the data.\n\nlong_onset_df &lt;- onset_df |&gt;\n  filter(day &lt;= cutoff + horizon)\n\nlong_data &lt;- list(\n  n =nrow(long_onset_df),\n  I0 = 1,\n  obs = long_onset_df$onsets,\n  gen_time_max = length(gen_time_pmf),\n  gen_time_pmf = gen_time_pmf,\n  ip_max = length(ip_pmf) - 1,\n  ip_pmf = ip_pmf,\n  h = 0\n)\n\n\nrw_long &lt;- mod$sample(\n  data = long_data, parallel_chains = 4, adapt_delta = 0.95,\n  init = \\() list(init_R = 0, rw_sd = 0.01)\n)\n\nWe first need to extract the forecast and estimated reproduction numbers.\n\nforecast_r &lt;- rw_forecast |&gt;\n  gather_draws(R[day]) |&gt;\n  ungroup() |&gt; \n  mutate(type = \"forecast\")\n\nlong_r &lt;- rw_long |&gt;\n  gather_draws(R[day]) |&gt;\n  ungroup() |&gt; \n  mutate(type = \"estimate\")\n\nWe can now plot the forecast and estimated reproduction numbers.\n\nforecast_r |&gt;\n  bind_rows(long_r) |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_vline(xintercept = cutoff, linetype = \"dashed\") +\n  geom_hline(yintercept = 1, linetype = \"dashed\") +\n  geom_line(aes(y = .value, group = interaction(.draw, type), color = type), alpha = 0.1)+\n  labs(title = \"Estimated R\", \n       subtitle = \"Estimated over whole time series (red), and forecast (blue)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe horizontal dashed line at 1 represents the threshold for epidemic growth. If the reproduction number is above 1 then the epidemic is growing, if it is below 1 then the epidemic is shrinking. The vertical dashed line represents the point at which we started forecasting.\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nCan you use this plot to explain why the forecast of onsets looks the way it does?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nWhen both models are being fit to data (i.e before the vertical dashed line) the forecast and estimated reproduction numbers are very similar.\nFor short-term forecasts \\(R_t\\) estimates continue to be fairly similar.\nHowever, the estimates have a consistent downwards trend which is not captured by the forecast (which looks like it has a constant mean value with increasing uncertainty).\nThis explains the divergence between the forecast and the data as the horizon increases.\nIt looks like only a relatively small number of forecast \\(R_t\\) trajectories grow to be very large but these are enough to visually dominate the forecast of onsets on the natural scale.\nThe performance we are seeing here makes sense given that random walks are defined to have a constant mean and increasing variance.\n\n\n\n\nWe managed to learn quite a lot about our model’s forecasting limitations just looking at a single forecast using visualisations. However, what if we wanted to quantify how well the model is doing? This is where forecast evaluation comes in which we will cover in the next section.",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#visualising-your-forecast",
    "href": "sessions/forecasting-concepts.html#visualising-your-forecast",
    "title": "Forecasting concepts",
    "section": "Visualising your forecast",
    "text": "Visualising your forecast\nAs for a single forecast, our first step is to visualise the forecasts as this can give us a good idea of how well the model is doing without having to calculate any metrics.\n\nrw_forecasts |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  ggplot(aes(x = day)) +\n  geom_line(aes(y = .value, group = interaction(.draw, target_day), col = target_day), alpha = 0.1) +\n  geom_point(data = onset_df |&gt;\n    filter(day &gt;= 21),\n    aes(x = day, y = onsets), color = \"black\") +\n  scale_color_binned(type = \"viridis\") +\n  labs(title = \"Weekly forecasts of symptom onsets over an outbreak\",\n       col = \"Forecast start day\")\n\n\n\n\n\n\n\n\nAs for the single forecast it may be helpful to also plot the forecast on the log scale.\n\nrw_forecasts |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt; \n  ggplot(aes(x = day)) +\n  geom_line(aes(y = .value, group = interaction(.draw, target_day), col = target_day), alpha = 0.1) +\n  geom_point(data = onset_df, aes(x = day, y = onsets), color = \"black\") +\n  scale_y_log10() +\n  scale_color_binned(type = \"viridis\") +\n  labs(title = \"Weekly symptom onset forecasts: log scale\",\n       col = \"Forecast start day\")\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nWhat do you think of these forecasts? Are they any good? How well do they capture changes in trend? Does the uncertainty seem reasonable? Do they seem to under or over predict consistently? Would you visualise the forecast in a different way?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhat do you think of these forecasts? - We think these forecasts are a reasonable place to start but there is definitely room for improvement. Are they any good? - They seem to do a reasonable job of capturing the short term dynamics but struggle with the longer term dynamics. How well do they capture changes in trend? - There is little evidence of the model capturing the reduction in onsets before it begins to show in the data. Does the uncertainty seem reasonable? - On the natural scale it looks like the model often over predicts. Things seem more balanced on the log scale but the model still seems to be overly uncertain. Do they seem to under or over predict consistently? - It looks like the model is consistently over predicting on the natural scale but this is less clear on the log scale.",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#scoring-your-forecast",
    "href": "sessions/forecasting-concepts.html#scoring-your-forecast",
    "title": "Forecasting concepts",
    "section": "Scoring your forecast",
    "text": "Scoring your forecast\nOn top of visualising the forecasts, we can also summarise performance quantitatively by transforming them using scoring metrics. Whilst some of these metrics are more useful for comparing models, many can be also be useful for understanding the performance of a single model. We will look at some of these metrics in the next section.\n\n\n\n\n\n\nTip\n\n\n\nIn this session, we’ll use “proper” scoring rules: these are scoring rules that make sure no model can get better scores than the true model, i.e. the model used to generate the data. Of course we usually don’t know this (as we don’t know the “true model” for real-world data) but proper scoring rules incentivise forecasters to make their best attempt at reproducing its behaviour.\n\n\nWe will use the {scoringutils} package to calculate these metrics. Our first step is to convert our forecasts into a format that the {scoringutils} package can use. We will use as_forecast to do this:\n\nsc_forecasts &lt;- rw_forecasts |&gt;\n  left_join(onset_df, by = \"day\") |&gt;\n  filter(!is.na(.value)) |&gt;\n  as_forecast(\n    forecast_unit = c(\"target_day\", \"horizon\", \"model\"),\n    forecast_type = \"sample\",\n    observed = \"onsets\",\n    predicted = \".value\",\n    model = \"model\",\n    sample_id = \".draw\"\n  )\nsc_forecasts\n\nForecast type: sample\n\n\nForecast unit:\n\n\ntarget_day, horizon, and model\n\n\n\n        sample_id predicted observed target_day horizon       model\n            &lt;int&gt;     &lt;num&gt;    &lt;int&gt;      &lt;num&gt;   &lt;int&gt;      &lt;char&gt;\n     1:         1         4        1         22       1 Random walk\n     2:         2         2        1         22       1 Random walk\n     3:         3         2        1         22       1 Random walk\n     4:         4         6        1         22       1 Random walk\n     5:         5         2        1         22       1 Random walk\n    ---                                                            \n223996:       996         1        2        127      14 Random walk\n223997:       997         0        2        127      14 Random walk\n223998:       998         0        2        127      14 Random walk\n223999:       999         1        2        127      14 Random walk\n224000:      1000         0        2        127      14 Random walk\n\n\nAs you can see this has created a forecast object which has a print method that summarises the forecasts.\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nWhat important information is in the forecast object?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe forecast unit which is the target day, horizon, and model\nThe type of forecast which is a sample forecast\n\n\n\n\nEverything seems to be in order. We can now use the scoringutils package to calculate some metrics. We will use the default sample metrics (as our forecasts are in sample format) and score our forecasts.\n\nsc_scores &lt;- sc_forecasts |&gt;\n  score()\n\nsc_scores\n\n     target_day horizon       model   bias       dss     crps log_score    mad\n          &lt;num&gt;   &lt;int&gt;      &lt;char&gt;  &lt;num&gt;     &lt;num&gt;    &lt;num&gt;     &lt;num&gt;  &lt;num&gt;\n  1:         22       1 Random walk  0.758 2.7770353 1.349424  2.101958 1.4826\n  2:         22       2 Random walk  0.202 1.9095371 0.552522  1.687439 2.9652\n  3:         22       3 Random walk  0.858 3.5962828 2.010624  2.499141 2.9652\n  4:         22       4 Random walk  0.885 3.9324993 2.376469  2.605082 2.9652\n  5:         22       5 Random walk  0.359 2.8247338 1.040579  2.199754 2.9652\n ---                                                                          \n220:        127      10 Random walk -0.914 5.3470953 2.627842  3.340293 1.4826\n221:        127      11 Random walk -0.717 1.9337058 1.156866  2.208107 1.4826\n222:        127      12 Random walk -0.510 0.9362237 0.586738  1.563904 1.4826\n223:        127      13 Random walk -0.914 5.0039119 2.318689  3.239324 1.4826\n224:        127      14 Random walk -0.637 1.1404519 0.774974  1.814469 1.4826\n     ae_median   se_mean\n         &lt;num&gt;     &lt;num&gt;\n  1:         2  5.731236\n  2:         1  0.831744\n  3:         3 11.410884\n  4:         4 16.378209\n  5:         1  3.667225\n ---                    \n220:         4 11.329956\n221:         2  2.515396\n222:         1  0.527076\n223:         3  8.265625\n224:         1  0.948676\n\n\n\nAt a glance\nBefore we look in detail at the scores, we can use summarise_scores to get a quick overview of the scores. Don’t worry if you don’t understand all the scores yet, we will go some of them in more detail in the next section and you can find more information in the {scoringutils} documentation.\n\nsc_scores |&gt;\n  summarise_scores(by = \"model\")\n\n         model     bias      dss     crps log_score     mad ae_median  se_mean\n        &lt;char&gt;    &lt;num&gt;    &lt;num&gt;    &lt;num&gt;     &lt;num&gt;   &lt;num&gt;     &lt;num&gt;    &lt;num&gt;\n1: Random walk 0.190192 6.303572 13.35136  3.983245 18.2512    17.875 1502.309\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nBefore we look in detail at the scores, what do you think the scores are telling you?\n\n\n\n\nContinuous ranked probability score\n\nWhat is the Continuous Ranked Probability Score (CRPS)?\nThe Continuous Ranked Probability Score (CRPS) is a proper scoring rule used to evaluate the accuracy of probabilistic forecasts. It is a generalization of the Mean Absolute Error (MAE) to probabilistic forecasts, where the forecast is a distribution rather than a single point estimate (i.e. like ours).\nThe CRPS can be thought about as the combination of two key aspects of forecasting: 1. The accuracy of the forecast in terms of how close the predicted values are to the observed value. 2. The confidence of the forecast in terms of the spread of the predicted values.\nBy balancing these two aspects, the CRPS provides a comprehensive measure of the quality of probabilistic forecasts.\n\n\n\n\n\n\nKey things to note about the CRPS\n\n\n\n\nSmall values are better\nAs it is an absolute scoring rule it can be difficult to use to compare forecasts across scales.\n\n\n\n\n\n\n\n\n\nMathematical Definition (optional)\n\n\n\n\n\nFor distributions with a finite first moment (a mean exists and it is finite), the CRPS can be expressed as:\n\\[\nCRPS(D, y) = \\mathbb{E}_{X \\sim D}[|X - y|] - \\frac{1}{2} \\mathbb{E}_{X, X' \\sim D}[|X - X'|]\n\\]\nwhere \\(X\\) and \\(X'\\) are independent random variables sampled from the distribution \\(D\\). To calculate this we simpley replace \\(X\\) and \\(X'\\) by samples from our posterior distribution and sum over all possible combinations.\nThis equation can be broke down into the two components:\n\nBreakdown of the Components\n\nExpected Absolute Error Between Forecast and Observation: \\(\\mathbb{E}_{X \\sim D}[|X - y|]\\) This term represents the average absolute difference between the values predicted by the forecasted distribution \\(D\\) and the actual observed value \\(y\\). It measures how far, on average, the forecasted values are from the observed value. A smaller value indicates that the forecasted distribution is closer to the observed value.\nExpected Absolute Error Between Two Forecasted Values: \\(\\frac{1}{2} \\mathbb{E}_{X, X' \\sim D}[|X - X'|]\\) This term represents the average absolute difference between two independent samples from the forecasted distribution \\(D\\). It measures the internal variability or spread of the forecasted distribution. A larger value indicates a wider spread of the forecasted values.\n\n\n\nInterpretation\n\nFirst Term (\\(\\mathbb{E}_{X \\sim D}[|X - y|]\\)): This term penalizes the forecast based on how far the predicted values are from the observed value. It ensures that the forecast is accurate in terms of proximity to the actual observation.\nSecond Term (\\(\\frac{1}{2} \\mathbb{E}_{X, X' \\sim D}[|X - X'|]\\)): This term accounts for the spread of the forecasted distribution. It penalizes forecasts that are too uncertain or have a wide spread. By subtracting this term, the CRPS rewards forecasts that are not only accurate but also confident (i.e., have a narrow spread).\n\n\n\n\n\nWhilst the CRPS is a very useful metric it can be difficult to interpret in isolation. It is often useful to compare the CRPS of different models or to compare the CRPS of the same model under different conditions. For example, lets compare the CRPS across different forecast horizons.\n\nsc_scores |&gt;\n  summarise_scores(by = \"horizon\") |&gt;\n  ggplot(aes(x = horizon, y = crps)) +\n  geom_point() +\n  labs(title = \"CRPS by daily forecast horizon\", \n       subtitle = \"Summarised across all forecasts\")\n\n\n\n\n\n\n\n\nand at different time points.\n\nsc_scores |&gt;\n  summarise_scores(by = \"target_day\") |&gt;\n  ggplot(aes(x = target_day, y = crps)) +\n  geom_point() +\n  labs(title = \"CRPS by forecast start date\", \n       subtitle = \"Summarised across all forecasts\", x = \"forecast date\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nHow do the CRPS scores change based on forecast date? How do the CRPS scores change with forecast horizon? What does this tell you about the model?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe CRPS scores increase for forecast dates where incidence is higher.\nThe CRPS scores increase with forecast horizon.\nAs the CRPS is an absolute measure it is hard to immediately know if the CRPS increasing with forecast date indicates that the model is performing worse.\nHowever, the CRPS increasing with forecast horizon is a sign that the model is struggling to capture the longer term dynamics of the epidemic.\n\n\n\n\n\n\n\nPIT histograms\nAs well as the CRPS we can also look at the calibration and bias of the model. Calibration is the agreement between the forecast probabilities and the observed frequencies. Bias is a measure of how likely the model is to over or under predict the observed values.\nThere are many ways to assess calibration and bias but one common way is to use a probability integral transform (PIT) histogram. This is a histogram of the cumulative distribution of function of a forecast evaluated at the observed value.\n\n\n\n\n\n\nInterpreting the PIT histogram\n\n\n\n\nIdeally PIT histograms should be uniform.\nIf is a U shape then the model is overconfident and if it is an inverted U shape then the model is underconfident.\nIf it is skewed then the model is biased towards the direction of the skew.\n\n\n\n\n\n\n\n\n\nMathematical Definition (optional)\n\n\n\n\n\nContinuous Case\nFor a continuous random variable \\(X\\) with cumulative distribution function (CDF) \\(F_X\\), the PIT is defined as:\n\\[\nY = F_X(X)\n\\]\nwhere \\(Y\\) is uniformly distributed on \\([0, 1]\\).\n\nInteger Case\nWhen dealing with integer forecasts, the standard PIT does not yield a uniform distribution even if the forecasts are perfectly calibrated. To address this, a randomized version of the PIT is used. For an integer-valued random variable \\(X\\) with CDF \\(F_X\\), the randomized PIT is defined as:\n\\[\nU = F_X(k) + v \\cdot (F_X(k) - F_X(k-1))\n\\]\nwhere:\n\n\\(k\\) is the observed integer value.\n\\(F_X(k)\\) is the CDF evaluated at \\(k\\).\n\\(v\\) is a random variable uniformly distributed on \\([0, 1]\\).\n\nThis transformation ensures that \\(U\\) is uniformly distributed on \\([0, 1]\\) if the forecasted distribution \\(F_X\\) is correctly specified.\n\n\n\n\nLet’s first look at the overall PIT histogram.\n\n sc_forecasts |&gt;\n  get_pit(by = \"model\") |&gt;\n  plot_pit() +\n  labs(title = \"PIT histogram\")\n\n\n\n\n\n\n\n\nAs before lets look at the PIT histogram by forecast horizon. To save space we will group horizons into a few days each:\n\nsc_forecasts |&gt; \n  mutate(group_horizon = case_when(\n    horizon &lt;= 3 ~ \"1-3\",\n    horizon &lt;= 7 ~ \"4-7\",\n    horizon &lt;= 14 ~ \"8-14\"\n  )) |&gt;\n  get_pit(by = \"group_horizon\") |&gt;\n  plot_pit() +\n  facet_wrap(~group_horizon) +\n  labs(title = \"PIT by forecast horizon (days)\")\n\n\n\n\n\n\n\n\nand then for different forecast dates.\n\n sc_forecasts |&gt;\n  get_pit(by = \"target_day\") |&gt;\n  plot_pit() +\n  facet_wrap(~target_day) +\n  labs(title = \"PIT by forecast date\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nWhat do you think of the PIT histograms? Do they look well calibrated? Do they look biased?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nIt looks like the model is biased towards overpredicting and that this bias gets worse at longer forecast horizons.\nLooking over forecast dates it looks like much of this bias is coming from near the outbreak peak where the model is consistently overpredicting but the model is also over predicting at other times.",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/forecasting-concepts.html#scoring-on-the-log-scale",
    "href": "sessions/forecasting-concepts.html#scoring-on-the-log-scale",
    "title": "Forecasting concepts",
    "section": "Scoring on the log scale",
    "text": "Scoring on the log scale\nWe can also score on the logarithmic scale. This can be useful if we are interested in the relative performance of the model at different scales of the data, for example if we are interested in the model’s performance at capturing the exponential growth phase of the epidemic. In some sense scoring in this way can be an approximation of scoring the effective reproduction number estimates. Doing this directly can be difficult as the effective reproduction number is a latent variable and so we cannot directly score it.\nWe again use scoringutils but first transform both the forecasts and observations to the log scale. Note that we cannot log scale after scoring as this will give incorrect results.\n\nlog_sc_forecasts &lt;- sc_forecasts |&gt;\n  transform_forecasts(\n    fun = log_shift,\n    offset = 1,\n    append = FALSE\n  )\n\nlog_scores &lt;- log_sc_forecasts |&gt;\n  score()\n\nFor more on scoring on the log scale see Scoring forecasts on transformed scales.\n\nAt a glance\n\nlog_scores |&gt;\n  summarise_scores(by = \"model\")\n\n         model  bias       dss      crps log_score       mad ae_median\n        &lt;char&gt; &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;\n1: Random walk 0.152 -0.509457 0.2407813 0.6023975 0.3761217 0.3228824\n     se_mean\n       &lt;num&gt;\n1: 0.1999966\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nBefore we look in detail at the scores, what do you think the scores are telling you? How do you think they will differ from the scores on the natural scale?\n\n\n\n\nCRPS\n\nlog_scores |&gt;\n  summarise_scores(by = \"horizon\") |&gt;\n  ggplot(aes(x = horizon, y = crps)) +\n  geom_point() +\n  labs(title = \"CRPS by daily forecast horizon, scored on the log scale\")\n\n\n\n\n\n\n\n\nand across different forecast dates\n\nlog_scores |&gt;\n  summarise_scores(by = \"target_day\") |&gt;\n  ggplot(aes(x = target_day, y = crps)) +\n  geom_point() +\n  labs(title = \"CRPS by forecast date, scored on the log scale\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nHow do the CRPS scores change based on forecast date? How do the CRPS scores change with forecast horizon? What does this tell you about the model?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nAs for the natural scale CRPS scores increase with forecast horizon but now the increase appears to be linear vs exponential.\nThere has been a reduction in the CRPS scores for forecast dates near the outbreak peak compared to other forecast dates but this is still the period where the model is performing worst.\n\n\n\n\n\n\nPIT histograms\nLet’s first look at the overall PIT histogram.\n\nlog_sc_forecasts |&gt;\n  get_pit(by = \"model\") |&gt;\n  plot_pit() +\n  labs(title = \"PIT histogram, scored on the log scale\")\n\n\n\n\n\n\n\n\nAs before lets look at the PIT histogram by forecast horizon\n\nlog_sc_forecasts |&gt;\n  mutate(group_horizon = case_when(\n    horizon &lt;= 3 ~ \"1-3\",\n    horizon &lt;= 7 ~ \"4-7\",\n    horizon &lt;= 14 ~ \"8-14\"\n  )) |&gt;\n  get_pit(by = \"group_horizon\") |&gt;\n  plot_pit() +\n  facet_wrap(~group_horizon) +\n  labs(title = \"PIT by forecast horizon, scored on the log scale\")\n\n\n\n\n\n\n\n\nand then for different forecast dates.\n\nlog_sc_forecasts |&gt;\n  get_pit(by = \"target_day\") |&gt;\n  plot_pit() +\n  facet_wrap(~target_day) +\n  labs(title = \"PIT by forecast date, scored on the log scale\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nWhat do you think of the PIT histograms? Do they look well calibrated? Do they look biased?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe overall PIT histograms suggest that the model is less biased to over predict when scored on the log scale than the natural scale, but it is still biased. This makes sense when we think back to the comparison of reproduction number estimates and forecasts we made earlier where the model was consistently over predicting on the reproduction number.\nBy forecast horizon the model is still biased towards over predicting but this bias is less pronounced than on the natural scale.\nTowards the end and beginning of the forecast period the model appears to be well calibrated on the log scale but is biased towards over predicting in the middle of the forecast period.\nThis matches with our knowledge of the underlying reproduction number which were initially constant and then began to decrease only to stabilise towards the end of the outbreak.",
    "crumbs": [
      "Forecasting concepts"
    ]
  },
  {
    "objectID": "sessions/introduction-and-course-overview.html",
    "href": "sessions/introduction-and-course-overview.html",
    "title": "Introduction and course overview",
    "section": "",
    "text": "From an epidemiological line list to informing decisions in real-time",
    "crumbs": [
      "Introduction and course overview"
    ]
  },
  {
    "objectID": "sessions/introduction-and-course-overview.html#footnotes",
    "href": "sessions/introduction-and-course-overview.html#footnotes",
    "title": "Introduction and course overview",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTime travel is messy stuff↩︎",
    "crumbs": [
      "Introduction and course overview"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html",
    "href": "sessions/nowcasting.html",
    "title": "Nowcasting concepts",
    "section": "",
    "text": "So far we’ve explored the delays and biases of real-time outbreak data, started to correct for these, and considered the underlying process that drives the evolution of an outbreak (looking at the reproduction number and renewal equation). Next, we’ll focus on predicting new information about how an outbreak is evolving in the present and future.\nWe know that we have incomplete information in the present because of delays in the observation process (reporting delays). The aim of nowcasting is to predict what an epidemiological time series will look like after all delayed reports are in, for which we need to account for the delays and biases we’ve already considered.\n\n\n\nIntroduction to nowcasting\n\n\n\n\nThis session aims to introduce the concept of nowcasting, and see how we can perform a nowcast if we know the underlying delay distribution.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/nowcasting.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html#slides",
    "href": "sessions/nowcasting.html#slides",
    "title": "Nowcasting concepts",
    "section": "",
    "text": "Introduction to nowcasting",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html#objectives",
    "href": "sessions/nowcasting.html#objectives",
    "title": "Nowcasting concepts",
    "section": "",
    "text": "This session aims to introduce the concept of nowcasting, and see how we can perform a nowcast if we know the underlying delay distribution.\n\n\n\n\n\n\nSetup\n\n\n\n\n\n\n\nThe source file of this session is located at sessions/nowcasting.qmd.\n\n\n\nIn this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.\n\n\n\n\n\nWe set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html#source-file",
    "href": "sessions/nowcasting.html#source-file",
    "title": "Nowcasting concepts",
    "section": "",
    "text": "The source file of this session is located at sessions/nowcasting.qmd.",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html#libraries-used",
    "href": "sessions/nowcasting.html#libraries-used",
    "title": "Nowcasting concepts",
    "section": "",
    "text": "In this session we will use the nfidd package to load the data set of infection times, the dplyr and tidyr packages for data wrangling, ggplot2 library for plotting, the here library to find the stan model, and the cmdstanr library for using stan. We will also use the tidybayes package for extracting results of the inference.\n\nlibrary(\"nfidd\")\n\nWarning: replacing previous import 'bayesplot::rhat' by 'posterior::rhat' when\nloading 'nfidd'\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"cmdstanr\")\nlibrary(\"tidybayes\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to interact with the material is via the Visual Editor of RStudio. If not using the Visual Editor please remember that the code in the session needs to be run inside the course repository so that the here() commands below find the stan model files.",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html#initialisation",
    "href": "sessions/nowcasting.html#initialisation",
    "title": "Nowcasting concepts",
    "section": "",
    "text": "We set a random seed for reproducibility. Setting this ensures that you should get exactly the same results on your computer as we do. We also set an option that makes cmdstanr show line numbers when printing model code. This is not strictly necessary but will help us talk about the models.\n\nset.seed(123)\noptions(cmdstanr_print_line_numbers = TRUE)",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html#the-simplest-possible-nowcasting-model",
    "href": "sessions/nowcasting.html#the-simplest-possible-nowcasting-model",
    "title": "Nowcasting concepts",
    "section": "The simplest possible nowcasting model",
    "text": "The simplest possible nowcasting model\nHere we assume that the delay distribution is known and that we can use it to nowcast the most recent data. In practice, the delay distribution is often not known and needs to be estimated from the data. We could do this using methods from the session on biases in delay distributions.\nIn the session on convolutions we used delay distributions convolved with the infection times to estimate the time series of symptom onsets. A simple way to nowcast is to use the same approach but using the cumulative distribution function of the delay distribution rather than the probability density function and only apply it to the most recent data as this is the only data that can be subject to change (due to delays in reporting). We will build intuition for this as usual using simulation. First we define the proportion reported using a delay distribution, again using a lognormal distribution with meanlog 1 and sdlog 0.5:\n\nproportion_reported &lt;- plnorm(1:15, 1, 0.5)\nplot(proportion_reported)\n\n\n\n\n\n\n\n\nThe plnorm() function is related to the rlnorm() function we used earlier to simulate the individual level reporting delay, but instead it gives the cumulative distribution function rather than random samples. That is, it gives us the probability that a report is made on day 1 or earlier, day 2 or earlier, etc.\nWe can now construct some simulated data and use this delay distribution to nowcast the most recent data. Here we use the same simulation approach as in the renewal session and apply the reporting_delay to the last 15 days of data.\n\nsource(here(\"snippets\", \"simulate-onsets.r\"))\nreported_onset_df &lt;- onset_df |&gt;\n  filter(day &lt; cutoff) |&gt;\n  mutate(proportion_reported = c(rep(1, n() - 15), rev(proportion_reported)),\n         reported_onsets = rpois(n(), onsets * proportion_reported)\n  )\ntail(reported_onset_df)\n\n# A tibble: 6 × 5\n    day onsets infections proportion_reported reported_onsets\n  &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;               &lt;dbl&gt;           &lt;int&gt;\n1    65     63         83              0.943               51\n2    66     64         75              0.889               58\n3    67     75         92              0.780               57\n4    68     78        113              0.578               34\n5    69     69        120              0.270               20\n6    70     84        115              0.0228               4\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nSpend a few minutes trying to understand the code above. What is the proportion_reported? What is the reported_onsets?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe proportion_reported is the cumulative distribution function of the delay distribution. It gives the probability that a report is made on day 1 or earlier, day 2 or earlier, etc. Note that for days more that 15 days into the past\nThe reported_onsets are the number of onsets that are reported on each day. This is calculated by multiplying the number of onsets by the proportion of onsets that are reported on each day. It has Poisson noise added to it to simulate the stochasticity in the reporting process.\n\n\n\n\nWe can now fit our first nowcasting model. Here we assume exactly the same generative process as we used for simulation and model the number of onsets as independent draws from a normal distribution.\n\nmod &lt;- cmdstan_model(here(\"stan\", \"simple-nowcast.stan\"))\nmod\n\n 1: functions {\n 2:   #include \"functions/condition_onsets_by_report.stan\"\n 3: }\n 4: \n 5: data {\n 6:   int n;                // number of days\n 7:   array[n] int obs;     // observed symptom onsets\n 8:   int report_max;       // max reporting delay\n 9:   array[report_max + 1] real report_cdf;\n10: }\n11: \n12: parameters {\n13:   array[n] real&lt;lower = 0&gt; onsets;\n14: }\n15: \n16: transformed parameters {\n17:   array[n] real reported_onsets = condition_onsets_by_report(onsets, report_cdf);\n18: }\n19: \n20: model {\n21:   onsets ~ normal(5, 20) T[0,];\n22:   // Likelihood\n23:   obs ~ poisson(reported_onsets);\n24: }\n\n\n\n\n\n\n\n\nTake 5 minutes\n\n\n\nFamiliarise yourself with the model above. What does it do?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nOn line 2 we define a new function condition_onsets_by_report.stan which takes the number of onsets and reports and the delay distribution as input and returns the nowcasted number of onsets.\nOn line 17, this function is used to calculate the nowcasted number of onsets and this is then used in the likelihood.\nOn line 21, we define the generative process for the number of onsets. Here we assume that onsets are independent with each drawn from a normal distribution.\n\n\n\n\nOnce again we can generate estimates from this model:\n\ndata &lt;- list(\n  n = nrow(reported_onset_df) - 1,\n  obs = reported_onset_df$reported_onsets[-1],\n  report_max = length(proportion_reported) - 1,\n  report_cdf = proportion_reported \n)\nsimple_nowcast_fit &lt;- mod$sample(data = data, parallel_chains = 4)\n\n\nsimple_nowcast_fit\n\n  variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n lp__      2334.35 2334.71 6.19 6.11 2323.36 2343.72 1.00     1572     2507\n onsets[1]    0.99    0.69 1.00 0.71    0.05    3.06 1.00     5796     2256\n onsets[2]    1.01    0.71 0.99 0.72    0.05    3.02 1.00     5775     2551\n onsets[3]    1.03    0.68 1.08 0.72    0.05    3.05 1.00     5721     2292\n onsets[4]    0.99    0.70 1.00 0.70    0.05    2.98 1.00     5078     2368\n onsets[5]    0.99    0.70 0.96 0.71    0.06    2.87 1.00     5456     2397\n onsets[6]    1.00    0.72 1.00 0.70    0.05    2.98 1.00     5677     2794\n onsets[7]    1.00    0.68 0.99 0.69    0.06    3.03 1.00     6219     2554\n onsets[8]    1.02    0.71 1.03 0.71    0.05    3.08 1.00     6398     2110\n onsets[9]    1.97    1.67 1.37 1.20    0.35    4.69 1.00     6745     2970\n\n # showing 10 of 139 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\nWe can now plot onsets alongside those nowcasted by the model:\n\nnowcast_onsets &lt;- simple_nowcast_fit |&gt;\n  gather_draws(onsets[day]) |&gt;\n  ungroup() |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  mutate(day = day + 1)\n\n\nggplot(nowcast_onsets, aes(x = day)) +\n  geom_line(mapping = aes(y = .value, group = .draw), alpha = 0.1) +\n  geom_col(data = reported_onset_df, mapping = aes(y = onsets), alpha = 0.6) +\n  geom_point(data = reported_onset_df, mapping = aes(y = reported_onsets))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe points in this plot represent the data available when the nowcast was made (and so are truncated) whilst the bars represent the finally reported data (a perfect nowcast would exactly reproduce these).\n\n\n\n\n\n\n\n\nTip\n\n\n\nAs we found in the using delay distributions to model the data generating process of an epidemic session, this simple model struggles to recreate the true number of onsets. This is because it does not capture the generative process of the data (i.e. the transmission process and delays from infection to onset). In the next section we will see how we can use a model that does capture this generative process to improve our nowcasts.",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html#adding-in-a-geometric-random-walk-to-the-nowcasting-model",
    "href": "sessions/nowcasting.html#adding-in-a-geometric-random-walk-to-the-nowcasting-model",
    "title": "Nowcasting concepts",
    "section": "Adding in a geometric random walk to the nowcasting model",
    "text": "Adding in a geometric random walk to the nowcasting model\nAs we saw in the session on the renewal equation, a geometric random walk is a simple way to model multiplicative growth. Adding this into our simple nowcasting model may help us to better capture the generative process of the data and so produce a better nowcast.\nWe first load the model\n\nrw_mod &lt;- cmdstan_model(here(\"stan\", \"simple-nowcast-rw.stan\"))\nrw_mod\n\n 1: functions {\n 2:   #include \"functions/geometric_random_walk.stan\"\n 3:   #include \"functions/condition_onsets_by_report.stan\"\n 4: }\n 5: \n 6: data {\n 7:   int n;                // number of days\n 8:   array[n] int obs;     // observed symptom onsets\n 9:   int report_max;       // max reporting delay\n10:   array[report_max + 1] real report_cdf;\n11: }\n12: \n13: parameters {\n14:   real&lt;lower=0&gt; init_onsets;\n15:   array[n-1] real rw_noise;\n16:   real&lt;lower=0&gt; rw_sd;\n17: }\n18: \n19: transformed parameters {\n20:   array[n] real onsets = geometric_random_walk(init_onsets, rw_noise, rw_sd);\n21:   array[n] real reported_onsets = condition_onsets_by_report(onsets, report_cdf);\n22: }\n23: \n24: model {\n25:   init_onsets ~ lognormal(0, 1) T[0,];\n26:   rw_noise ~ std_normal();\n27:   rw_sd ~ normal(0, 5) T[0,];\n28:   //Likelihood\n29:   obs ~ poisson(reported_onsets);\n30: }\n\n\nand then fit it\n\nrw_nowcast_fit &lt;- rw_mod$sample(data = data, parallel_chains = 4)\n\n\nrw_nowcast_fit\n\n    variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n lp__        2177.13 2177.50 8.77 8.58 2162.03 2191.03 1.00      836     1408\n init_onsets    0.29    0.25 0.17 0.15    0.09    0.62 1.00     4994     3271\n rw_noise[1]   -1.18   -1.18 0.83 0.83   -2.56    0.19 1.00     4120     3116\n rw_noise[2]   -0.82   -0.82 0.91 0.92   -2.32    0.66 1.00     4835     2973\n rw_noise[3]   -0.55   -0.54 0.90 0.86   -2.03    0.95 1.00     5052     3111\n rw_noise[4]   -0.34   -0.33 0.93 0.93   -1.87    1.18 1.00     5113     3224\n rw_noise[5]   -0.18   -0.18 0.95 0.93   -1.74    1.39 1.00     4562     2915\n rw_noise[6]   -0.01   -0.03 0.93 0.93   -1.53    1.55 1.00     4625     2931\n rw_noise[7]    0.18    0.16 0.95 0.97   -1.35    1.70 1.00     5887     3063\n rw_noise[8]    0.36    0.37 0.90 0.88   -1.14    1.82 1.00     4985     3298\n\n # showing 10 of 209 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\nAgain we can extract the nowcasted onsets and plot them alongside the observed data:\n\nrw_nowcast_onsets &lt;- rw_nowcast_fit |&gt;\n  gather_draws(onsets[day]) |&gt;\n  ungroup() |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt; ## sample 100 iterations randomly\n  mutate(day = day + 1)\n\n\nggplot(rw_nowcast_onsets, aes(x = day)) +\n  geom_col(data = reported_onset_df, mapping = aes(y = onsets), alpha = 0.6) +\n  geom_line(mapping = aes(y = .value, group = .draw), alpha = 0.1) +\n  geom_point(data = reported_onset_df, mapping = aes(y = reported_onsets))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nWhat do you think of the nowcast now? Does it look better than the previous one?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe nowcast better matches the ultimately observed data. The geometric random walk allows the model to capture the multiplicative growth in the data and so better capture that current indidence is related to past incidence.\nThis should be particularly true when the data is more truncated (i.e nearer to the date of the nowcast) as the geometric random walk allows the model to extrapolate incidence based on previous incidence rather than relying on the prior distribution as the simpler model did.\nHowever, the model is still quite simple and so may struggle to capture more complex patterns in the data. In particular, the prior model for the geometric random walk assumes that onsets are the same as the previous day with statistical noise. This may not be a good assumption in a rapidly changing epidemic (where the reproduction number is not near 1).",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/nowcasting.html#what-happens-if-we-get-the-delay-distribution-wrong",
    "href": "sessions/nowcasting.html#what-happens-if-we-get-the-delay-distribution-wrong",
    "title": "Nowcasting concepts",
    "section": "What happens if we get the delay distribution wrong?",
    "text": "What happens if we get the delay distribution wrong?\nIn practice, we often do not know the delay distribution and so need to estimate it using the data at hand. In the session on biases in delay distributions we saw how we could do this using individual-level records. We will now look at what happens if we get the delay distribution wrong.\nWe use the same data as before but now assume that the delay distribution is a gamma distribution with shape 2 and rate 3. This is a very different distribution to the lognormal distribution we used to simulate the data.\n\nwrong_proportion_reported &lt;- pgamma(1:15, 2, 3)\nplot(wrong_proportion_reported)\n\n\n\n\n\n\n\n\nWe first need to update the data to use this new delay distribution:\n\nwrong_delay_data &lt;- data\nwrong_delay_data$report_cdf &lt;- wrong_proportion_reported\n\nWe now fit the nowcasting model with the wrong delay distribution:\n\ngamma_nowcast_fit &lt;- rw_mod$sample(data = wrong_delay_data, parallel_chains = 4)\n\n\ngamma_nowcast_fit\n\n    variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n lp__        2180.83 2181.24 8.70 8.61 2165.76 2194.57 1.00      782     1805\n init_onsets    0.30    0.27 0.18 0.16    0.08    0.65 1.00     3902     2665\n rw_noise[1]   -1.20   -1.20 0.86 0.83   -2.61    0.22 1.00     4991     2817\n rw_noise[2]   -0.81   -0.80 0.90 0.88   -2.33    0.68 1.00     5342     2885\n rw_noise[3]   -0.55   -0.53 0.90 0.92   -2.07    0.90 1.00     5430     3050\n rw_noise[4]   -0.34   -0.33 0.93 0.96   -1.86    1.15 1.00     5523     3216\n rw_noise[5]   -0.15   -0.14 0.91 0.92   -1.66    1.36 1.00     4868     3107\n rw_noise[6]    0.04    0.03 0.91 0.93   -1.44    1.54 1.00     4668     2834\n rw_noise[7]    0.21    0.21 0.92 0.91   -1.31    1.74 1.00     5434     3032\n rw_noise[8]    0.45    0.44 0.93 0.90   -1.07    2.00 1.00     5034     2746\n\n # showing 10 of 209 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\nAgain we can extract the nowcast of symptom onsets and plot it alongside the observed data:\n\ngamma_nowcast_onsets &lt;- gamma_nowcast_fit |&gt;\n  gather_draws(onsets[day]) |&gt;\n  ungroup() |&gt;\n  filter(.draw %in% sample(.draw, 100)) |&gt;\n  mutate(day = day + 1)\n\n\nggplot(gamma_nowcast_onsets, aes(x = day)) +\n  geom_col(data = reported_onset_df, mapping = aes(y = onsets), alpha = 0.6) +\n  geom_line(mapping = aes(y = .value, group = .draw), alpha = 0.1) +\n  geom_point(data = reported_onset_df, mapping = aes(y = reported_onsets))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake 2 minutes\n\n\n\nWhat do you think of the nowcast now? How would you know you had the wrong delay if you didn’t have the true delay distribution?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThe nowcast now looks very different to the observed data. This is because the model is using the wrong delay distribution to nowcast the data.\nIf you didn’t have the true delay distribution you would not know that you had the wrong delay distribution. This is why it is important to estimate the delay distribution from the data.\nIn practice, you would likely compare the nowcast to the observed data and if they did not match you would consider whether the delay distribution was the cause.",
    "crumbs": [
      "Nowcasting concepts"
    ]
  },
  {
    "objectID": "sessions/slides/forecasting-as-an-epidemiological-problem.html#r-fontawesomefalaptop-code-white-your-turn",
    "href": "sessions/slides/forecasting-as-an-epidemiological-problem.html#r-fontawesomefalaptop-code-white-your-turn",
    "title": "Forecasting as an epidemiological problem",
    "section": "r fontawesome::fa(\"laptop-code\", \"white\") Your Turn",
    "text": "r fontawesome::fa(\"laptop-code\", \"white\") Your Turn\n\nStart with a simple model and use it to make a forecast (using stan)\nEvaluate the forecasts using proper scoring rules"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#epidemiological-events-disease-progression",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#epidemiological-events-disease-progression",
    "title": "Introduction to epidemiological delays",
    "section": "Epidemiological events: disease progression",
    "text": "Epidemiological events: disease progression\n\ninfection\nsymptom onset\nbecoming infectious\nhospital admission\ndeath"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#epidemiological-events-recovery",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#epidemiological-events-recovery",
    "title": "Introduction to epidemiological delays",
    "section": "Epidemiological events: recovery",
    "text": "Epidemiological events: recovery\n\npathogen clearance\nsymptoms clearance\nend of infectiousness\ndischarge from hospital"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#epidemiological-events-control",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#epidemiological-events-control",
    "title": "Introduction to epidemiological delays",
    "section": "Epidemiological events: control",
    "text": "Epidemiological events: control\n\nquarantine\nisolation\ntreatment"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#epidemiological-events-reporting",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#epidemiological-events-reporting",
    "title": "Introduction to epidemiological delays",
    "section": "Epidemiological events: reporting",
    "text": "Epidemiological events: reporting\n\nspecimen taken\nreport added to database"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names",
    "title": "Introduction to epidemiological delays",
    "section": "Some delays have names",
    "text": "Some delays have names\ninfection to symptom onset\n\nIncubation period"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-1",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-1",
    "title": "Introduction to epidemiological delays",
    "section": "Some delays have names",
    "text": "Some delays have names\ninfection to becoming infectious\n\nLatent period"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-2",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-2",
    "title": "Introduction to epidemiological delays",
    "section": "Some delays have names",
    "text": "Some delays have names\nbecoming infectious to end of infectiousness\n\nInfectious period"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-3",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-3",
    "title": "Introduction to epidemiological delays",
    "section": "Some delays have names",
    "text": "Some delays have names\nhospital admission to discharge\n\nLength of stay"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-4",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-4",
    "title": "Introduction to epidemiological delays",
    "section": "Some delays have names",
    "text": "Some delays have names\nsymptom onset (person A) to symptom onset (person B, infected by A)\n\nSerial interval"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-5",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#some-delays-have-names-5",
    "title": "Introduction to epidemiological delays",
    "section": "Some delays have names",
    "text": "Some delays have names\ninfection (person A) to infection (person B, infected by A)\n\nGeneration interval"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#why-do-we-want-to-know-these",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#why-do-we-want-to-know-these",
    "title": "Introduction to epidemiological delays",
    "section": "Why do we want to know these?",
    "text": "Why do we want to know these?"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#key-parameters-in-mathematical-models",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#key-parameters-in-mathematical-models",
    "title": "Introduction to epidemiological delays",
    "section": "Key parameters in mathematical models",
    "text": "Key parameters in mathematical models\n\nFerguson et al., 2020"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#key-parameters-in-mathematical-models-1",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#key-parameters-in-mathematical-models-1",
    "title": "Introduction to epidemiological delays",
    "section": "Key parameters in mathematical models",
    "text": "Key parameters in mathematical models\n\nWard et al., 2020"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#key-elements-of-infectious-disease-epidemiology",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#key-elements-of-infectious-disease-epidemiology",
    "title": "Introduction to epidemiological delays",
    "section": "Key elements of infectious disease epidemiology",
    "text": "Key elements of infectious disease epidemiology\n Nishiura et al., 2007"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#why-do-we-want-to-know-these-1",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#why-do-we-want-to-know-these-1",
    "title": "Introduction to epidemiological delays",
    "section": "Why do we want to know these?",
    "text": "Why do we want to know these?\n\nKey elements of infectious disease epidemiology\nIntricate relationship with nowcasting/forecasting"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#quantifying-delays",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#quantifying-delays",
    "title": "Introduction to epidemiological delays",
    "section": "Quantifying delays",
    "text": "Quantifying delays\n\nEpidemiological delays are variable\nWe can capture their variability using probability distributions"
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#warning-two-levels-of-uncertainty",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#warning-two-levels-of-uncertainty",
    "title": "Introduction to epidemiological delays",
    "section": "Warning: Two levels of uncertainty",
    "text": "Warning: Two levels of uncertainty\n\nProbability distributions characterise variability in the delays between individuals\nParameters of the probability distribution can be uncertain\n\n\n\n\\[\n\\alpha \\sim \\mathrm{Normal}(mean = 5, sd = 0.1) \\\\\n\\beta \\sim \\mathrm{Normal}(mean = 1, sd = 0.1) \\\\\n\\]\nShowing probability density functions of lognormal distributions with shape \\(\\alpha\\) and rate \\(\\beta\\)."
  },
  {
    "objectID": "sessions/slides/introduction-to-epidemiological-delays.html#your-turn",
    "href": "sessions/slides/introduction-to-epidemiological-delays.html#your-turn",
    "title": "Introduction to epidemiological delays",
    "section": " Your Turn",
    "text": "Your Turn\n\nSimulate epidemiological delays\nEstimate parameters of a delay distribution"
  },
  {
    "objectID": "sessions/slides/introduction-to-nowcasting.html#r-fontawesomefalaptop-code-white-your-turn",
    "href": "sessions/slides/introduction-to-nowcasting.html#r-fontawesomefalaptop-code-white-your-turn",
    "title": "Introduction to nowcasting",
    "section": "r fontawesome::fa(\"laptop-code\", \"white\") Your Turn",
    "text": "r fontawesome::fa(\"laptop-code\", \"white\") Your Turn\n\nPerform nowcast with a known reporting delay distribution\nPerform a nowcast using a more realistic data generating process\nExplore the impact of getting the delay distribution wrong"
  },
  {
    "objectID": "sessions/slides/introduction-to-stan.html#what-is-stan-and-why-do-we-use-it",
    "href": "sessions/slides/introduction-to-stan.html#what-is-stan-and-why-do-we-use-it",
    "title": "Introduction to stan",
    "section": "What is stan and why do we use it?",
    "text": "What is stan and why do we use it?\n\na Probabilistic Programming Language for Bayesian inference (i.e., a way to write down models)\nmodels are written in a text file (often ending .stan) and then loaded into an R/python/etc interface\nonce a model is written down, stan can be used to generate samples from the posterior distribution (using a variety of methods)"
  },
  {
    "objectID": "sessions/slides/introduction-to-stan.html#how-to-write-a-model-in-stan",
    "href": "sessions/slides/introduction-to-stan.html#how-to-write-a-model-in-stan",
    "title": "Introduction to stan",
    "section": "How to write a model in stan",
    "text": "How to write a model in stan\n\n\nIn a stan model file we specify:\n\nData(types and names)\nParameters(types and names)\nModel(prior and likelihood)\n\n\n\n\ndata {\n\n}\n\nparameters {\n\n}\n\nmodel {\n\n}"
  },
  {
    "objectID": "sessions/slides/introduction-to-stan.html#example-fairness-of-a-coin",
    "href": "sessions/slides/introduction-to-stan.html#example-fairness-of-a-coin",
    "title": "Introduction to stan",
    "section": "Example: fairness of a coin",
    "text": "Example: fairness of a coin\n\n\nData:\n\n\\(N\\) coin flips\n\\(x\\) times heads\n\nParameters\n\n\\(\\theta\\), probability of getting heads; uniform prior in \\([0, 1]\\)\n\n\n\n\ndata {\n  int&lt;lower = 1&gt; N;  // integer, minimum 1\n  int&lt;lower = 0&gt; x; // integer, minimum 0\n}\n\nparameters {\n  real&lt;lower = 0, upper = 1&gt; theta; // real, between 0 and 1\n}\n\nmodel {\n  // Uniform prior\n  theta ~ uniform(0, 1);\n  // Binomial likelihood\n  x ~ binomial(N, theta);\n}"
  },
  {
    "objectID": "sessions/slides/introduction-to-stan.html#using-stan-from-r",
    "href": "sessions/slides/introduction-to-stan.html#using-stan-from-r",
    "title": "Introduction to stan",
    "section": "Using stan from R",
    "text": "Using stan from R\nThere are two packages for using stan from R. We will use the cmdstanr package:\n\nlibrary(\"cmdstanr\")\nmod &lt;- cmdstan_model(here::here(\"stan\", \"coin.stan\"))\nmod\n\ndata {\n  int&lt;lower = 1&gt; N;  // integer, minimum 1\n  int&lt;lower = 0&gt; x; // integer, minimum 0\n}\n\nparameters {\n  real&lt;lower = 0, upper = 1&gt; theta; // real, between 0 and 1\n}\n\nmodel {\n  // Uniform prior\n  theta ~ uniform(0, 1);\n  // Binomial likelihood\n  x ~ binomial(N, theta);\n}"
  },
  {
    "objectID": "sessions/slides/introduction-to-stan.html#sampling-from-the-posterior",
    "href": "sessions/slides/introduction-to-stan.html#sampling-from-the-posterior",
    "title": "Introduction to stan",
    "section": "Sampling from the posterior",
    "text": "Sampling from the posterior\n\ndata &lt;- list(\n  N = 10, ## 10 coin flips\n  x = 6 ## 6 times heads\n)\nmod$sample(data = data)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n variable  mean median   sd  mad     q5   q95 rhat ess_bulk ess_tail\n    lp__  -8.70  -8.39 0.80 0.33 -10.24 -8.15 1.00     1677     1845\n    theta  0.58   0.59 0.14 0.15   0.35  0.81 1.00     1517     1763"
  }
]